import{S as PS,i as $S,s as AS,k as i,q as p,a as n,y as v,l as r,m as a,h as l,r as s,c as u,z as m,n as D,b as f,E as t,A as E,g as _,d as c,B as d}from"./index.d78780bf.js";import{H as hS}from"./Highlight.1019e7a6.js";import{I as L}from"./Image.605b14b5.js";function xS(qm){let y;return{c(){y=p("이때 lines라는 RDD를 메모리로 불러오는 게 아님! count라는 action이 처음 수행된 *errors*를 메모리로 불러옴! (Lazy Execution)")},l(S){y=s(S,"이때 lines라는 RDD를 메모리로 불러오는 게 아님! count라는 action이 처음 수행된 *errors*를 메모리로 불러옴! (Lazy Execution)")},m(S,Rt){f(S,y,Rt)},d(S){S&&l(y)}}}function wS(qm){let y,S,Rt,Jm,mu,ei,Qm,Eu,k,Ua,Ca,Gm,Km,ja,Ba,Wm,Vm,Lt,Na,Zm,Xm,It,Fa,Ym,gm,za,eE,lE,Oa,Ta,tE,iE,qa,Ja,rE,aE,Qa,Ga,oE,_u,cu,du,Ru,be,ye,Ka,fE,Lu,Iu,ku,li,pE,bu,W,Wa,sE,nE,Va,uE,DE,Za,vE,yu,ti,mE,Su,w,Xa,EE,_E,Ya,cE,dE,ga,RE,LE,eo,IE,Pu,ii,kE,$u,V,lo,bE,yE,to,SE,PE,io,$E,Au,ri,AE,hu,Se,ro,hE,xE,ao,wE,xu,ai,ME,wu,M,oo,HE,UE,fo,CE,jE,po,BE,NE,so,FE,Mu,oi,zE,Hu,Pe,no,OE,TE,uo,qE,Uu,fi,JE,Cu,$e,Do,QE,GE,vo,KE,ju,pi,WE,Bu,Ae,mo,VE,ZE,Eo,XE,Nu,Fu,zu,Ou,he,xe,_o,YE,Tu,qu,Ju,we,Me,co,gE,Qu,si,e_,Gu,Z,Ro,l_,t_,Lo,i_,r_,Io,a_,Ku,ni,o_,Wu,He,ko,f_,p_,bo,s_,Vu,ui,n_,Zu,X,yo,u_,D_,So,v_,m_,Po,E_,Xu,Ue,Ce,$o,__,Yu,Di,c_,gu,vi,Ao,d_,e1,mi,R_,l1,Y,ho,L_,I_,Ei,k_,_e,xo,b_,y_,wo,S_,P_,Mo,$_,A_,Ho,h_,t1,_i,x_,i1,H,Uo,w_,M_,Co,H_,U_,jo,C_,j_,Bo,B_,r1,je,Be,No,N_,a1,ci,F_,o1,di,kt,z_,bt,O_,f1,Ri,T_,p1,yt,s1,Li,q_,n1,St,u1,ce,Fo,J_,Q_,zo,G_,K_,D1,Ne,Oo,Fe,W_,To,V_,v1,Ii,Z_,m1,Pt,E1,U,ki,X_,de,$t,Y_,qo,g_,e3,l3,Jo,t3,i3,Qo,r3,a3,Go,o3,f3,ze,Ko,p3,s3,Wo,n3,u3,D3,Vo,v3,_1,Oe,Te,Zo,m3,c1,At,d1,bi,E3,R1,R,Xo,_3,c3,Yo,d3,R3,go,L3,I3,ef,k3,b3,lf,y3,S3,tf,P3,$3,rf,A3,h3,af,x3,L1,yi,w3,I1,qe,of,ff,pf,M3,H3,Si,ht,sf,U3,C3,nf,uf,j3,k1,Je,Qe,Df,B3,b1,Pi,N3,y1,$i,vf,F3,S1,Ai,z3,P1,g,hi,O3,xt,mf,T3,q3,Ef,J3,Q3,_f,G3,K3,cf,W3,$1,A1,h1,x1,Ge,Ke,df,V3,w1,M1,H1,xi,Z3,U1,wi,Rf,X3,C1,Mi,Y3,j1,ee,Lf,g3,ec,If,lc,tc,kf,ic,B1,Hi,rc,N1,We,bf,ac,oc,yf,fc,F1,Ui,pc,z1,Ve,Sf,sc,nc,Pf,uc,O1,Ze,Xe,$f,Dc,T1,wt,q1,Ye,Af,vc,mc,hf,Ec,J1,Ci,_c,Q1,ji,xf,cc,G1,Bi,dc,K1,Ni,wf,Rc,W1,ge,el,Mf,Lc,V1,Fi,Ic,Z1,ll,Hf,kc,bc,Uf,yc,X1,Mt,Y1,zi,Sc,g1,C,Cf,Pc,$c,Oi,Ac,jf,hc,xc,Ht,wc,Bf,Mc,Hc,Uc,Nf,Cc,eD,tl,il,Ff,jc,lD,Ti,zf,Bc,tD,qi,Nc,iD,rl,Of,Fc,zc,Tf,Oc,rD,Ji,Tc,aD,Ut,oD,I,x,qc,qf,Jc,Qc,Jf,Gc,Kc,Qf,Wc,Vc,Gf,Zc,Xc,Yc,Kf,gc,ed,Wf,ld,td,Vf,id,rd,Zf,ad,od,Xf,fd,pd,Yf,sd,fD,Qi,nd,pD,P,gf,ud,Dd,ep,vd,md,lp,Ed,_d,Gi,cd,Ct,dd,tp,Rd,sD,nD,uD,DD,al,ol,ip,Ld,vD,mD,ED,Ki,Id,_D,j,rp,kd,bd,ap,yd,Sd,op,Pd,$d,fp,Ad,cD,Wi,hd,dD,B,pp,xd,wd,sp,Md,Hd,np,Ud,Cd,Vi,jd,Re,Zi,Bd,jt,Nd,up,Fd,zd,Dp,Od,RD,Bt,LD,le,vp,Td,qd,mp,Jd,Qd,Ep,Gd,ID,Xi,Kd,kD,fl,_p,cp,Wd,Vd,dp,Rp,Zd,bD,Yi,Xd,yD,gi,Yd,SD,N,Lp,gd,e4,Ip,l4,t4,kp,i4,r4,bp,a4,PD,er,o4,$D,pl,yp,f4,p4,Sp,s4,AD,lr,n4,hD,sl,Pp,u4,D4,$p,v4,xD,tr,m4,wD,ir,Ap,E4,MD,rr,_4,HD,$,hp,c4,d4,xp,R4,L4,wp,I4,k4,Mp,b4,y4,Hp,S4,UD,CD,jD,BD,nl,ul,Up,P4,ND,FD,zD,ar,$4,OD,Dl,Cp,A4,h4,jp,x4,TD,or,w4,qD,vl,Bp,M4,H4,Np,U4,JD,ml,El,Fp,C4,QD,Nt,GD,fr,j4,KD,A,zp,B4,N4,Op,F4,z4,Tp,O4,T4,qp,q4,J4,Jp,Q4,WD,pr,G4,VD,te,Qp,K4,W4,Gp,V4,Z4,Kp,X4,ZD,_l,Wp,Y4,g4,sr,e5,Vp,Zp,l5,XD,nr,t5,YD,cl,Xp,i5,r5,Yp,a5,gD,dl,Rl,gp,o5,e2,ur,f5,l2,Dr,es,p5,t2,vr,s5,i2,F,ls,n5,u5,ts,D5,v5,is,m5,E5,rs,_5,r2,mr,c5,a2,Ll,as,d5,R5,Er,L5,Ft,os,I5,k5,fs,b5,o2,zt,f2,_r,y5,p2,Il,kl,ps,S5,s2,cr,P5,n2,ie,dr,$5,ss,ns,A5,h5,Rr,x5,us,Ds,w5,M5,Lr,H5,vs,ms,U5,u2,Ir,C5,D2,z,Es,j5,B5,_s,N5,F5,cs,z5,O5,ds,T5,v2,bl,yl,Rs,q5,m2,kr,J5,E2,br,Ls,Q5,_2,yr,G5,c2,re,Is,K5,W5,ks,V5,Z5,bs,X5,d2,Sr,Y5,R2,Sl,ys,g5,eR,Ss,lR,L2,Pr,tR,I2,Pl,Ps,iR,rR,$s,aR,k2,b2,y2,S2,$l,Al,As,oR,P2,$2,A2,$r,fR,h2,O,Ar,pR,hs,xs,sR,nR,hr,uR,ws,Ms,DR,vR,Hs,mR,ER,Us,_R,x2,hl,xl,Cs,cR,w2,Ot,M2,ae,js,dR,RR,Bs,LR,IR,xr,kR,Tt,Ns,bR,yR,Fs,SR,H2,wr,PR,U2,oe,zs,$R,AR,Os,hR,xR,Ts,wR,C2,Mr,MR,j2,Hr,HR,B2,fe,qs,UR,CR,Js,jR,BR,Qs,NR,N2,qt,F2,wl,Gs,FR,zR,Ks,OR,z2,Ml,Hl,Ws,TR,O2,Jt,T2,Ul,Vs,qR,JR,Zs,QR,q2,Cl,jl,Xs,GR,J2,Qt,Q2,pe,Ys,KR,WR,gs,VR,ZR,en,XR,G2,Ur,YR,K2,se,ln,gR,e6,tn,l6,t6,rn,i6,W2,Bl,Nl,an,r6,V2,Gt,Z2,Fl,zl,on,a6,X2,Cr,o6,Y2,jr,Br,f6,fn,pn,p6,g2,Kt,ev,Nr,s6,lv,Fr,zr,n6,sn,nn,u6,tv,Or,D6,iv,Tr,qr,v6,Le,un,m6,E6,Dn,_6,c6,vn,d6,rv,Ol,Tl,mn,R6,av,Wt,ov,ne,En,L6,I6,_n,k6,b6,Jr,y6,cn,dn,S6,fv,pv,sv,nv,ql,Jl,Rn,P6,uv,Dv,vv,Qr,$6,mv,Ql,Gl,Ln,A6,Ev,Gr,h6,_v,Kl,In,x6,w6,kn,M6,cv,Kr,H6,dv,T,bn,U6,C6,yn,j6,B6,Sn,N6,F6,Wr,z6,Pn,$n,O6,Rv,Vr,T6,Lv,q,An,q6,J6,hn,Q6,G6,xn,K6,W6,wn,V6,Iv,Zr,Z6,kv,J,Mn,X6,Y6,Hn,g6,e7,Un,l7,t7,Cn,i7,bv,Xr,r7,yv,Wl,Vl,jn,a7,Sv,Yr,o7,Pv,gr,Bn,f7,$v,ea,p7,Av,hv,xv,wv,Zl,Xl,Nn,s7,Mv,Hv,Uv,la,n7,Cv,Q,Vt,Fn,u7,D7,Zt,zn,v7,m7,On,E7,_7,Xt,Tn,c7,d7,Ie,qn,R7,L7,Jn,I7,k7,Qn,b7,y7,Yt,Gn,S7,P7,Kn,Wn,$7,A7,gt,Vn,h7,x7,ke,Zn,w7,M7,Xn,H7,U7,Yn,C7,jv,Yl,j7,B7,N7,Bv,G,gn,F7,z7,eu,O7,T7,lu,q7,J7,tu,Q7,Nv,gl,G7,K7,W7,Fv,ue,iu,V7,Z7,ru,X7,Y7,au,g7,zv,et,eL,lL,tL,Ov,ta,ou,iL,Tv,qv,Jv,Qv,lt,tt,fu,rL,Gv,Kv,Wv,ia,aL,Vv,ra,pu,oL,Zv,aa,fL,Xv,oa,su,pL,Yv,fa,sL,gv,pa,nu,nL,em,sa,uL,lm;return bt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/2.png"}}),yt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/3.png"}}),St=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/1.png"}}),Fe=new hS({props:{$$slots:{default:[xS]},$$scope:{ctx:qm}}}),Pt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/0.png"}}),At=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/4.png"}}),wt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/5.png"}}),Mt=new L({props:{alt:"Alt text](/post_img/Distributed%20Computing/Spark/RDD/6.png) ![Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/7.png"}}),Ut=new L({props:{alt:"Alt text](/post_img/Distributed%20Computing/Spark/RDD/8.png) ![Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/9.png"}}),Ct=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/10.png"}}),jt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/11.png"}}),Bt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/12.png"}}),Nt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/13.png"}}),zt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/14.png"}}),Ot=new L({props:{alt:"Alt text](/post_img/Distributed%20Computing/Spark/RDD/15.png) ![Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/16.png"}}),qt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/17.png"}}),Jt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/18.png"}}),Qt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/19.png"}}),Gt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/20.png"}}),Kt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/21.png"}}),Wt=new L({props:{alt:"Alt text",src:"/post_img/Distributed%20Computing/Spark/RDD/22.png"}}),{c(){y=i("h2"),S=i("a"),Rt=i("span"),Jm=p("Abstraction"),mu=n(),ei=i("p"),Qm=p("RDD(Resilient Distributed Datasets)"),Eu=n(),k=i("ul"),Ua=i("li"),Ca=i("p"),Gm=p("Resilient : 메모리 내부에서 데이터가 손실 시 유실된 파티션을 재연산해 복구할 수 있다."),Km=n(),ja=i("li"),Ba=i("p"),Wm=p("Distributed : 스파크 클러스터를 통하여 메모리에 분산되어 저장된다."),Vm=n(),Lt=i("li"),Na=i("p"),Zm=p("Data : 파일, 정보 등등"),Xm=n(),It=i("ul"),Fa=i("li"),Ym=p("분산 메모리 abstraction"),gm=n(),za=i("li"),eE=p("fault-tolerant하게 in-memory computation 가능해짐"),lE=n(),Oa=i("li"),Ta=i("p"),tE=p("iterative한 작업이나 interactive data mining 작업의 경우 in-memory로 하면 성능 향상"),iE=n(),qa=i("li"),Ja=i("p"),rE=p("shared memory의 제약된 형태로 fine-grained보단 course-grained 사용함"),aE=n(),Qa=i("li"),Ga=i("p"),oE=p("Spark에서는 이 RDD를 사용하여 다양한 형태의 user application이나 computation에서 적용 가능"),_u=n(),cu=i("br"),du=i("br"),Ru=n(),be=i("h2"),ye=i("a"),Ka=i("span"),fE=p("Introduce"),Lu=n(),Iu=i("hr"),ku=n(),li=i("p"),pE=p("MapReduce나 Dryad 등 데이터 분석 도구 특징"),bu=n(),W=i("ul"),Wa=i("li"),sE=p("fault tolerant나 work distribution에 대한 걱정 없이 High level operator를 통해 분산 환경에서 parallel computation 허용함"),nE=n(),Va=i("li"),uE=p("즉, 얘네들은 분산된 resource에 접근하는 abstraction임"),DE=n(),Za=i("li"),vE=p("근데 분산된 메모리를 활용하기 위한 abstraction은 부족함"),yu=n(),ti=i("p"),mE=p("data reuse 측면"),Su=n(),w=i("ul"),Xa=i("li"),EE=p("iterative한 작업(머신 러닝, 그래프 알고리즘 등)이나 interactive data mining 작업을 할 때, computation 사이에서 데이터를 reuse하는 유일한 방법은 intermediate data를 external stable storage에 저장하는 것임. (이런 애들은 reuse 자주 함)"),_E=n(),Ya=i("li"),cE=p("data replication, disk I/O, serialization 등 execution time 큰 것들로 인해 overhead 발생함"),dE=n(),ga=i("li"),RE=p("intermediate data를 메모리에 저장해서 reuse하는, Pregel과 HaLoop이라는 애들이 나오긴 했음. 근데 얘네들은 오직 특정한 형태의 computation pattern만 지원함"),LE=n(),eo=i("li"),IE=p("general하게 reuse할 수 있는 abstraction은 없음"),Pu=n(),ii=i("p"),kE=p("RDD는 다양한 application에서 data reuse를 가능하게 함"),$u=n(),V=i("ul"),lo=i("li"),bE=p("intermediate data를 메모리에 저장할 수 있는 fault tolerant, parallel 데이터 구조"),yE=n(),to=i("li"),SE=p("최적화되게끔 partitioning을 제어하거나 다양한 operator를 사용해서 데이터를 조작할 수 있음."),PE=n(),io=i("li"),$E=p("adhoc query를 돌릴 수도 있다."),Au=n(),ri=i("p"),AE=p("기존에 존재하는 클러스터 단위의 in-memory storage abstraction(distributed shared memory, key-value store, database, Piccolo)는 mutable state를 fine grade로 나누었음(ex. cells in table)"),hu=n(),Se=i("ul"),ro=i("li"),hE=p("이런 방식에서 fault-tolerance를 제공하려면 machine들 사이에서 1. replication을 저장하거나, 2. log update를 해야 함."),xE=n(),ao=i("li"),wE=p("이러한 방식은 상당한 양의 data-intensive workload가 발생하며, 데이터들이 cluster network를 통해 복사됨. cluster network의 bandwidth는 RAM보다 훨씬 별로라서, overhead가 발생함"),xu=n(),ai=i("p"),ME=p("반면 RDD에서는 이런 시스템과는 달리, 많은 데이터 항목에 동일하게 operation을 적용 가능한 course-grained 기반의 정보 교환(map, filter, join 등)을 함"),wu=n(),M=i("ul"),oo=i("li"),HE=p("실제 데이터가 아닌, dataset(lineage)을 만들 때 사용되는 transformation을 logging함으로써, fault tolerance 제공"),UE=n(),fo=i("li"),CE=p("lineage chain이 점점 커지면 데이터 자체를 checkpointing하는 게 유용할 때도 있음"),jE=n(),po=i("li"),BE=p("만약 RDD의 partition을 손실한다고 해도, RDD에서는 그 partition이 다른 RDD로부터 어떻게 생겨났는지에 대한 정보를 가지고 있음. 따라서 그 파티션을 recompute함"),NE=n(),so=i("li"),FE=p("따라서 손실된 데이터는 (비싼 data replication을 하지 않고도) 빠르게 복구될 수 있음"),Mu=n(),oi=i("p"),zE=p("coarse-grained transformation 기반의 인터페이스가 처음에는 너무 제약된 형태로 보일 순 있지만, RDD는 다양한 병렬 application에 적합함."),Hu=n(),Pe=i("ul"),no=i("li"),OE=p("이러한 application은 여러 data item에 동일한 operation을 적용하는 경향"),TE=n(),uo=i("li"),qE=p("실제로, RDD는 MapReduce, Dryad, SQL, pregel, HaLoop 뿐만 아니라, 이러한 시스템으로 하기 어려운 interactive data mining과 같이 새로운 application 등, 분리된 시스템으로 제안된 cluster programming model에 적용될 수 있음"),Uu=n(),fi=i("p"),JE=p("Spark라는 시스템에 RDD 구현하였음"),Cu=n(),$e=i("ul"),Do=i("li"),QE=p("UC 버클리를 비롯한 여러 회사에서 연구 및 production에 사용중"),GE=n(),vo=i("li"),KE=p("Spark는 language-intergrated programming interface를 제공함(언어 자체에 Query문이 포함된 LINQ처럼). 또한 Spark는 Scala interpreter를 통해서 크기가 큰 dataset에 query를 날릴 수 있음"),ju=n(),pi=i("p"),WE=p("Spark의 성능"),Bu=n(),Ae=i("ul"),mo=i("li"),VE=p("iterative application에서 하둡보다 20배 빠르고, real-world data analytic report에서 40배 빠르고, 1TB dataset을 scan하는 데 5~7초가 걸린다."),ZE=n(),Eo=i("li"),XE=p("RDD의 generality(범용성)을 증명하기 위해, Pregel과 HaLoop의 프로그래밍 모델을 Spark 위에서 구현하기도 했음. 이때 Pregel과 HaLoop이 사용하는 placement optimization을 적용하였고, 비교적 적은 라이브러리로 구현함."),Nu=n(),Fu=i("br"),zu=i("br"),Ou=n(),he=i("h2"),xe=i("a"),_o=i("span"),YE=p("Resilient Distributed Datasets(RDD)"),Tu=n(),qu=i("hr"),Ju=n(),we=i("h3"),Me=i("a"),co=i("span"),gE=p("RDD Abstraction"),Qu=n(),si=i("p"),e_=p("RDD는 Read-only이며, record들의 Partitioned Collection임."),Gu=n(),Z=i("ul"),Ro=i("li"),l_=p("RDD는 stable storage의 데이터나, 다른 RDD에 대한 deterministic operation을 통해서만 생성될 수 있음."),t_=n(),Lo=i("li"),i_=p("deterministic : 예측한 그대로 동작. 어떤 특정한 입력이 들어오면 언제나 똑같은 과정을 거쳐서 언제나 똑같은 결과를 내놓는다."),r_=n(),Io=i("li"),a_=p("이러한 operation을 RDD의 다른 operation과 구분하기 위해 transform이라 부름. transform의 예는 map, filter, join 등이 있음"),Ku=n(),ni=i("p"),o_=p("RDD는 항상 materialized일 필요는 없음(구체적으로 모든 정보를 포함할 필요는 없음)."),Wu=n(),He=i("ul"),ko=i("li"),f_=p("대신 stable storage에 저장된 데이터의 partition을 계산하기 위해, 다른 dataset(lineage)으로부터 어떻게 만들어진 것인지에 대해 정보를 포함하고 있음"),p_=n(),bo=i("li"),s_=p("프로그램은 failure가 발생한 후 reconstruct할 수 없는 RDD를 참조할 수 없음"),Vu=n(),ui=i("p"),n_=p("사용자는 RDD의 persistence(지속성)과 partitioning을 조절할 수 있음."),Zu=n(),X=i("ul"),yo=i("li"),u_=p("재사용할 RDD를 지정하고, 어떤 storage strategy를 사용할 것인지 결정 가능 (ex. in-memory storage)"),D_=n(),So=i("li"),v_=p("또한 RDD element가 각 record의 key에 따라 machine별로 partition 되게끔 요청할 수 있음"),m_=n(),Po=i("li"),E_=p("이는 placement optimization할 때 유용"),Xu=n(),Ue=i("h3"),Ce=i("a"),$o=i("span"),__=p("Spark Programming Interface"),Yu=n(),Di=i("p"),c_=p("Spark는 laguage-integrated API를 통해 RDD를 제공함"),gu=n(),vi=i("ul"),Ao=i("li"),d_=p("DryadLINQ나 FlumeJava와 유사함. 여기서는 각각의 dataset이 object로 표현되고, method를 통해 transformation을 호출함"),e1=n(),mi=i("p"),R_=p("개발자들은 stable storage로부터 (map이나 filter 등의)transformation을 함으로써, 한 개 이상의 RDD를 정의할 수 있음."),l1=n(),Y=i("ul"),ho=i("li"),L_=p("이렇게 RDD를 얻으면, action을 취할 수 있음"),I_=n(),Ei=i("li"),k_=p("action : 그 값을 applciation으로 반환하거나, storage system 밖으로 데이터를 빼내는 등으로 사용하는 것. action의 예는 다음과 같음"),_e=i("ul"),xo=i("li"),b_=p("count : dataset 내의 element의 수"),y_=n(),wo=i("li"),S_=p("collect : element 자체를 반환"),P_=n(),Mo=i("li"),$_=p("save : dataset을 storage system에 저장"),A_=n(),Ho=i("li"),h_=p("Spark는 RDD에서 처음 실행되는 action을 느리게 연산하여, transformation에 pipeline할 수 있음"),t1=n(),_i=i("p"),x_=p("persist : 특정 RDD가 미래의 operation에서 reuse될 수 있게끔 지정하는 method"),i1=n(),H=i("ul"),Uo=i("li"),w_=p("Spark는 default로 persistent RDD를 메모리에 저장해둠"),M_=n(),Co=i("li"),H_=p("하지만 RAM에 공간이 없으면 disk로 spill할 수 있음"),U_=n(),jo=i("li"),C_=p("유저 또한 다른 persistence strategy를 요청할 수 있음. 예를 들면 persist라는 flag는 RDD를 disk에만 저장하거나, 다른 machine들에 replication을 저장함"),j_=n(),Bo=i("li"),B_=p("유저는 RDD별로 persistence priority를 지정하여, 어떤 in-memory data가 disk로 먼저 spill되게끔 할 것인지 결정할 수 있음"),r1=n(),je=i("h4"),Be=i("a"),No=i("span"),N_=p("Example: Console Log Mining"),a1=n(),ci=i("p"),F_=p("웹 서비스가 장애를 겪고 있고, 오퍼레이터가 원인을 찾아내기 위해 테라바이트 단위의 로그를 HDFS로 분석해 본다고 가정해봅시다."),o1=n(),di=i("ul"),kt=i("li"),z_=p("Spark를 쓰면 오페레이터는 log의 에러 메시지를 RAM으로 불러와서, interactively(대화식) query를 날릴 수 있다.  "),v(bt.$$.fragment),O_=p(`
- line 1 : HDFS 파일으로부터 RDD를 정의한다
- line 2 : 1의 RDD에서 Filter된 RDD (ERROR로 시작하는 데이터) => scala 문법으로 가능!
- line 3 : *errors*라는 RDD가 메모리에 남아서, query 사이에서 공유될 수 있게 함`),f1=n(),Ri=i("p"),T_=p("cluster에 수행될 작업이 없다면, RDD로 에러 메시지의 수를 세는 등, action을 할 수 있음."),p1=n(),v(yt.$$.fragment),s1=n(),Li=i("p"),q_=p("사용자는 이렇게 얻은 RDD에서 추가적인 transformation을 실행하고, 그렇게 또 얻은 RDD에서 결과를 얻을 수 있음"),n1=n(),v(St.$$.fragment),u1=n(),ce=i("p"),Fo=i("em"),J_=p("errors"),Q_=p("에 관련된 첫 번째 액션(위에선 count)이 실행되면, Spark는 "),zo=i("em"),G_=p("errors"),K_=p("의 partition을 메모리에 불러옴. 그러면 다음의 매우 연산이 빨라짐"),D1=n(),Ne=i("ul"),Oo=i("li"),v(Fe.$$.fragment),W_=n(),To=i("li"),V_=p("에러 메시지는 데이터의 극히 일부분에 해당하는 것이기에 충분히 작음. 메모리에 올려도 괜찮음"),v1=n(),Ii=i("p"),Z_=p("이 모델이 fault tolerance를 달성하는 방법을 그림으로 나타낸 것"),m1=n(),v(Pt.$$.fragment),E1=n(),U=i("ul"),ki=i("li"),X_=p("위 3개의 query에 대한, RDD의 lineage graph"),de=i("ol"),$t=i("li"),Y_=p("lines라는 RDD에 대한 filter의 결과로, "),qo=i("em"),g_=p("errors"),e3=p("라는 RDD를 얻음"),l3=n(),Jo=i("li"),t3=p("1에서 filter하여 다음의 RDD, map 하여 다음의 RDD를 얻음"),i3=n(),Qo=i("li"),r3=p("2에서 collect()"),a3=n(),Go=i("li"),o3=p("Spark의 스케쥴러는 2의 map, filter 변환을 파이프라인화함"),f3=n(),ze=i("li"),Ko=i("em"),p3=p("errors"),s3=p("라는 RDD의 데이터가 캐싱되어 있는 partition을 가진 node한테 연산하라고 던짐 (아까 "),Wo=i("em"),n3=p("errors"),u3=p("는 count() 했었죠? 메모리에 올라가 있음)"),D3=n(),Vo=i("li"),v3=p("만약 partition을 손실할 경우, Spark는 해당되는 line 파티션에만 filter를 적용하여 재구성함"),_1=n(),Oe=i("h3"),Te=i("a"),Zo=i("span"),m3=p("Advantages of the RDD Model"),c1=n(),v(At.$$.fragment),d1=n(),bi=i("p"),E3=p("RDD와 Distributed Shared Memory(DSM)를 비교했을 때 장점이 나옴."),R1=n(),R=i("ul"),Xo=i("li"),_3=p("DSM은 global address space의 임의의 공간에서 read/write를 수행"),c3=n(),Yo=i("li"),d3=p("전통적인 shared memory system 뿐 아니라, Piccolo나 분산 데이터베이스 등 shared state를 fine-grained로 write하는 application도 DHT 사용함"),R3=n(),go=i("li"),L3=p("DSM은 일반적인 방식이지만, 하지만 이런 방식은 commodity cluster에서 효율적이고 fault-tolerant한 방식으로 구현하기 어려움"),I3=n(),ef=i("li"),k3=p("DSM은 각 메모리의 위치별 read / write를 허용하지만(이게 fine-grained의 정의임. 그리고 RDD도 read 연산은 fine-grained로 가능함), 반면 RDD는 Course-grained인 transformation을 통해서만 생성(write)될 수 있음"),b3=n(),lf=i("li"),y3=p("이는 RDD를 사용하는 application이 bulk write만 하게끔 제약하지만, 보다 효율적인 fault-tolerance를 제공함"),S3=n(),tf=i("li"),P3=p("RDD는 checkpointing의 overhead가 없는 대신, lineage를 통해 회복이 가능. (물론 lineage chain이 너무 길 경우 체크포인트를 쓰기도 함. 나중에 다룰 예정)"),$3=n(),rf=i("li"),A3=p(`또한 RDD에서는 failure 발생 시 오직 손실된 partition만 복구하며, 이는 전체 프로그램을 rollback할 필요 없이 다른 node에서 병렬적으로 실행 가능함.
RDD의 두 번째 장점은, straggler가 있으면 그 태스크의 백업 복사본을 실행할 수 있다는 것(MapReduce처럼)`),h3=n(),af=i("li"),x3=p("DSM에서는 Backup Task를 만드는 것이 어려움. 두 task가 동일한 메모리 영역을 액세스하여, 설의 업데이트를 방해하는 등 문제가 생길 수 있기 때문임."),L1=n(),yi=i("p"),w3=p("마지막으로, RDD는 두 가지 이점을 제공함"),I1=n(),qe=i("ul"),of=i("li"),ff=i("ol"),pf=i("li"),M3=p("bulk 연산에서 data locality에 따라 runtime schedule 가능 => 성능 향상"),H3=n(),Si=i("li"),ht=i("ol"),sf=i("li"),U3=p("스캔 기반 작업에만 사용된다면, 저장할 공간이 없을 때 성능 저하가 graceful하게 일어남."),C3=n(),nf=i("ul"),uf=i("li"),j3=p("RAM에 맞지 않는 partition은 disk에 저장되며, 현재의 data-parallel system과 유사한 성능을 냄."),k1=n(),Je=i("h3"),Qe=i("a"),Df=i("span"),B3=p("Application Not Suitable for RDDs"),b1=n(),Pi=i("p"),N3=p("RDD는 same operation을 전체 dataset에 적용하는 batch application에 적합함"),y1=n(),$i=i("ul"),vf=i("li"),F3=p("RDD는 각 단계의 transformation을 lineage graph의 한 단계로 기억하며, 많은 양의 데이터를 기록할 필요 없이 손실된 partition을 복구할 수 있음."),S1=n(),Ai=i("p"),z3=p("반면 부적합한 application도 존재함"),P1=n(),g=i("ul"),hi=i("li"),O3=p("asynchronous하게 fine-grained shared state를 update하는 application"),xt=i("ul"),mf=i("li"),T3=p("web server의 storage system"),q3=n(),Ef=i("li"),J3=p("점진적인 web crawler"),Q3=n(),_f=i("li"),G3=p("이러한 Application의 경우, 전통적인 log update, data checkpoint를 생성하는, database를 사용하는 것이 좋음"),K3=n(),cf=i("li"),W3=p("Spark의 목표는 batch analytic을 위한 프로그래밍 모델을 제공하는 것"),$1=n(),A1=i("br"),h1=i("br"),x1=n(),Ge=i("h2"),Ke=i("a"),df=i("span"),V3=p("Spark Programming Interfaces"),w1=n(),M1=i("hr"),H1=n(),xi=i("p"),Z3=p("Spark는 language-integrated API를 통해 RDD abstraction을 제공함"),U1=n(),wi=i("ul"),Rf=i("li"),X3=p("함수형 + 정적 타이핑 언어인 Scala를 선택하였는데, 간결하기 때문에 interactive하게 사용하기 용이함"),C1=n(),Mi=i("p"),Y3=p("Spark를 쓰는 개발자는 driver program을 작성해야 하는데, 얘가 클러스터의 worker들에 접속함."),j1=n(),ee=i("ul"),Lf=i("li"),g3=p("Driver는 한 개 이상의 RDD를 정의하고, action을 호출함."),ec=n(),If=i("li"),lc=p("Driver는 RDD Lineage를 추적함"),tc=n(),kf=i("li"),ic=p("worker는 여러 연산을 통해 RDD Partition을 RAM에 저장할 수 있는 long-lived process임"),B1=n(),Hi=i("p"),rc=p("map과 같은 RDD Operation에는 closure(function literal)를 넘겨줘야 함"),N1=n(),We=i("ul"),bf=i("li"),ac=p("이때 closure는 Java object로 표현되며, Serialize하여 네트워크를 통해 closure를 전송할 수 있음"),oc=n(),yf=i("li"),fc=p("또한, 이 closure에 묶여 있는 변수는 Object의 field값으로 설정됨"),F1=n(),Ui=i("p"),pc=p("RDD 자체는 원소의 타입을 파라미터로 넘길 수 있는 statically typed objected이다."),z1=n(),Ve=i("ul"),Sf=i("li"),sc=p("RDD[Int]는 Int의 RDD이다."),nc=n(),Pf=i("li"),uc=p("Scala는 Type Interface를 지원하니, 타입을 생략해도 된다."),O1=n(),Ze=i("h3"),Xe=i("a"),$f=i("span"),Dc=p("RDD Operations in Spark"),T1=n(),v(wt.$$.fragment),q1=p(`  
위 표는 Spark에서 사용 가능한 Transformation과 Action의 목록임.
`),Ye=i("ul"),Af=i("li"),vc=p("대괄호 안에 타입 파라미터를 표시하여, 각 연산의 특징을 제시하였음."),mc=n(),hf=i("li"),Ec=p("transformation은 lazy operation인 반면, action은 프로그램에 값을 반환하거나 외부 스토리지에 값을 write하기 위해 연산을 시작함."),J1=n(),Ci=i("p"),_c=p(`join 등의 연산은 key-value pair 형태의 RDD에서만 가능함.
또한 함수 이름은 스칼라나 다른 함수형 언어의 API와 매칭이 가능하게끔 선정하였음`),Q1=n(),ji=i("ul"),xf=i("li"),cc=p("map : 1-1 mapping / flatMap : MapReduce의 map과 유사함. 각 input value를 한 개 이상의 output과 mapping"),G1=n(),Bi=i("p"),dc=p(`사용자는 RDD가 지속되게끔 요청할 수 있음. (persist)
RDD의 partition order를 얻을 수도 있음.`),K1=n(),Ni=i("ul"),wf=i("li"),Rc=p(`Partitioner Class가 partition order를 나타냄. 이걸 가지고 다른 dataset을 partition할 수도 있음.
groupByKey, reduceByKey, sort 등의 연산은 자동으로 hash partition 또는 range partition된 RDD를 생성한다.`),W1=n(),ge=i("h3"),el=i("a"),Mf=i("span"),Lc=p("Example: Logistic Regression"),V1=n(),Fi=i("p"),Ic=p("기계 학습 알고리즘의 경우, iterative한 경우가 많다."),Z1=n(),ll=i("ul"),Hf=i("li"),kc=p("gradient descent 등 반복 최적화 절차를 수행하기 때문"),bc=n(),Uf=i("li"),yc=p("따라서 데이터를 메모리에 저장한다면 험청 빨라질 것임"),X1=n(),v(Mt.$$.fragment),Y1=n(),zi=i("p"),Sc=p("위 코드는 logistic regression 예제인데, 제가 머신러닝 이런거 안해봐서 뭔지 잘 모름 ㅈㅅ; 흐름만 봄"),g1=n(),C=i("ul"),Cf=i("li"),Pc=p("text file에서 map"),$c=n(),Oi=i("li"),Ac=p("parsePoint 함수 넘겨서 텍스트 파일의 각 라인으로부터 좌표상의 위치 얻음 => "),jf=i("em"),hc=p("points"),xc=n(),Ht=i("li"),wc=p("반복적으로 "),Bf=i("em"),Mc=p("points"),Hc=p("에서 map 및 reduce하여 결과(w 벡터)를 얻을 수 있음"),Uc=n(),Nf=i("li"),Cc=p("메모리에 올려놓고 반복하기 때문에 20배까지 속도가 빨라짐"),eD=n(),tl=i("h3"),il=i("a"),Ff=i("span"),jc=p("Example: PageRank"),lD=n(),Ti=i("ul"),zf=i("li"),Bc=p("RDD의 partitioning을 사용하여, 성능을 향상시킬 수 있는 것을 보여줌"),tD=n(),qi=i("p"),Nc=p(`더 복잡한 data sharing pattern임.
PageRank 알고리즘은 다른 문서에서 각 문서로 link되는 회수를 합산하여, 문서의 rank를 반복적으로 업데이트한다.`),iD=n(),rl=i("ul"),Of=i("li"),Fc=p("각 iteration마다 각 문서는 r/n의 기여도를 이웃들에게 보낸다. (r : rank, n : 이웃의 수)"),zc=n(),Tf=i("li"),Oc=p("그 후 순위를 α/N + (1 − α)∑ci 로 계산 (∑ci : 받은 기여도의 총합, N : 총 문서 수)"),rD=n(),Ji=i("p"),Tc=p("PageRank를 Spark로 나타내면 다음과 같음"),aD=n(),v(Ut.$$.fragment),oD=p(`  
좌측의 프로그램을 돌리면 우측의 그림과 같은 RDD Lineage 그래프를 얻을 수 있음
`),I=i("ul"),x=i("li"),qc=p("각 iteration마다, 이전 iteration의 "),qf=i("em"),Jc=p("contribs"),Qc=p("와 "),Jf=i("em"),Gc=p("ranks"),Kc=p(", 그리고 정적인 "),Qf=i("em"),Wc=p("links"),Vc=p("라는 dataset으로부터, 새로운 "),Gf=i("em"),Zc=p("ranks"),Xc=p("라는 dataset을 만듦."),Yc=n(),Kf=i("li"),gc=p("이 그래프의 흥미로운 특징은, 반복의 회수만큼 graph가 늘어난다는 것이다."),ed=n(),Wf=i("li"),ld=p("이 작업은 많은 iteration이 동반되므로, fault recovery를 효율적으로 하려면 특정 버전의 ranks를 replication을 만들어서 저장해야 할 수도 있음"),td=n(),Vf=i("li"),id=p("사용자는 RELIABLE 플래그를 줘서 persist 메소드를 호출하면 그렇게 할 수 있음"),rd=n(),Zf=i("li"),ad=p("하지만 links라는 dataset은 replication을 만들 필요가 없음. 그냥 input file에서 map 다시 돌리면 해당 partition을 다시 얻는 게 더 효율적이기 때문"),od=n(),Xf=i("li"),fd=p("이 dataset은 보통 ranks보다 훨씬 크기가 큼. 각 문서에는 많은 링크가 있지만 순위는 한 개뿐이기 때문"),pd=n(),Yf=i("li"),sd=p("따라서 lineage를 사용하여 복구하는 게, 프로그램의 전체 in-memory state의 checkpoint를 만드는 것보다 시간을 절약할 수 있음"),fD=n(),Qi=i("p"),nd=p("RDD의 partitioning을 제어함으로써, PageRank 알고리즘에서의 통신을 최적화할 수 있음"),pD=n(),P=i("ul"),gf=i("li"),ud=p("만약 links를 기준으로 partitioning하게끔 명시한다면, ranks에 대해서도 동일한 방식으로 partitioning할 수 있음"),Dd=n(),ep=i("li"),vd=p("그렇게 되면 links와 ranks간의 join 연산이 통신을 필요로 하지 않게 됨(같은 머신 위에 필요한 데이터가 있음)"),md=n(),lp=i("li"),Ed=p("Partitioner class를 작성하여, 도메인 이름에 따라 페이지를 묶을 수도 있음."),_d=n(),Gi=i("li"),cd=p("아래와 같이, links를 정의할 때 PartitionBy()라는 method를 통해 진행  "),v(Ct.$$.fragment),dd=n(),tp=i("li"),Rd=p("RDD는 사용자가 이러한 목표(일관된 partitioning을 통한 최적화)를 직접 표현할 수 있게 함."),sD=n(),nD=i("br"),uD=i("br"),DD=n(),al=i("h2"),ol=i("a"),ip=i("span"),Ld=p("Representing RDDs"),vD=n(),mD=i("hr"),ED=n(),Ki=i("p"),Id=p("RDD를 Abstraction으로 제공하기 위한 과제 중 하나는, 광범위한 transformation에서 lineage를 추적할 수 있는 표현을 선택하는 것임"),_D=n(),j=i("ul"),rp=i("li"),kd=p("RDD를 구현하는 시스템은 반드시 다양한 transformation 연산자들을 제공해야 하며, 사용자가 임의의 방식으로 transformation을 선택할 수 있게 해야 함."),bd=n(),ap=i("li"),yd=p("이 논문에서는 graph-based의 표현을 제안함"),Sd=n(),op=i("li"),Pd=p("Spark에서는 이 표현을 사용함으로써, 각각의 스케줄러에 특별한 논리를 추가하지 않고 광범위한 transformation을 지원함"),$d=n(),fp=i("li"),Ad=p("시스템 설계가 매우 단순화됨"),cD=n(),Wi=i("p"),hd=p("각각의 RDD는 아래와 같은 정보를 노출하는 공통적인 인터페이스로 나타낼 수 있음"),dD=n(),B=i("ol"),pp=i("li"),xd=p("partition의 집합 (dataset의 atomic pieces)"),wd=n(),sp=i("li"),Md=p("Parent RDD에 대한 종속성(dependency) 집합"),Hd=n(),np=i("li"),Ud=p("Parent RDD를 기반으로 dataset을 계산하는 함수"),Cd=n(),Vi=i("li"),jd=p("partitioning scheme 및 데이터 배치에 대한 메타데이터"),Re=i("ul"),Zi=i("li"),Bd=p("해당 인터페이스는 아래와 같은 테이블에서 보여줌  "),v(jt.$$.fragment),Nd=n(),up=i("li"),Fd=p("예를 들면, HDFS 파일을 표현하는 RDD는 파일의 각 블록마다 partition을 가지고 있고 어떤 machine의 블록에 올라가 있는지 정보를 알고 있음"),zd=n(),Dp=i("li"),Od=p("한편 이 RDD에 map을 한 결과물은 동일한 partition을 가지지만, 요소를 계산할 때 parent data에 map 함수를 적용한다."),RD=n(),v(Bt.$$.fragment),LD=p(`
RDD간의 종속성(Dependency)를 나타내는 인터페이스는 두 종류가 있음
`),le=i("ul"),vp=i("li"),Td=p("narrow dependency: 1개의 Parent RDD에 1개의 Child RDD가 종속"),qd=n(),mp=i("li"),Jd=p("wide dependency : 1개의 Parent RDD에 여러 개의 Child RDD가 종속될 수 있음"),Qd=n(),Ep=i("li"),Gd=p("예를 들어 map은 narrow dependency이고, join은 (parent가 hash-partitioned 되어있는 게 아니라면) wide dependency임."),ID=n(),Xi=i("p"),Kd=p("이렇게 narrow와 wide로 구분하는 게 유용한 이유가 두 가지 있음."),kD=n(),fl=i("ol"),_p=i("li"),cp=i("p"),Wd=p(`narrow dependency는 모든 parent partition을 계산할 수 있는 하나의 cluster node에서 pipelined execution이 가능함.
=> 예를 들면 각 요소마다 filter 이후 map을 적용할 수 있음
=> 반면 wide dependency에서는, MapReduce처럼 Parent Patrtition의 모든 데이터가 Child들에 Shuffle되어야 한다.`),Vd=n(),dp=i("li"),Rp=i("p"),Zd=p(`node failure 이후 회복할 때는 narrow dependency에서 더 효율적임
=> 손실이 발생한 parent partition만 회복하면 되기 때문이며, 이는 다른 노드에서 병렬적으로 재연산이 가능
=> 반면 wide dependency의 lineage graph에서는, 특정 단일 노드에서 failure가 발생하면 해당 RDD의 조상으로부터 형성된 특정 파티션을 잃어버릴 수도 있으며, 이 경우 완전히 재실행해야 할 수도 있음.`),bD=n(),Yi=i("p"),Xd=p(`Spark에서, 이러한 RDD의 공통적인 인터페이스는 대부분의 transformation을 20줄 이내로 수행할 수 있게 하였음.
아래 내용은 여러 RDD 구현이 요약된 것임`),yD=n(),gi=i("p"),Yd=p("HDFS Files"),SD=n(),N=i("ul"),Lp=i("li"),gd=p("RDD가 HDFS의 파일인 경우, partitions()는 파일의 각 블록당 한 개의 partition이 반환된다."),e4=n(),Ip=i("li"),l4=p("각 Partition 객체에 block offset이 포함되어 있다"),t4=n(),kp=i("li"),i4=p("prefferedLocation()은 블록이 존재하는 노드를 반환한다."),r4=n(),bp=i("li"),a4=p("iterator()는 블록을 읽는다."),PD=n(),er=i("p"),o4=p("map"),$D=n(),pl=i("ul"),yp=i("li"),f4=p("임의의 RDD에서 map을 호출하면 MappedRDD 객체가 반환된다"),p4=n(),Sp=i("li"),s4=p("이 객체는 parent와 동일한 partition 및 preferred location을 가지지만, Iterator()는 parent의 record와 매핑하기 위해 전달된 함수를 적용한다."),AD=n(),lr=i("p"),n4=p("union"),hD=n(),sl=i("ul"),Pp=i("li"),u4=p("두 개의 RDD에서 union을 호출하면, 각 부모의 partition이 합쳐진 partition을 가진 RDD가 반환됨"),D4=n(),$p=i("li"),v4=p("각각의 Child Partition은 parent에 대한 narrow dependency를 통해 계산됨"),xD=n(),tr=i("p"),m4=p("sample"),wD=n(),ir=i("ul"),Ap=i("li"),E4=p("sample은 map과 비슷하지만, RDD가 parent record를 deterministically하게 샘플링하기 위해 각 partition마다 random number seed를 저장한다는 차이가 있음"),MD=n(),rr=i("p"),_4=p("join"),HD=n(),$=i("ul"),hp=i("li"),c4=p("두 RDD를 join하는 연산은 세 가지 경우가 있음."),d4=n(),xp=i("li"),R4=p("두 RDD가 동일 partition에 hash/range partition된 경우(partitioner가 같은 경우), 둘 다 narrow dependency"),L4=n(),wp=i("li"),I4=p("둘 중 하나만 hash/range partition된 경우(partitioner를 가짐), narrow와 wide 혼합"),k4=n(),Mp=i("li"),b4=p("아니면, 둘 다 wide dependency임"),y4=n(),Hp=i("li"),S4=p("어떤 경우이든 결과물인 RDD는 partitioner를 가지며, parent로부터 물려받거나 default hash partitioner를 가짐"),UD=n(),CD=i("br"),jD=i("br"),BD=n(),nl=i("h2"),ul=i("a"),Up=i("span"),P4=p("Implementation"),ND=n(),FD=i("hr"),zD=n(),ar=i("p"),$4=p("Spark 시스템은 Mesos cluster manager 위에서 동작하며, Hadoop, MPI(Message Passing Interface) 등 다른 어플리케이션과 리소스를 공유할 수 있다."),OD=n(),Dl=i("ul"),Cp=i("li"),A4=p("각각의 Spark 프로그램은 driver(master)와 worker를 가진 별도의 Mesos Application으로 동작한다."),h4=n(),jp=i("li"),x4=p("애플리케이션 간의 자원 관리는 Mesos에 의해 처리된다."),TD=n(),or=i("p"),w4=p("Spark는 HDFS, HBase 등 Hadoop의 입력 소스를 통해 데이터를 읽어올 수 있다."),qD=n(),vl=i("ul"),Bp=i("li"),M4=p("기존의 Hadoop에서 사용하는 input plugin API를 사용한다."),H4=n(),Np=i("li"),U4=p("특별히 수정된 Scala 버전을 사용하지 않아도 된다."),JD=n(),ml=i("h3"),El=i("a"),Fp=i("span"),C4=p("Job Scheduling"),QD=n(),v(Nt.$$.fragment),GD=p(`  
그림에서 검정색은 이미 메모리에 올라가 있는 부분임.  
stage 1의 결과물이 이미 RAM에 올라가 있으므로, stage 3의 RDD를 얻기 위해서는 stage 2, 3만 하면 됨
`),fr=i("p"),j4=p("Spark scheduler는 4장에서 다루었던 RDD 표현을 사용한다. Spark의 scheduler는 Dryad의 scheduler와 비슷하지만, persistent RDD의 어떤 partition을 메모리에 올릴지도 고려한다."),KD=n(),A=i("ul"),zp=i("li"),B4=p("위 그림처럼, 유저가 RDD에 대한 action을 수행할 때마다 scheduler는 실행할 stage의 DAG를 만들기 위해 RDD의 lineage graph를 검사한다."),N4=n(),Op=i("li"),F4=p("DAG : Directed Acyclic Graph. Cycle이 없는 Directed Graph"),z4=n(),Tp=i("li"),O4=p("각 stage는 narrow dependency로 구성할 수 있는, 여러 transform의 파이프라인으로 구성되어 있음"),T4=n(),qp=i("li"),q4=p("각 stage를 구분하는 것은 wide dependency에 필요한 shuffle 연산 또는 parent RDD의 계산을 단순화할 수 있는 이미 계산된 partition이다."),J4=n(),Jp=i("li"),Q4=p("Scheduler는 대상 RDD가 계산될 때까지, 각 stage의 missing partition을 연산하는 작업을 생성한다."),WD=n(),pr=i("p"),G4=p("Spark의 scheduler는 delay scheduling을 사용하여, data locality에 따라 machine에 작업 할당"),VD=n(),te=i("ul"),Qp=i("li"),K4=p("만약 task가 어느 노드의 메모리에서 사용 가능한 partition을 처리해야 할 경우, 해당 노드로 보낸다."),W4=n(),Gp=i("li"),V4=p(`또는 task가 HDFS처럼 preferred location이 존재하는 RDD의 partition을 처리하는 경우, 해당 파티션으로 보냄
Wide Dependency(shuffle)의 경우, 오류 복구를 단순화하기 위해 parent partition을 보유한 노드에 있는 intermediate record를 materialize함.`),Z4=n(),Kp=i("li"),X4=p("MapReduce가 map output을 materialize하는 것과 유사"),ZD=n(),_l=i("ol"),Wp=i("li"),Y4=p("만약 task가 failure하면, 해당 stage의 parent가 살아있는 한 다른 node에서 작업을 다시 실행함."),g4=n(),sr=i("li"),e5=p("만약 특정 stage 자체를 사용할 수 없는 경우(예를 들면 shuffle 중 map side의 출력값이 손실된 경우), 병렬적으로 missing partition을 계산하기 위해 task를 다시 전송한다."),Vp=i("ul"),Zp=i("li"),l5=p("RDD linage graph를 replicating하는 것은 간단하지만, scheduler 실패는 아직 핸들링하기 어려움"),XD=n(),nr=i("p"),t5=p("Spark의 모든 연산은 driver 프로그램에서 action이 호출되면 그에 따라 실행됨"),YD=n(),cl=i("ul"),Xp=i("li"),i5=p("하지만 map과 같은 cluster의 작업이 조회 작업을 호출하도록 하여, hash-partition된 RDD의 요소에 key값을 통해 random access할 수 있게 하는 실험도 하고 있음"),r5=n(),Yp=i("li"),a5=p("이 경우, task는 scheduler에게 필요한 partition이 missing 상태일 경우 이를 계산하게끔 지시해야 함."),gD=n(),dl=i("h3"),Rl=i("a"),gp=i("span"),o5=p("Interpreter Integration"),e2=n(),ur=i("p"),f5=p("Scala는 Python이나 Ruby처럼 interactive shell을 제공함"),l2=n(),Dr=i("ul"),es=i("li"),p5=p("데이터를 in-memory로 처리하여 latency가 낮기 때문에, 사용자는 Spark Interpreter를 통해 interactive하게 많은 양의 데이터에 query를 날릴 수 있음"),t2=n(),vr=i("p"),s5=p("Scala interpreter는 사용가 입력한 클래스가 있는 라인을 컴파일하여 JVM에 로드하고, 그 위에서 함수를 호출함."),i2=n(),F=i("ul"),ls=i("li"),n5=p("이러한 클래스는 그 라인에서 선언된 변수나 함수를 포함하며, initialize method로 그 라인을 실행하는 singleton object를 포함함."),u5=n(),ts=i("li"),D5=p("singleton object : class의 instance가 오직 1개만 생성됨"),v5=n(),is=i("li"),m5=p("예를 들면, 만약 유저가 var x = 5를 입력하고 그 다음 println(x)를 입력했다고 가정"),E5=n(),rs=i("li"),_5=p("인터프리터는 x를 포함하는 Line1이라는 클래스를 만들고, println(Line1.getInstance().x)로 컴파일"),r2=n(),mr=i("p"),c5=p("Spark interpreter에서는 두 가지의 변화를 줬음"),a2=n(),Ll=i("ol"),as=i("li"),d5=p("Class Shipping: worker 노드가 각 라인에 선언된 클래스의 바이트 코드를 읽어올 수 있게끔, interpreter는 이런 클래스를 HTTP로 전송함."),R5=n(),Er=i("li"),L5=p("수정된 코드 생성: 일반적으로 코드의 각 라인마다 생성된 Singleton Object는 해당 클래스의 static method를 통해 접근함."),Ft=i("ul"),os=i("li"),I5=p("위 예제(Line1.getInstance().x)처럼 이전 라인에서 정의된 변수를 참조하는 closure를 serialize할 때, Java는 object graph를 추적하여 x를 감싸는 Line1 인스턴스를 전달하지 않음. 따라서 worker 노드는 x를 받지 않을 것임."),k5=n(),fs=i("li"),b5=p("code generation logic을 수정하여, 참조를 하려고 할 시 각 라인의 object의 instance를 직접 참조하게끔 변경하였음"),o2=n(),v(zt.$$.fragment),f2=p(`  
위 그림은 사용자가 입력한 라인을 interpreter가 어떻게 해석하는지 보여줌
`),_r=i("p"),y5=p("Spark interpreter를 쓰면 HDFS에 저장된 dataset을 탐색하거나, trace를 추적(아마 lineage graph?)하는데 유용하다는 것을 발견하였음."),p2=n(),Il=i("h3"),kl=i("a"),ps=i("span"),S5=p("Memory Management"),s2=n(),cr=i("p"),P5=p("Spark는 persistent RDD를 저장하기 위한 세 가지 옵션을 제공한다."),n2=n(),ie=i("ol"),dr=i("li"),$5=p("in-memory storage - deserialized Java object"),ss=i("ul"),ns=i("li"),A5=p("JVM이 RDD 요소를 native하게 접근할 수 있기 때문에 가장 빠름"),h5=n(),Rr=i("li"),x5=p("in-memory storage – serialized data"),us=i("ul"),Ds=i("li"),w5=p("Java의 object graph보다 메모리 측면에서는 효율적이지만, 성능은 감소"),M5=n(),Lr=i("li"),H5=p("on-disk storage"),vs=i("ul"),ms=i("li"),U5=p("RDD가 너무 커서 RAM에 저장하기엔 너무 크지만 사용할 때마다 재계산하기에는 비용이 너무 많이 드는 RDD에 유용함"),u2=n(),Ir=i("p"),C5=p("사용 가능한 메모리는 제한적이므로, RDD 레벨에서 LRU 제거 정책을 사용함."),D2=n(),z=i("ul"),Es=i("li"),j5=p("새로운 RDD Partition이 계산될 때 이를 저장할 공간이 충분치 않다면, 가장 예전에 access된 RDD를 쫓아냄."),B5=n(),_s=i("li"),N5=p("예외적으로, 새로운 partition이 있는 RDD와 동일한 RDD는 쫓아내지 않는데, cycling partition이 일어나지 않게끔 하기 위함"),F5=n(),cs=i("li"),z5=p("대부분의 작업은 RDD 전체에서 수행되기 때문에, 이는 굉장히 중요함. 이미 메모리에 있는 파티션이 미래에 필요할 가능성이 높음."),O5=n(),ds=i("li"),T5=p("메모리 관리 정책의 기본값인 이 방식도 잘 동작하지만, 사용자는 각 RDD에 persistence priority를 부여하여 제어할 수도 있음."),v2=n(),bl=i("h3"),yl=i("a"),Rs=i("span"),q5=p("Support for Checkpointing"),m2=n(),kr=i("p"),J5=p("RDD가 failure한 이후 lineage를 통해 복구할 수 있지만, lineage chain이 너무 길면 복구 과정에서 시간이 너무 오래 걸릴 수 있음"),E2=n(),br=i("ul"),Ls=i("li"),Q5=p("RDD를 stable storage에 checkpointing하면 유용함"),_2=n(),yr=i("p"),G5=p("일반적으로 Checkpoint는 wide dependency를 포함하는, 긴 lineage graph의 RDD에 대해 유용함"),c2=n(),re=i("ul"),Is=i("li"),K5=p("만약 이 경우 클러스터 안의 노드의 falilure는 각각의 parent RDD로부터 온 데이터 조각의 손실로 이어질 수 있음. 이 경우 모든 데이터를 다시 계산해야 함"),W5=n(),ks=i("li"),V5=p("반면 narrow dependency의 경우에는, Checkpointing이 불필요함."),Z5=n(),bs=i("li"),X5=p("노드가 실패하여 lost partition을 계산하려면 전체 RDD를 복제하는 비용의 극히 일부만으로 다른 노드에서 병렬적으로 재계산할 수 있기 때문"),d2=n(),Sr=i("p"),Y5=p("Spark는 (persist() method의 REPLICATE flag 등) checkpointing API를 제공함."),R2=n(),Sl=i("ul"),ys=i("li"),g5=p("다만 어떤 데이터를 checkpointing할지는 유저가 결정"),eR=n(),Ss=i("li"),lR=p("시스템 복구 시간을 최소화할 수 있도록 자동으로 checkpointing하는 방법을 연구 중에 있음"),L2=n(),Pr=i("p"),tR=p("RDD의 read-only라는 특성 덕에 일반적인 shared memory보다 checkpointing하기 쉬움."),I2=n(),Pl=i("ul"),Ps=i("li"),iR=p("data consistency를 고려할 필요가 없음"),rR=n(),$s=i("li"),aR=p("checkpointing을 background에서 진행하면서, 작동중인 프로그램을 멈추거나 특별한 분산 스냅샷 스키마를 사용할 필요가 없음. (동시에 가능)"),k2=n(),b2=i("br"),y2=i("br"),S2=n(),$l=i("h2"),Al=i("a"),As=i("span"),oR=p("Evaluation"),P2=n(),$2=i("hr"),A2=n(),$r=i("p"),fR=p("EC2에 올려서 Spark와 RDD, 및 이를 사용하는 User Application의 성능을 검사하였음"),h2=n(),O=i("ol"),Ar=i("li"),pR=p("스파크는 반복적인 기계 학습 및 그래프 애플리케이션에서 하둡을 최대 20배 능가함"),hs=i("ul"),xs=i("li"),sR=p("데이터를 자바 객체로 메모리에 저장함으로써 입출력 및 역직렬화 비용을 피할 수 있기 때문에 속도가 향상된다."),nR=n(),hr=i("li"),uR=p("사용자가 작성한 애플리케이션에 올라간 Spark는 성능과 확장성이 뛰어나다."),ws=i("ul"),Ms=i("li"),DR=p("analytics report 할 때 하둡보다 40배 빨랐음"),vR=n(),Hs=i("li"),mR=p("노드에 장애가 발생하면 스파크는 손실된 RDD 파티션만 재구성하여 신속하게 복구할 수 있다."),ER=n(),Us=i("li"),_R=p("스파크는 1TB 데이터 세트를 5-7초의 지연시간(latency)으로 대화식(interactively)으로 쿼리하는 데 사용할 수 있다"),x2=n(),hl=i("h3"),xl=i("a"),Cs=i("span"),cR=p("Iterative Machine Learning Applications"),w2=n(),v(Ot.$$.fragment),M2=n(),ae=i("ul"),js=i("li"),dR=p("Logistic Regression: I/O 및 serialization sensitive"),RR=n(),Bs=i("li"),LR=p("K-Means: compute-intensive"),IR=n(),xr=i("li"),kR=p("HadoopBinMem"),Tt=i("ul"),Ns=i("li"),bR=p("input data를 binary format으로 바꾸는 hadoop 버전"),yR=n(),Fs=i("li"),SR=p("데이터를 in-memory HDFS 인스턴스에 저장"),H2=n(),wr=i("p"),PR=p("그림 7의 First iteration: HadoopBM > Hadoop > Spark"),U2=n(),oe=i("ul"),zs=i("li"),$R=p("HadoopBM : 데이터를 binary로 바꾸는 추가적인 작업 및 in-memory HDFS를 replicate하는 overhead로 인해 가장 느림"),AR=n(),Os=i("li"),hR=p("Hadoop : heartbeat를 보내기 위한 Signaling overhead로 인해 Spark보다 느림"),xR=n(),Ts=i("li"),wR=p("Spark: 이후의 Iteration부터는 RDD로 인해 데이터가 reuse되어 빨라짐"),C2=n(),Mr=i("p"),MR=p("그림 8: 그냥 machine 수 달리해서 재 본거임. 역시 spark가 제일 빠름"),j2=n(),Hr=i("p"),HR=p("하둡이 느린 이유"),B2=n(),fe=i("ol"),qs=i("li"),UR=p(`하둡의 소프트웨어 스택의 오버헤드
=> 하둡은 job을 수행할 때 job 설정, task 시작, 정리 등의 overhead 등으로 인해, 최소 25초의 오버헤드가 발생`),CR=n(),Js=i("li"),jR=p(`데이터를 서빙할 때 HDFS의 오버헤드
=> HDFS는 여러 개의 메모리 복사본을 각 블록에 전송하며, 각 블록에 체크섬을 수행하기 때문에 오버헤드 발생`),BR=n(),Qs=i("li"),NR=p("binary record를 Java object로 변경하기 위한 deserialization 비용"),N2=n(),v(qt.$$.fragment),F2=p(`  
Text – binary 시간 차이 : parsing에 소요되는 시간
`),wl=i("ul"),Gs=i("li"),FR=p("Hadoop은 binary data를 Java object로 변환하는데 시간이 필요함"),zR=n(),Ks=i("li"),OR=p("Spark는 RDD 요소를 메모리에 Java object로 바로 저장하므로, 오버헤드를 회피함"),z2=n(),Ml=i("h3"),Hl=i("a"),Ws=i("span"),TR=p("PageRank"),O2=n(),v(Jt.$$.fragment),T2=p(`  
PageRank에서도 Spark가 빠르게 나옴
`),Ul=i("ul"),Vs=i("li"),qR=p("Controlled Partitioning을 해주면, data access가 일관되게 일어나기 때문에 속도를 향상시킬 수 있다"),JR=n(),Zs=i("li"),QR=p("또한 Pregel에서 PageRank를 돌려도, Pregel은 추가적인 연산을 하기 때문에 Spark의 버전보다 4초정도 더 길게 나옴."),q2=n(),Cl=i("h3"),jl=i("a"),Xs=i("span"),GR=p("Fault Recovery"),J2=n(),v(Qt.$$.fragment),Q2=p(`  
K-means를 돌릴 때 failure가 발생한 경우 recovery에 얼마나 시간이 걸리는지 보여줌
`),pe=i("ul"),Ys=i("li"),KR=p("6번째 iteration에서 machine 하나 죽여서, 그 machine에서 돌아가는 task가 실패"),WR=n(),gs=i("li"),VR=p("다른 machone에서 task를 다시 실행"),ZR=n(),en=i("li"),XR=p("해당 task의 input data와 RDD lineage를 다시 읽고, RDD Partition을 재구성"),G2=n(),Ur=i("p"),YR=p("checkpoint 기반의 장애 복구 메커니즘은 체크포인트 빈도에 따라 작업을 여러번 반복해야 할수도 있음"),K2=n(),se=i("ul"),ln=i("li"),gR=p("또한 시스템은 네트워크를 통해 대용량의 working set을 replicate해야 함"),e6=n(),tn=i("li"),l6=p("이를 RAM에 복제하면 Spark의 두 배 메모리를 쓰는 거고, DISK에 복제하면 대용량의 데이터를 쓰는 것을 기다려야 함"),t6=n(),rn=i("li"),i6=p("Spark의 RDD lineage graph는 크기가 10kb 미만"),W2=n(),Bl=i("h3"),Nl=i("a"),an=i("span"),r6=p("Behavior with Insufficient Memory"),V2=n(),v(Gt.$$.fragment),Z2=p(`  
성능이 감소되긴 하지만 Graceful하게(어느정도 하락폭을 예측할 수 있게) 감소됨
`),Fl=i("h3"),zl=i("a"),on=i("span"),a6=p("User Applications Built with Spark"),X2=n(),Cr=i("p"),o6=p("In-memory Analytics:"),Y2=n(),jr=i("ul"),Br=i("li"),f6=p("영상 배포하는 Conviva Inc라는 회사는 analytic report를 만들기 위해 하둡을 쓰다가 Spark를 사용"),fn=i("ul"),pn=i("li"),p6=p("40배 빨라짐"),g2=n(),v(Kt.$$.fragment),ev=n(),Nr=i("p"),s6=p("Traffic Modeling:"),lv=n(),Fr=i("ul"),zr=i("li"),n6=p("산발적으로 수집된 자동차 GPS 측정치에서 교통 현황을 추정하기 위한 학습 알고리즘을 병렬적으로 구성함."),sn=i("ul"),nn=i("li"),u6=p("두 개의 map과 reduceByKey를 반복적으로 적용하여 모델을 학습시켰고, 성능이 선형적으로 확장됨 (분산처리가 잘 되고 있음)"),tv=n(),Or=i("p"),D6=p("Twitter Spam Classification:"),iv=n(),Tr=i("ul"),qr=i("li"),v6=p("트위터의 스팸 메시지에서 link를 검증하기 위해 Spark 사용"),Le=i("ul"),un=i("li"),m6=p("앞서 봤던 logistic regression를 사용하였고, URL이 가리키는 페이지 정보를 수집함."),E6=n(),Dn=i("li"),_6=p("성능이 linear하게 늘어나지는 않았음 (communication cost가 iteration보다 높아지기 때문)"),c6=n(),vn=i("li"),d6=p("아마 네트워크에 접속해서 페이지 정보를 읽어와야 하기 때문인 듯"),rv=n(),Ol=i("h3"),Tl=i("a"),mn=i("span"),R6=p("Interactive Data Mining"),av=n(),v(Wt.$$.fragment),ov=p(`  
Spark는 거대한 dataset에 대화식 query를 날릴 수 있음
`),ne=i("ul"),En=i("li"),L6=p("(1) => 전체 페이지에 query하여 조회수 확인"),I6=n(),_n=i("li"),k6=p("(2) => 제목이 주어진 단어와 같은 페이지만 조회수 확인"),b6=n(),Jr=i("li"),y6=p("(3) => 제목이 부분적으로 일치하는 페이지만 조회수 확인"),cn=i("ul"),dn=i("li"),S6=p("response time이 on-disk에서 하는 것보다 훨씬 빠름 (on-disk는 170초 걸렸다고 함)"),fv=n(),pv=i("br"),sv=i("br"),nv=n(),ql=i("h2"),Jl=i("a"),Rn=i("span"),P6=p("Discussions"),uv=n(),Dv=i("hr"),vv=n(),Qr=i("p"),$6=p("RDD는 immutable하고 coarse-grained transformation을 하므로, 제한된 interface만을 제공하는 것처럼 보이지만, 다양한 application에 적합함"),mv=n(),Ql=i("h3"),Gl=i("a"),Ln=i("span"),A6=p("Expressing Existing Programming Models"),Ev=n(),Gr=i("p"),h6=p("RDD는 지금까지 제안되어 온 다양한 클러스터 프로그래밍 모델을 “효율적으로” 표현할 수 있음"),_v=n(),Kl=i("ul"),In=i("li"),x6=p("효율적이라는 말은, 단순히 이러한 모델로 작성한 프로그램과 동일한 output을 얻을 수 있을 뿐 아니라, 최적화까지 가능함."),w6=n(),kn=i("li"),M6=p("데이터를 memory에 보관하고, communication을 minimize하기 위해 잘 partitioning하고, failure를 효율적으로 recovery함"),cv=n(),Kr=i("p"),H6=p("RDD로 표현 가능한 모델"),dv=n(),T=i("ul"),bn=i("li"),U6=p("MapReduce: flatMap, GroupByKey, reduceByKey가 각각 Mapper, Reducer, Combiner에 해당"),C6=n(),yn=i("li"),j6=p("DryadLINQ: Spark로도 할 수 있음"),B6=n(),Sn=i("li"),N6=p("SQL: SQL query를 날려서 data-parallel operation을 수행할 수 있음"),F6=n(),Wr=i("li"),z6=p("Pregel: Google Pregel은 iterative graph application에 특화된 모델임"),Pn=i("ul"),$n=i("li"),O6=p("RDD를 사용하면 Pregel이 하는 것처럼 vertex state를 메모리에 유지하고, Partitioning을 제어하고, 통신을 최소화하고, 장애 시 부분적인 복구를 수행할 수 있다."),Rv=n(),Vr=i("p"),T6=p("Iterative MapReduce"),Lv=n(),q=i("ul"),An=i("li"),q6=p("HaLoop 및 Twister 등 MapReduce를 Iterative하게 돌리기 위한 시스템이 있음"),J6=n(),hn=i("li"),Q6=p(`얘네의 핵심은 partitioning 및 메모리에 올려놓고 reuse하는 것인데, 이것도 Spark 200줄로 표현이 가능했음
Batched Stream Processing`),G6=n(),xn=i("li"),K6=p("새로운 데이터를 받아서 주기적으로 결과를 업데이트하는 점진적인 시스템"),W6=n(),wn=i("li"),V6=p("Intermediate state를 RDD로 두면 처리 속도가 향상됨."),Iv=n(),Zr=i("p"),Z6=p("RDD가 이렇게 다양한 프로그래밍 모델을 표현할 수 있는 이유는, RDD의 제약조건이 다수의 병렬 어플리케이션에서 큰 의미가 없기 때문임."),kv=n(),J=i("ul"),Mn=i("li"),X6=p("RDD는 오직 transformation을 거쳐서 생성될 수 있음"),Y6=n(),Hn=i("li"),g6=p("근데 대부분의 병렬 프로그램이 표현을 쉽게 하려고 원래 동일한 연산을 record에 적용하고 있음."),e7=n(),Un=i("li"),l7=p("동일한 dataset의 버전을 나타내기 위해 여러 개의 RDD를 생성할 수 있기 때문에, RDD의 immutability는 장애물이 아님."),t7=n(),Cn=i("li"),i7=p("실제로, 대부분의 MapReduce 애플리케이션은 HDFS 등 파일 업데이트를 허용하지 않는 파일 시스템에서 실행됨."),bv=n(),Xr=i("p"),r7=p("이전 프레임워크들은 데이터 공유를 위한 abstraction이 부족했기 때문에 이런 범용성을 가지지 못한 것 같음"),yv=n(),Wl=i("h3"),Vl=i("a"),jn=i("span"),a7=p("Leveraging RDDs for Debugging"),Sv=n(),Yr=i("p"),o7=p("DD는 fault tolerance를 위해 deterministical하게 다시 계산할 수 있게끔 설계되었지만, 이러한 특성 덕분에 디버깅도 잘함"),Pv=n(),gr=i("ul"),Bn=i("li"),f7=p("작업 중 RDD의 lineage를 기록함으로써, RDD를 나중에 재구성하여 사용자가 대화식으로 query할 수 있고, RDD 종속된 파티션을 다시 계산하여 단일 프로세스 디버거에서 job의 모든 task를 다시 실행할 수 있음"),$v=n(),ea=i("p"),p7=p("여러 노드에서 이벤트 순서를 캡쳐해야 하는 기존의 general distributed system에서의 replay debugger와는 달리, 이 방식은 RDD lineage graph만을 기록하기 때문에 recording overhead가 거의 없음."),Av=n(),hv=i("br"),xv=i("br"),wv=n(),Zl=i("h2"),Xl=i("a"),Nn=i("span"),s7=p("Related Work"),Mv=n(),Hv=i("hr"),Uv=n(),la=i("p"),n7=p("Cluster Programming Models:"),Cv=n(),Q=i("ol"),Vt=i("li"),Fn=i("p"),u7=p("data flow model"),D7=n(),Zt=i("ul"),zn=i("li"),v7=p("MapReduce, Dryad, Ciel 등은 데이터 프로세싱을 위한 다양한 Operator 제공"),m7=n(),On=i("li"),E7=p("반면 RDD는 data replication, I/O 및 serization의 높은 비용을 피하기 위해 stable storage보다 더 효율적인 abstraction을 제공함."),_7=n(),Xt=i("li"),Tn=i("p"),c7=p("High level programming interface for data flow system"),d7=n(),Ie=i("ul"),qn=i("li"),R7=p("DryadLINQ, FlumeJava는 사용자가 map, join 등의 연산자로 parallel collection에 접근할 수 있는 language-integrated API를 제공"),L7=n(),Jn=i("li"),I7=p("하지만 이러한 시스템들은 query의 결과를 다른 query로 pipeline하기 어려움"),k7=n(),Qn=i("li"),b7=p("Spark는 이것이 가능하기 때문에, 다양한 Application에서 활용할 수 있음"),y7=n(),Yt=i("li"),Gn=i("p"),S7=p("Pregel, HaLoop, Twister 등은 generic abstraction을 제공하지 않아서 정해진 용도 이외의 용도로 사용하기 어려움."),P7=n(),Kn=i("ul"),Wn=i("li"),$7=p("RDD는 distributed storage abstraction을 제공하여, interactive data mining 등 위의 시스템이 하기 어려운 것도 가능함"),A7=n(),gt=i("li"),Vn=i("p"),h7=p("Piccolo나 RAMCloud 등의 Distributed Shared Memory 기반의 시스템은 사용자가 in-memory computation을 수행할 수 있게끔, shared mutable state를 노출시킴."),x7=n(),ke=i("ul"),Zn=i("li"),w7=p("RDD는 두 가지 측면에서 이러한 시스템과 다름"),M7=n(),Xn=i("li"),H7=p("RDD는 map, sort, join 등 high level interface를 제공하는 반면, 위의 애들은 table cell에 대한 read/update밖에 지원하지 않음"),U7=n(),Yn=i("li"),C7=p("RDD는 Lineage based라서, 위 애들보다 checkpoint 및 rollback이 덜 무거움"),jv=n(),Yl=i("p"),j7=p("Caching System:"),B7=i("br"),N7=p(`
Nectar는 DryadLINQ 작업에서 intermediate data를 재사용할 수 있음.`),Bv=n(),G=i("ul"),gn=i("li"),F7=p("RDD에서도 이러한 능력을 본땄음"),z7=n(),eu=i("li"),O7=p("근데 Nectar는 in-memory caching을 제공하지 않고, 사용자가 원하는 dataset을 persist 및 partitioning control하게끔 하는 기능이 없음."),T7=n(),lu=i("li"),q7=p("CIel 및 FlumeJava는 in-memory로 caching을 지원하지 않고, 원하는 데이터를 caching할 수 없음"),J7=n(),tu=i("li"),Q7=p("분산 파일 시스템에 대한 인메모리 캐시도 제시되었지만, RDD처럼 중간 결과를 sharing하는 것보다는 약간 모자람"),Nv=n(),gl=i("p"),G7=p("Lineage:"),K7=i("br"),W7=p(`
Lineage를 capture하는 것은 오랜 연구 주제였음.`),Fv=n(),ue=i("ul"),iu=i("li"),V7=p("RDD는 fine-grained lineage를 capture하는 데 비용이 적게 드는 병렬 프로그래밍 모델을 제공하여, 장애 복구에 사용할 수 있도록 함."),Z7=n(),ru=i("li"),X7=p("이러한 lineage based의 회복 매커니즘은 MapReduce나 Dryad의 메커니즘하고 비슷하지만, 얘네들은 job이 끝나면 lineage를 잃어버리므로, 컴퓨팅 간에 데이터를 공유하려면 replicated storage를 사용해야 함"),Y7=n(),au=i("li"),g7=p("반면 RDD는 disk I/O나 replication 없이 lineage를 써서, 데이터가 메모리에 지속되게 하여 효율적으로 데이터를 공유할 수 있음."),zv=n(),et=i("p"),eL=p("Relational Database:"),lL=i("br"),tL=p(`
RDMS는 fine-grained이며 모든 record에 대한 read/write 접근을 허용함. 또한 fault tolerance, logging operation, consistency를 유지해야 함`),Ov=n(),ta=i("ul"),ou=i("li"),iL=p("반면 RDS는 coarse-grained이므로 이런거 할 필요가 없음"),Tv=n(),qv=i("br"),Jv=i("br"),Qv=n(),lt=i("h2"),tt=i("a"),fu=i("span"),rL=p("Conclusion"),Gv=n(),Kv=i("hr"),Wv=n(),ia=i("p"),aL=p("RDD : cluster application에서 데이터를 sharing하는 abstraction"),Vv=n(),ra=i("ul"),pu=i("li"),oL=p("효율적인, general-purpose, fault-tolerance를 제공"),Zv=n(),aa=i("p"),fL=p("RDD는 다양한 종류의 병렬 application을 표현할 수 있음"),Xv=n(),oa=i("ul"),su=i("li"),pL=p("iterative computation을 위해 제안된 많은 특화된 프로그래밍 모델과, 이러한 모델이 캡처하지 못하는 새로운 응용 프로그램 등 다양한 병렬 애플리케이션을 표현할 수 있음."),Yv=n(),fa=i("p"),sL=p("fault tolerance를 위해 data replicating을 선택하는 기존 cluster의 storage abstraction과는 달리, RDD는 coarse-grained transformation 기반의 API를 제공"),gv=n(),pa=i("ul"),nu=i("li"),nL=p("lineage를 통해 효율적으로 recover 가능"),em=n(),sa=i("p"),uL=p(`RDD가 구현된 시스템인 Spark의 성능은 interactive application에서 Hadoop보다 20배 뛰어남.
또한 100기가바이트 대의 데이터에 대화형 쿼리를 날릴 수도 있다.`),this.h()},l(e){y=r(e,"H2",{id:!0});var o=a(y);S=r(o,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var uu=a(S);Rt=r(uu,"SPAN",{class:!0}),a(Rt).forEach(l),uu.forEach(l),Jm=s(o,"Abstraction"),o.forEach(l),mu=u(e),ei=r(e,"P",{});var s0=a(ei);Qm=s(s0,"RDD(Resilient Distributed Datasets)"),s0.forEach(l),Eu=u(e),k=r(e,"UL",{});var K=a(k);Ua=r(K,"LI",{});var n0=a(Ua);Ca=r(n0,"P",{});var u0=a(Ca);Gm=s(u0,"Resilient : 메모리 내부에서 데이터가 손실 시 유실된 파티션을 재연산해 복구할 수 있다."),u0.forEach(l),n0.forEach(l),Km=u(K),ja=r(K,"LI",{});var D0=a(ja);Ba=r(D0,"P",{});var v0=a(Ba);Wm=s(v0,"Distributed : 스파크 클러스터를 통하여 메모리에 분산되어 저장된다."),v0.forEach(l),D0.forEach(l),Vm=u(K),Lt=r(K,"LI",{});var tm=a(Lt);Na=r(tm,"P",{});var m0=a(Na);Zm=s(m0,"Data : 파일, 정보 등등"),m0.forEach(l),Xm=u(tm),It=r(tm,"UL",{});var im=a(It);Fa=r(im,"LI",{});var E0=a(Fa);Ym=s(E0,"분산 메모리 abstraction"),E0.forEach(l),gm=u(im),za=r(im,"LI",{});var _0=a(za);eE=s(_0,"fault-tolerant하게 in-memory computation 가능해짐"),_0.forEach(l),im.forEach(l),tm.forEach(l),lE=u(K),Oa=r(K,"LI",{});var c0=a(Oa);Ta=r(c0,"P",{});var d0=a(Ta);tE=s(d0,"iterative한 작업이나 interactive data mining 작업의 경우 in-memory로 하면 성능 향상"),d0.forEach(l),c0.forEach(l),iE=u(K),qa=r(K,"LI",{});var R0=a(qa);Ja=r(R0,"P",{});var L0=a(Ja);rE=s(L0,"shared memory의 제약된 형태로 fine-grained보단 course-grained 사용함"),L0.forEach(l),R0.forEach(l),aE=u(K),Qa=r(K,"LI",{});var I0=a(Qa);Ga=r(I0,"P",{});var k0=a(Ga);oE=s(k0,"Spark에서는 이 RDD를 사용하여 다양한 형태의 user application이나 computation에서 적용 가능"),k0.forEach(l),I0.forEach(l),K.forEach(l),_u=u(e),cu=r(e,"BR",{}),du=r(e,"BR",{}),Ru=u(e),be=r(e,"H2",{id:!0});var DL=a(be);ye=r(DL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var b0=a(ye);Ka=r(b0,"SPAN",{class:!0}),a(Ka).forEach(l),b0.forEach(l),fE=s(DL,"Introduce"),DL.forEach(l),Lu=u(e),Iu=r(e,"HR",{}),ku=u(e),li=r(e,"P",{});var y0=a(li);pE=s(y0,"MapReduce나 Dryad 등 데이터 분석 도구 특징"),y0.forEach(l),bu=u(e),W=r(e,"UL",{});var na=a(W);Wa=r(na,"LI",{});var S0=a(Wa);sE=s(S0,"fault tolerant나 work distribution에 대한 걱정 없이 High level operator를 통해 분산 환경에서 parallel computation 허용함"),S0.forEach(l),nE=u(na),Va=r(na,"LI",{});var P0=a(Va);uE=s(P0,"즉, 얘네들은 분산된 resource에 접근하는 abstraction임"),P0.forEach(l),DE=u(na),Za=r(na,"LI",{});var $0=a(Za);vE=s($0,"근데 분산된 메모리를 활용하기 위한 abstraction은 부족함"),$0.forEach(l),na.forEach(l),yu=u(e),ti=r(e,"P",{});var A0=a(ti);mE=s(A0,"data reuse 측면"),A0.forEach(l),Su=u(e),w=r(e,"UL",{});var it=a(w);Xa=r(it,"LI",{});var h0=a(Xa);EE=s(h0,"iterative한 작업(머신 러닝, 그래프 알고리즘 등)이나 interactive data mining 작업을 할 때, computation 사이에서 데이터를 reuse하는 유일한 방법은 intermediate data를 external stable storage에 저장하는 것임. (이런 애들은 reuse 자주 함)"),h0.forEach(l),_E=u(it),Ya=r(it,"LI",{});var x0=a(Ya);cE=s(x0,"data replication, disk I/O, serialization 등 execution time 큰 것들로 인해 overhead 발생함"),x0.forEach(l),dE=u(it),ga=r(it,"LI",{});var w0=a(ga);RE=s(w0,"intermediate data를 메모리에 저장해서 reuse하는, Pregel과 HaLoop이라는 애들이 나오긴 했음. 근데 얘네들은 오직 특정한 형태의 computation pattern만 지원함"),w0.forEach(l),LE=u(it),eo=r(it,"LI",{});var M0=a(eo);IE=s(M0,"general하게 reuse할 수 있는 abstraction은 없음"),M0.forEach(l),it.forEach(l),Pu=u(e),ii=r(e,"P",{});var H0=a(ii);kE=s(H0,"RDD는 다양한 application에서 data reuse를 가능하게 함"),H0.forEach(l),$u=u(e),V=r(e,"UL",{});var ua=a(V);lo=r(ua,"LI",{});var U0=a(lo);bE=s(U0,"intermediate data를 메모리에 저장할 수 있는 fault tolerant, parallel 데이터 구조"),U0.forEach(l),yE=u(ua),to=r(ua,"LI",{});var C0=a(to);SE=s(C0,"최적화되게끔 partitioning을 제어하거나 다양한 operator를 사용해서 데이터를 조작할 수 있음."),C0.forEach(l),PE=u(ua),io=r(ua,"LI",{});var j0=a(io);$E=s(j0,"adhoc query를 돌릴 수도 있다."),j0.forEach(l),ua.forEach(l),Au=u(e),ri=r(e,"P",{});var B0=a(ri);AE=s(B0,"기존에 존재하는 클러스터 단위의 in-memory storage abstraction(distributed shared memory, key-value store, database, Piccolo)는 mutable state를 fine grade로 나누었음(ex. cells in table)"),B0.forEach(l),hu=u(e),Se=r(e,"UL",{});var rm=a(Se);ro=r(rm,"LI",{});var N0=a(ro);hE=s(N0,"이런 방식에서 fault-tolerance를 제공하려면 machine들 사이에서 1. replication을 저장하거나, 2. log update를 해야 함."),N0.forEach(l),xE=u(rm),ao=r(rm,"LI",{});var F0=a(ao);wE=s(F0,"이러한 방식은 상당한 양의 data-intensive workload가 발생하며, 데이터들이 cluster network를 통해 복사됨. cluster network의 bandwidth는 RAM보다 훨씬 별로라서, overhead가 발생함"),F0.forEach(l),rm.forEach(l),xu=u(e),ai=r(e,"P",{});var z0=a(ai);ME=s(z0,"반면 RDD에서는 이런 시스템과는 달리, 많은 데이터 항목에 동일하게 operation을 적용 가능한 course-grained 기반의 정보 교환(map, filter, join 등)을 함"),z0.forEach(l),wu=u(e),M=r(e,"UL",{});var rt=a(M);oo=r(rt,"LI",{});var O0=a(oo);HE=s(O0,"실제 데이터가 아닌, dataset(lineage)을 만들 때 사용되는 transformation을 logging함으로써, fault tolerance 제공"),O0.forEach(l),UE=u(rt),fo=r(rt,"LI",{});var T0=a(fo);CE=s(T0,"lineage chain이 점점 커지면 데이터 자체를 checkpointing하는 게 유용할 때도 있음"),T0.forEach(l),jE=u(rt),po=r(rt,"LI",{});var q0=a(po);BE=s(q0,"만약 RDD의 partition을 손실한다고 해도, RDD에서는 그 partition이 다른 RDD로부터 어떻게 생겨났는지에 대한 정보를 가지고 있음. 따라서 그 파티션을 recompute함"),q0.forEach(l),NE=u(rt),so=r(rt,"LI",{});var J0=a(so);FE=s(J0,"따라서 손실된 데이터는 (비싼 data replication을 하지 않고도) 빠르게 복구될 수 있음"),J0.forEach(l),rt.forEach(l),Mu=u(e),oi=r(e,"P",{});var Q0=a(oi);zE=s(Q0,"coarse-grained transformation 기반의 인터페이스가 처음에는 너무 제약된 형태로 보일 순 있지만, RDD는 다양한 병렬 application에 적합함."),Q0.forEach(l),Hu=u(e),Pe=r(e,"UL",{});var am=a(Pe);no=r(am,"LI",{});var G0=a(no);OE=s(G0,"이러한 application은 여러 data item에 동일한 operation을 적용하는 경향"),G0.forEach(l),TE=u(am),uo=r(am,"LI",{});var K0=a(uo);qE=s(K0,"실제로, RDD는 MapReduce, Dryad, SQL, pregel, HaLoop 뿐만 아니라, 이러한 시스템으로 하기 어려운 interactive data mining과 같이 새로운 application 등, 분리된 시스템으로 제안된 cluster programming model에 적용될 수 있음"),K0.forEach(l),am.forEach(l),Uu=u(e),fi=r(e,"P",{});var W0=a(fi);JE=s(W0,"Spark라는 시스템에 RDD 구현하였음"),W0.forEach(l),Cu=u(e),$e=r(e,"UL",{});var om=a($e);Do=r(om,"LI",{});var V0=a(Do);QE=s(V0,"UC 버클리를 비롯한 여러 회사에서 연구 및 production에 사용중"),V0.forEach(l),GE=u(om),vo=r(om,"LI",{});var Z0=a(vo);KE=s(Z0,"Spark는 language-intergrated programming interface를 제공함(언어 자체에 Query문이 포함된 LINQ처럼). 또한 Spark는 Scala interpreter를 통해서 크기가 큰 dataset에 query를 날릴 수 있음"),Z0.forEach(l),om.forEach(l),ju=u(e),pi=r(e,"P",{});var X0=a(pi);WE=s(X0,"Spark의 성능"),X0.forEach(l),Bu=u(e),Ae=r(e,"UL",{});var fm=a(Ae);mo=r(fm,"LI",{});var Y0=a(mo);VE=s(Y0,"iterative application에서 하둡보다 20배 빠르고, real-world data analytic report에서 40배 빠르고, 1TB dataset을 scan하는 데 5~7초가 걸린다."),Y0.forEach(l),ZE=u(fm),Eo=r(fm,"LI",{});var g0=a(Eo);XE=s(g0,"RDD의 generality(범용성)을 증명하기 위해, Pregel과 HaLoop의 프로그래밍 모델을 Spark 위에서 구현하기도 했음. 이때 Pregel과 HaLoop이 사용하는 placement optimization을 적용하였고, 비교적 적은 라이브러리로 구현함."),g0.forEach(l),fm.forEach(l),Nu=u(e),Fu=r(e,"BR",{}),zu=r(e,"BR",{}),Ou=u(e),he=r(e,"H2",{id:!0});var vL=a(he);xe=r(vL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var eI=a(xe);_o=r(eI,"SPAN",{class:!0}),a(_o).forEach(l),eI.forEach(l),YE=s(vL,"Resilient Distributed Datasets(RDD)"),vL.forEach(l),Tu=u(e),qu=r(e,"HR",{}),Ju=u(e),we=r(e,"H3",{id:!0});var mL=a(we);Me=r(mL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var lI=a(Me);co=r(lI,"SPAN",{class:!0}),a(co).forEach(l),lI.forEach(l),gE=s(mL,"RDD Abstraction"),mL.forEach(l),Qu=u(e),si=r(e,"P",{});var tI=a(si);e_=s(tI,"RDD는 Read-only이며, record들의 Partitioned Collection임."),tI.forEach(l),Gu=u(e),Z=r(e,"UL",{});var Da=a(Z);Ro=r(Da,"LI",{});var iI=a(Ro);l_=s(iI,"RDD는 stable storage의 데이터나, 다른 RDD에 대한 deterministic operation을 통해서만 생성될 수 있음."),iI.forEach(l),t_=u(Da),Lo=r(Da,"LI",{});var rI=a(Lo);i_=s(rI,"deterministic : 예측한 그대로 동작. 어떤 특정한 입력이 들어오면 언제나 똑같은 과정을 거쳐서 언제나 똑같은 결과를 내놓는다."),rI.forEach(l),r_=u(Da),Io=r(Da,"LI",{});var aI=a(Io);a_=s(aI,"이러한 operation을 RDD의 다른 operation과 구분하기 위해 transform이라 부름. transform의 예는 map, filter, join 등이 있음"),aI.forEach(l),Da.forEach(l),Ku=u(e),ni=r(e,"P",{});var oI=a(ni);o_=s(oI,"RDD는 항상 materialized일 필요는 없음(구체적으로 모든 정보를 포함할 필요는 없음)."),oI.forEach(l),Wu=u(e),He=r(e,"UL",{});var pm=a(He);ko=r(pm,"LI",{});var fI=a(ko);f_=s(fI,"대신 stable storage에 저장된 데이터의 partition을 계산하기 위해, 다른 dataset(lineage)으로부터 어떻게 만들어진 것인지에 대해 정보를 포함하고 있음"),fI.forEach(l),p_=u(pm),bo=r(pm,"LI",{});var pI=a(bo);s_=s(pI,"프로그램은 failure가 발생한 후 reconstruct할 수 없는 RDD를 참조할 수 없음"),pI.forEach(l),pm.forEach(l),Vu=u(e),ui=r(e,"P",{});var sI=a(ui);n_=s(sI,"사용자는 RDD의 persistence(지속성)과 partitioning을 조절할 수 있음."),sI.forEach(l),Zu=u(e),X=r(e,"UL",{});var va=a(X);yo=r(va,"LI",{});var nI=a(yo);u_=s(nI,"재사용할 RDD를 지정하고, 어떤 storage strategy를 사용할 것인지 결정 가능 (ex. in-memory storage)"),nI.forEach(l),D_=u(va),So=r(va,"LI",{});var uI=a(So);v_=s(uI,"또한 RDD element가 각 record의 key에 따라 machine별로 partition 되게끔 요청할 수 있음"),uI.forEach(l),m_=u(va),Po=r(va,"LI",{});var DI=a(Po);E_=s(DI,"이는 placement optimization할 때 유용"),DI.forEach(l),va.forEach(l),Xu=u(e),Ue=r(e,"H3",{id:!0});var EL=a(Ue);Ce=r(EL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var vI=a(Ce);$o=r(vI,"SPAN",{class:!0}),a($o).forEach(l),vI.forEach(l),__=s(EL,"Spark Programming Interface"),EL.forEach(l),Yu=u(e),Di=r(e,"P",{});var mI=a(Di);c_=s(mI,"Spark는 laguage-integrated API를 통해 RDD를 제공함"),mI.forEach(l),gu=u(e),vi=r(e,"UL",{});var EI=a(vi);Ao=r(EI,"LI",{});var _I=a(Ao);d_=s(_I,"DryadLINQ나 FlumeJava와 유사함. 여기서는 각각의 dataset이 object로 표현되고, method를 통해 transformation을 호출함"),_I.forEach(l),EI.forEach(l),e1=u(e),mi=r(e,"P",{});var cI=a(mi);R_=s(cI,"개발자들은 stable storage로부터 (map이나 filter 등의)transformation을 함으로써, 한 개 이상의 RDD를 정의할 수 있음."),cI.forEach(l),l1=u(e),Y=r(e,"UL",{});var ma=a(Y);ho=r(ma,"LI",{});var dI=a(ho);L_=s(dI,"이렇게 RDD를 얻으면, action을 취할 수 있음"),dI.forEach(l),I_=u(ma),Ei=r(ma,"LI",{});var _L=a(Ei);k_=s(_L,"action : 그 값을 applciation으로 반환하거나, storage system 밖으로 데이터를 빼내는 등으로 사용하는 것. action의 예는 다음과 같음"),_e=r(_L,"UL",{});var Ea=a(_e);xo=r(Ea,"LI",{});var RI=a(xo);b_=s(RI,"count : dataset 내의 element의 수"),RI.forEach(l),y_=u(Ea),wo=r(Ea,"LI",{});var LI=a(wo);S_=s(LI,"collect : element 자체를 반환"),LI.forEach(l),P_=u(Ea),Mo=r(Ea,"LI",{});var II=a(Mo);$_=s(II,"save : dataset을 storage system에 저장"),II.forEach(l),Ea.forEach(l),_L.forEach(l),A_=u(ma),Ho=r(ma,"LI",{});var kI=a(Ho);h_=s(kI,"Spark는 RDD에서 처음 실행되는 action을 느리게 연산하여, transformation에 pipeline할 수 있음"),kI.forEach(l),ma.forEach(l),t1=u(e),_i=r(e,"P",{});var bI=a(_i);x_=s(bI,"persist : 특정 RDD가 미래의 operation에서 reuse될 수 있게끔 지정하는 method"),bI.forEach(l),i1=u(e),H=r(e,"UL",{});var at=a(H);Uo=r(at,"LI",{});var yI=a(Uo);w_=s(yI,"Spark는 default로 persistent RDD를 메모리에 저장해둠"),yI.forEach(l),M_=u(at),Co=r(at,"LI",{});var SI=a(Co);H_=s(SI,"하지만 RAM에 공간이 없으면 disk로 spill할 수 있음"),SI.forEach(l),U_=u(at),jo=r(at,"LI",{});var PI=a(jo);C_=s(PI,"유저 또한 다른 persistence strategy를 요청할 수 있음. 예를 들면 persist라는 flag는 RDD를 disk에만 저장하거나, 다른 machine들에 replication을 저장함"),PI.forEach(l),j_=u(at),Bo=r(at,"LI",{});var $I=a(Bo);B_=s($I,"유저는 RDD별로 persistence priority를 지정하여, 어떤 in-memory data가 disk로 먼저 spill되게끔 할 것인지 결정할 수 있음"),$I.forEach(l),at.forEach(l),r1=u(e),je=r(e,"H4",{id:!0});var cL=a(je);Be=r(cL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var AI=a(Be);No=r(AI,"SPAN",{class:!0}),a(No).forEach(l),AI.forEach(l),N_=s(cL,"Example: Console Log Mining"),cL.forEach(l),a1=u(e),ci=r(e,"P",{});var hI=a(ci);F_=s(hI,"웹 서비스가 장애를 겪고 있고, 오퍼레이터가 원인을 찾아내기 위해 테라바이트 단위의 로그를 HDFS로 분석해 본다고 가정해봅시다."),hI.forEach(l),o1=u(e),di=r(e,"UL",{});var xI=a(di);kt=r(xI,"LI",{});var sm=a(kt);z_=s(sm,"Spark를 쓰면 오페레이터는 log의 에러 메시지를 RAM으로 불러와서, interactively(대화식) query를 날릴 수 있다.  "),m(bt.$$.fragment,sm),O_=s(sm,`
- line 1 : HDFS 파일으로부터 RDD를 정의한다
- line 2 : 1의 RDD에서 Filter된 RDD (ERROR로 시작하는 데이터) => scala 문법으로 가능!
- line 3 : *errors*라는 RDD가 메모리에 남아서, query 사이에서 공유될 수 있게 함`),sm.forEach(l),xI.forEach(l),f1=u(e),Ri=r(e,"P",{});var wI=a(Ri);T_=s(wI,"cluster에 수행될 작업이 없다면, RDD로 에러 메시지의 수를 세는 등, action을 할 수 있음."),wI.forEach(l),p1=u(e),m(yt.$$.fragment,e),s1=u(e),Li=r(e,"P",{});var MI=a(Li);q_=s(MI,"사용자는 이렇게 얻은 RDD에서 추가적인 transformation을 실행하고, 그렇게 또 얻은 RDD에서 결과를 얻을 수 있음"),MI.forEach(l),n1=u(e),m(St.$$.fragment,e),u1=u(e),ce=r(e,"P",{});var Du=a(ce);Fo=r(Du,"EM",{});var HI=a(Fo);J_=s(HI,"errors"),HI.forEach(l),Q_=s(Du,"에 관련된 첫 번째 액션(위에선 count)이 실행되면, Spark는 "),zo=r(Du,"EM",{});var UI=a(zo);G_=s(UI,"errors"),UI.forEach(l),K_=s(Du,"의 partition을 메모리에 불러옴. 그러면 다음의 매우 연산이 빨라짐"),Du.forEach(l),D1=u(e),Ne=r(e,"UL",{});var nm=a(Ne);Oo=r(nm,"LI",{});var CI=a(Oo);m(Fe.$$.fragment,CI),CI.forEach(l),W_=u(nm),To=r(nm,"LI",{});var jI=a(To);V_=s(jI,"에러 메시지는 데이터의 극히 일부분에 해당하는 것이기에 충분히 작음. 메모리에 올려도 괜찮음"),jI.forEach(l),nm.forEach(l),v1=u(e),Ii=r(e,"P",{});var BI=a(Ii);Z_=s(BI,"이 모델이 fault tolerance를 달성하는 방법을 그림으로 나타낸 것"),BI.forEach(l),m1=u(e),m(Pt.$$.fragment,e),E1=u(e),U=r(e,"UL",{});var ot=a(U);ki=r(ot,"LI",{});var dL=a(ki);X_=s(dL,"위 3개의 query에 대한, RDD의 lineage graph"),de=r(dL,"OL",{});var _a=a(de);$t=r(_a,"LI",{});var um=a($t);Y_=s(um,"lines라는 RDD에 대한 filter의 결과로, "),qo=r(um,"EM",{});var NI=a(qo);g_=s(NI,"errors"),NI.forEach(l),e3=s(um,"라는 RDD를 얻음"),um.forEach(l),l3=u(_a),Jo=r(_a,"LI",{});var FI=a(Jo);t3=s(FI,"1에서 filter하여 다음의 RDD, map 하여 다음의 RDD를 얻음"),FI.forEach(l),i3=u(_a),Qo=r(_a,"LI",{});var zI=a(Qo);r3=s(zI,"2에서 collect()"),zI.forEach(l),_a.forEach(l),dL.forEach(l),a3=u(ot),Go=r(ot,"LI",{});var OI=a(Go);o3=s(OI,"Spark의 스케쥴러는 2의 map, filter 변환을 파이프라인화함"),OI.forEach(l),f3=u(ot),ze=r(ot,"LI",{});var vu=a(ze);Ko=r(vu,"EM",{});var TI=a(Ko);p3=s(TI,"errors"),TI.forEach(l),s3=s(vu,"라는 RDD의 데이터가 캐싱되어 있는 partition을 가진 node한테 연산하라고 던짐 (아까 "),Wo=r(vu,"EM",{});var qI=a(Wo);n3=s(qI,"errors"),qI.forEach(l),u3=s(vu,"는 count() 했었죠? 메모리에 올라가 있음)"),vu.forEach(l),D3=u(ot),Vo=r(ot,"LI",{});var JI=a(Vo);v3=s(JI,"만약 partition을 손실할 경우, Spark는 해당되는 line 파티션에만 filter를 적용하여 재구성함"),JI.forEach(l),ot.forEach(l),_1=u(e),Oe=r(e,"H3",{id:!0});var RL=a(Oe);Te=r(RL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var QI=a(Te);Zo=r(QI,"SPAN",{class:!0}),a(Zo).forEach(l),QI.forEach(l),m3=s(RL,"Advantages of the RDD Model"),RL.forEach(l),c1=u(e),m(At.$$.fragment,e),d1=u(e),bi=r(e,"P",{});var GI=a(bi);E3=s(GI,"RDD와 Distributed Shared Memory(DSM)를 비교했을 때 장점이 나옴."),GI.forEach(l),R1=u(e),R=r(e,"UL",{});var b=a(R);Xo=r(b,"LI",{});var KI=a(Xo);_3=s(KI,"DSM은 global address space의 임의의 공간에서 read/write를 수행"),KI.forEach(l),c3=u(b),Yo=r(b,"LI",{});var WI=a(Yo);d3=s(WI,"전통적인 shared memory system 뿐 아니라, Piccolo나 분산 데이터베이스 등 shared state를 fine-grained로 write하는 application도 DHT 사용함"),WI.forEach(l),R3=u(b),go=r(b,"LI",{});var VI=a(go);L3=s(VI,"DSM은 일반적인 방식이지만, 하지만 이런 방식은 commodity cluster에서 효율적이고 fault-tolerant한 방식으로 구현하기 어려움"),VI.forEach(l),I3=u(b),ef=r(b,"LI",{});var ZI=a(ef);k3=s(ZI,"DSM은 각 메모리의 위치별 read / write를 허용하지만(이게 fine-grained의 정의임. 그리고 RDD도 read 연산은 fine-grained로 가능함), 반면 RDD는 Course-grained인 transformation을 통해서만 생성(write)될 수 있음"),ZI.forEach(l),b3=u(b),lf=r(b,"LI",{});var XI=a(lf);y3=s(XI,"이는 RDD를 사용하는 application이 bulk write만 하게끔 제약하지만, 보다 효율적인 fault-tolerance를 제공함"),XI.forEach(l),S3=u(b),tf=r(b,"LI",{});var YI=a(tf);P3=s(YI,"RDD는 checkpointing의 overhead가 없는 대신, lineage를 통해 회복이 가능. (물론 lineage chain이 너무 길 경우 체크포인트를 쓰기도 함. 나중에 다룰 예정)"),YI.forEach(l),$3=u(b),rf=r(b,"LI",{});var gI=a(rf);A3=s(gI,`또한 RDD에서는 failure 발생 시 오직 손실된 partition만 복구하며, 이는 전체 프로그램을 rollback할 필요 없이 다른 node에서 병렬적으로 실행 가능함.
RDD의 두 번째 장점은, straggler가 있으면 그 태스크의 백업 복사본을 실행할 수 있다는 것(MapReduce처럼)`),gI.forEach(l),h3=u(b),af=r(b,"LI",{});var e8=a(af);x3=s(e8,"DSM에서는 Backup Task를 만드는 것이 어려움. 두 task가 동일한 메모리 영역을 액세스하여, 설의 업데이트를 방해하는 등 문제가 생길 수 있기 때문임."),e8.forEach(l),b.forEach(l),L1=u(e),yi=r(e,"P",{});var l8=a(yi);w3=s(l8,"마지막으로, RDD는 두 가지 이점을 제공함"),l8.forEach(l),I1=u(e),qe=r(e,"UL",{});var Dm=a(qe);of=r(Dm,"LI",{});var t8=a(of);ff=r(t8,"OL",{});var i8=a(ff);pf=r(i8,"LI",{});var r8=a(pf);M3=s(r8,"bulk 연산에서 data locality에 따라 runtime schedule 가능 => 성능 향상"),r8.forEach(l),i8.forEach(l),t8.forEach(l),H3=u(Dm),Si=r(Dm,"LI",{});var LL=a(Si);ht=r(LL,"OL",{start:!0});var IL=a(ht);sf=r(IL,"LI",{});var a8=a(sf);U3=s(a8,"스캔 기반 작업에만 사용된다면, 저장할 공간이 없을 때 성능 저하가 graceful하게 일어남."),a8.forEach(l),C3=u(IL),IL.forEach(l),nf=r(LL,"UL",{});var o8=a(nf);uf=r(o8,"LI",{});var f8=a(uf);j3=s(f8,"RAM에 맞지 않는 partition은 disk에 저장되며, 현재의 data-parallel system과 유사한 성능을 냄."),f8.forEach(l),o8.forEach(l),LL.forEach(l),Dm.forEach(l),k1=u(e),Je=r(e,"H3",{id:!0});var kL=a(Je);Qe=r(kL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var p8=a(Qe);Df=r(p8,"SPAN",{class:!0}),a(Df).forEach(l),p8.forEach(l),B3=s(kL,"Application Not Suitable for RDDs"),kL.forEach(l),b1=u(e),Pi=r(e,"P",{});var s8=a(Pi);N3=s(s8,"RDD는 same operation을 전체 dataset에 적용하는 batch application에 적합함"),s8.forEach(l),y1=u(e),$i=r(e,"UL",{});var n8=a($i);vf=r(n8,"LI",{});var u8=a(vf);F3=s(u8,"RDD는 각 단계의 transformation을 lineage graph의 한 단계로 기억하며, 많은 양의 데이터를 기록할 필요 없이 손실된 partition을 복구할 수 있음."),u8.forEach(l),n8.forEach(l),S1=u(e),Ai=r(e,"P",{});var D8=a(Ai);z3=s(D8,"반면 부적합한 application도 존재함"),D8.forEach(l),P1=u(e),g=r(e,"UL",{});var ca=a(g);hi=r(ca,"LI",{});var bL=a(hi);O3=s(bL,"asynchronous하게 fine-grained shared state를 update하는 application"),xt=r(bL,"UL",{});var vm=a(xt);mf=r(vm,"LI",{});var v8=a(mf);T3=s(v8,"web server의 storage system"),v8.forEach(l),q3=u(vm),Ef=r(vm,"LI",{});var m8=a(Ef);J3=s(m8,"점진적인 web crawler"),m8.forEach(l),vm.forEach(l),bL.forEach(l),Q3=u(ca),_f=r(ca,"LI",{});var E8=a(_f);G3=s(E8,"이러한 Application의 경우, 전통적인 log update, data checkpoint를 생성하는, database를 사용하는 것이 좋음"),E8.forEach(l),K3=u(ca),cf=r(ca,"LI",{});var _8=a(cf);W3=s(_8,"Spark의 목표는 batch analytic을 위한 프로그래밍 모델을 제공하는 것"),_8.forEach(l),ca.forEach(l),$1=u(e),A1=r(e,"BR",{}),h1=r(e,"BR",{}),x1=u(e),Ge=r(e,"H2",{id:!0});var yL=a(Ge);Ke=r(yL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var c8=a(Ke);df=r(c8,"SPAN",{class:!0}),a(df).forEach(l),c8.forEach(l),V3=s(yL,"Spark Programming Interfaces"),yL.forEach(l),w1=u(e),M1=r(e,"HR",{}),H1=u(e),xi=r(e,"P",{});var d8=a(xi);Z3=s(d8,"Spark는 language-integrated API를 통해 RDD abstraction을 제공함"),d8.forEach(l),U1=u(e),wi=r(e,"UL",{});var R8=a(wi);Rf=r(R8,"LI",{});var L8=a(Rf);X3=s(L8,"함수형 + 정적 타이핑 언어인 Scala를 선택하였는데, 간결하기 때문에 interactive하게 사용하기 용이함"),L8.forEach(l),R8.forEach(l),C1=u(e),Mi=r(e,"P",{});var I8=a(Mi);Y3=s(I8,"Spark를 쓰는 개발자는 driver program을 작성해야 하는데, 얘가 클러스터의 worker들에 접속함."),I8.forEach(l),j1=u(e),ee=r(e,"UL",{});var da=a(ee);Lf=r(da,"LI",{});var k8=a(Lf);g3=s(k8,"Driver는 한 개 이상의 RDD를 정의하고, action을 호출함."),k8.forEach(l),ec=u(da),If=r(da,"LI",{});var b8=a(If);lc=s(b8,"Driver는 RDD Lineage를 추적함"),b8.forEach(l),tc=u(da),kf=r(da,"LI",{});var y8=a(kf);ic=s(y8,"worker는 여러 연산을 통해 RDD Partition을 RAM에 저장할 수 있는 long-lived process임"),y8.forEach(l),da.forEach(l),B1=u(e),Hi=r(e,"P",{});var S8=a(Hi);rc=s(S8,"map과 같은 RDD Operation에는 closure(function literal)를 넘겨줘야 함"),S8.forEach(l),N1=u(e),We=r(e,"UL",{});var mm=a(We);bf=r(mm,"LI",{});var P8=a(bf);ac=s(P8,"이때 closure는 Java object로 표현되며, Serialize하여 네트워크를 통해 closure를 전송할 수 있음"),P8.forEach(l),oc=u(mm),yf=r(mm,"LI",{});var $8=a(yf);fc=s($8,"또한, 이 closure에 묶여 있는 변수는 Object의 field값으로 설정됨"),$8.forEach(l),mm.forEach(l),F1=u(e),Ui=r(e,"P",{});var A8=a(Ui);pc=s(A8,"RDD 자체는 원소의 타입을 파라미터로 넘길 수 있는 statically typed objected이다."),A8.forEach(l),z1=u(e),Ve=r(e,"UL",{});var Em=a(Ve);Sf=r(Em,"LI",{});var h8=a(Sf);sc=s(h8,"RDD[Int]는 Int의 RDD이다."),h8.forEach(l),nc=u(Em),Pf=r(Em,"LI",{});var x8=a(Pf);uc=s(x8,"Scala는 Type Interface를 지원하니, 타입을 생략해도 된다."),x8.forEach(l),Em.forEach(l),O1=u(e),Ze=r(e,"H3",{id:!0});var SL=a(Ze);Xe=r(SL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var w8=a(Xe);$f=r(w8,"SPAN",{class:!0}),a($f).forEach(l),w8.forEach(l),Dc=s(SL,"RDD Operations in Spark"),SL.forEach(l),T1=u(e),m(wt.$$.fragment,e),q1=s(e,`  
위 표는 Spark에서 사용 가능한 Transformation과 Action의 목록임.
`),Ye=r(e,"UL",{});var _m=a(Ye);Af=r(_m,"LI",{});var M8=a(Af);vc=s(M8,"대괄호 안에 타입 파라미터를 표시하여, 각 연산의 특징을 제시하였음."),M8.forEach(l),mc=u(_m),hf=r(_m,"LI",{});var H8=a(hf);Ec=s(H8,"transformation은 lazy operation인 반면, action은 프로그램에 값을 반환하거나 외부 스토리지에 값을 write하기 위해 연산을 시작함."),H8.forEach(l),_m.forEach(l),J1=u(e),Ci=r(e,"P",{});var U8=a(Ci);_c=s(U8,`join 등의 연산은 key-value pair 형태의 RDD에서만 가능함.
또한 함수 이름은 스칼라나 다른 함수형 언어의 API와 매칭이 가능하게끔 선정하였음`),U8.forEach(l),Q1=u(e),ji=r(e,"UL",{});var C8=a(ji);xf=r(C8,"LI",{});var j8=a(xf);cc=s(j8,"map : 1-1 mapping / flatMap : MapReduce의 map과 유사함. 각 input value를 한 개 이상의 output과 mapping"),j8.forEach(l),C8.forEach(l),G1=u(e),Bi=r(e,"P",{});var B8=a(Bi);dc=s(B8,`사용자는 RDD가 지속되게끔 요청할 수 있음. (persist)
RDD의 partition order를 얻을 수도 있음.`),B8.forEach(l),K1=u(e),Ni=r(e,"UL",{});var N8=a(Ni);wf=r(N8,"LI",{});var F8=a(wf);Rc=s(F8,`Partitioner Class가 partition order를 나타냄. 이걸 가지고 다른 dataset을 partition할 수도 있음.
groupByKey, reduceByKey, sort 등의 연산은 자동으로 hash partition 또는 range partition된 RDD를 생성한다.`),F8.forEach(l),N8.forEach(l),W1=u(e),ge=r(e,"H3",{id:!0});var PL=a(ge);el=r(PL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var z8=a(el);Mf=r(z8,"SPAN",{class:!0}),a(Mf).forEach(l),z8.forEach(l),Lc=s(PL,"Example: Logistic Regression"),PL.forEach(l),V1=u(e),Fi=r(e,"P",{});var O8=a(Fi);Ic=s(O8,"기계 학습 알고리즘의 경우, iterative한 경우가 많다."),O8.forEach(l),Z1=u(e),ll=r(e,"UL",{});var cm=a(ll);Hf=r(cm,"LI",{});var T8=a(Hf);kc=s(T8,"gradient descent 등 반복 최적화 절차를 수행하기 때문"),T8.forEach(l),bc=u(cm),Uf=r(cm,"LI",{});var q8=a(Uf);yc=s(q8,"따라서 데이터를 메모리에 저장한다면 험청 빨라질 것임"),q8.forEach(l),cm.forEach(l),X1=u(e),m(Mt.$$.fragment,e),Y1=u(e),zi=r(e,"P",{});var J8=a(zi);Sc=s(J8,"위 코드는 logistic regression 예제인데, 제가 머신러닝 이런거 안해봐서 뭔지 잘 모름 ㅈㅅ; 흐름만 봄"),J8.forEach(l),g1=u(e),C=r(e,"UL",{});var ft=a(C);Cf=r(ft,"LI",{});var Q8=a(Cf);Pc=s(Q8,"text file에서 map"),Q8.forEach(l),$c=u(ft),Oi=r(ft,"LI",{});var $L=a(Oi);Ac=s($L,"parsePoint 함수 넘겨서 텍스트 파일의 각 라인으로부터 좌표상의 위치 얻음 => "),jf=r($L,"EM",{});var G8=a(jf);hc=s(G8,"points"),G8.forEach(l),$L.forEach(l),xc=u(ft),Ht=r(ft,"LI",{});var dm=a(Ht);wc=s(dm,"반복적으로 "),Bf=r(dm,"EM",{});var K8=a(Bf);Mc=s(K8,"points"),K8.forEach(l),Hc=s(dm,"에서 map 및 reduce하여 결과(w 벡터)를 얻을 수 있음"),dm.forEach(l),Uc=u(ft),Nf=r(ft,"LI",{});var W8=a(Nf);Cc=s(W8,"메모리에 올려놓고 반복하기 때문에 20배까지 속도가 빨라짐"),W8.forEach(l),ft.forEach(l),eD=u(e),tl=r(e,"H3",{id:!0});var AL=a(tl);il=r(AL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var V8=a(il);Ff=r(V8,"SPAN",{class:!0}),a(Ff).forEach(l),V8.forEach(l),jc=s(AL,"Example: PageRank"),AL.forEach(l),lD=u(e),Ti=r(e,"UL",{});var Z8=a(Ti);zf=r(Z8,"LI",{});var X8=a(zf);Bc=s(X8,"RDD의 partitioning을 사용하여, 성능을 향상시킬 수 있는 것을 보여줌"),X8.forEach(l),Z8.forEach(l),tD=u(e),qi=r(e,"P",{});var Y8=a(qi);Nc=s(Y8,`더 복잡한 data sharing pattern임.
PageRank 알고리즘은 다른 문서에서 각 문서로 link되는 회수를 합산하여, 문서의 rank를 반복적으로 업데이트한다.`),Y8.forEach(l),iD=u(e),rl=r(e,"UL",{});var Rm=a(rl);Of=r(Rm,"LI",{});var g8=a(Of);Fc=s(g8,"각 iteration마다 각 문서는 r/n의 기여도를 이웃들에게 보낸다. (r : rank, n : 이웃의 수)"),g8.forEach(l),zc=u(Rm),Tf=r(Rm,"LI",{});var ek=a(Tf);Oc=s(ek,"그 후 순위를 α/N + (1 − α)∑ci 로 계산 (∑ci : 받은 기여도의 총합, N : 총 문서 수)"),ek.forEach(l),Rm.forEach(l),rD=u(e),Ji=r(e,"P",{});var lk=a(Ji);Tc=s(lk,"PageRank를 Spark로 나타내면 다음과 같음"),lk.forEach(l),aD=u(e),m(Ut.$$.fragment,e),oD=s(e,`  
좌측의 프로그램을 돌리면 우측의 그림과 같은 RDD Lineage 그래프를 얻을 수 있음
`),I=r(e,"UL",{});var h=a(I);x=r(h,"LI",{});var De=a(x);qc=s(De,"각 iteration마다, 이전 iteration의 "),qf=r(De,"EM",{});var tk=a(qf);Jc=s(tk,"contribs"),tk.forEach(l),Qc=s(De,"와 "),Jf=r(De,"EM",{});var ik=a(Jf);Gc=s(ik,"ranks"),ik.forEach(l),Kc=s(De,", 그리고 정적인 "),Qf=r(De,"EM",{});var rk=a(Qf);Wc=s(rk,"links"),rk.forEach(l),Vc=s(De,"라는 dataset으로부터, 새로운 "),Gf=r(De,"EM",{});var ak=a(Gf);Zc=s(ak,"ranks"),ak.forEach(l),Xc=s(De,"라는 dataset을 만듦."),De.forEach(l),Yc=u(h),Kf=r(h,"LI",{});var ok=a(Kf);gc=s(ok,"이 그래프의 흥미로운 특징은, 반복의 회수만큼 graph가 늘어난다는 것이다."),ok.forEach(l),ed=u(h),Wf=r(h,"LI",{});var fk=a(Wf);ld=s(fk,"이 작업은 많은 iteration이 동반되므로, fault recovery를 효율적으로 하려면 특정 버전의 ranks를 replication을 만들어서 저장해야 할 수도 있음"),fk.forEach(l),td=u(h),Vf=r(h,"LI",{});var pk=a(Vf);id=s(pk,"사용자는 RELIABLE 플래그를 줘서 persist 메소드를 호출하면 그렇게 할 수 있음"),pk.forEach(l),rd=u(h),Zf=r(h,"LI",{});var sk=a(Zf);ad=s(sk,"하지만 links라는 dataset은 replication을 만들 필요가 없음. 그냥 input file에서 map 다시 돌리면 해당 partition을 다시 얻는 게 더 효율적이기 때문"),sk.forEach(l),od=u(h),Xf=r(h,"LI",{});var nk=a(Xf);fd=s(nk,"이 dataset은 보통 ranks보다 훨씬 크기가 큼. 각 문서에는 많은 링크가 있지만 순위는 한 개뿐이기 때문"),nk.forEach(l),pd=u(h),Yf=r(h,"LI",{});var uk=a(Yf);sd=s(uk,"따라서 lineage를 사용하여 복구하는 게, 프로그램의 전체 in-memory state의 checkpoint를 만드는 것보다 시간을 절약할 수 있음"),uk.forEach(l),h.forEach(l),fD=u(e),Qi=r(e,"P",{});var Dk=a(Qi);nd=s(Dk,"RDD의 partitioning을 제어함으로써, PageRank 알고리즘에서의 통신을 최적화할 수 있음"),Dk.forEach(l),pD=u(e),P=r(e,"UL",{});var ve=a(P);gf=r(ve,"LI",{});var vk=a(gf);ud=s(vk,"만약 links를 기준으로 partitioning하게끔 명시한다면, ranks에 대해서도 동일한 방식으로 partitioning할 수 있음"),vk.forEach(l),Dd=u(ve),ep=r(ve,"LI",{});var mk=a(ep);vd=s(mk,"그렇게 되면 links와 ranks간의 join 연산이 통신을 필요로 하지 않게 됨(같은 머신 위에 필요한 데이터가 있음)"),mk.forEach(l),md=u(ve),lp=r(ve,"LI",{});var Ek=a(lp);Ed=s(Ek,"Partitioner class를 작성하여, 도메인 이름에 따라 페이지를 묶을 수도 있음."),Ek.forEach(l),_d=u(ve),Gi=r(ve,"LI",{});var hL=a(Gi);cd=s(hL,"아래와 같이, links를 정의할 때 PartitionBy()라는 method를 통해 진행  "),m(Ct.$$.fragment,hL),hL.forEach(l),dd=u(ve),tp=r(ve,"LI",{});var _k=a(tp);Rd=s(_k,"RDD는 사용자가 이러한 목표(일관된 partitioning을 통한 최적화)를 직접 표현할 수 있게 함."),_k.forEach(l),ve.forEach(l),sD=u(e),nD=r(e,"BR",{}),uD=r(e,"BR",{}),DD=u(e),al=r(e,"H2",{id:!0});var xL=a(al);ol=r(xL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ck=a(ol);ip=r(ck,"SPAN",{class:!0}),a(ip).forEach(l),ck.forEach(l),Ld=s(xL,"Representing RDDs"),xL.forEach(l),vD=u(e),mD=r(e,"HR",{}),ED=u(e),Ki=r(e,"P",{});var dk=a(Ki);Id=s(dk,"RDD를 Abstraction으로 제공하기 위한 과제 중 하나는, 광범위한 transformation에서 lineage를 추적할 수 있는 표현을 선택하는 것임"),dk.forEach(l),_D=u(e),j=r(e,"UL",{});var pt=a(j);rp=r(pt,"LI",{});var Rk=a(rp);kd=s(Rk,"RDD를 구현하는 시스템은 반드시 다양한 transformation 연산자들을 제공해야 하며, 사용자가 임의의 방식으로 transformation을 선택할 수 있게 해야 함."),Rk.forEach(l),bd=u(pt),ap=r(pt,"LI",{});var Lk=a(ap);yd=s(Lk,"이 논문에서는 graph-based의 표현을 제안함"),Lk.forEach(l),Sd=u(pt),op=r(pt,"LI",{});var Ik=a(op);Pd=s(Ik,"Spark에서는 이 표현을 사용함으로써, 각각의 스케줄러에 특별한 논리를 추가하지 않고 광범위한 transformation을 지원함"),Ik.forEach(l),$d=u(pt),fp=r(pt,"LI",{});var kk=a(fp);Ad=s(kk,"시스템 설계가 매우 단순화됨"),kk.forEach(l),pt.forEach(l),cD=u(e),Wi=r(e,"P",{});var bk=a(Wi);hd=s(bk,"각각의 RDD는 아래와 같은 정보를 노출하는 공통적인 인터페이스로 나타낼 수 있음"),bk.forEach(l),dD=u(e),B=r(e,"OL",{});var st=a(B);pp=r(st,"LI",{});var yk=a(pp);xd=s(yk,"partition의 집합 (dataset의 atomic pieces)"),yk.forEach(l),wd=u(st),sp=r(st,"LI",{});var Sk=a(sp);Md=s(Sk,"Parent RDD에 대한 종속성(dependency) 집합"),Sk.forEach(l),Hd=u(st),np=r(st,"LI",{});var Pk=a(np);Ud=s(Pk,"Parent RDD를 기반으로 dataset을 계산하는 함수"),Pk.forEach(l),Cd=u(st),Vi=r(st,"LI",{});var wL=a(Vi);jd=s(wL,"partitioning scheme 및 데이터 배치에 대한 메타데이터"),Re=r(wL,"UL",{});var Ra=a(Re);Zi=r(Ra,"LI",{});var ML=a(Zi);Bd=s(ML,"해당 인터페이스는 아래와 같은 테이블에서 보여줌  "),m(jt.$$.fragment,ML),ML.forEach(l),Nd=u(Ra),up=r(Ra,"LI",{});var $k=a(up);Fd=s($k,"예를 들면, HDFS 파일을 표현하는 RDD는 파일의 각 블록마다 partition을 가지고 있고 어떤 machine의 블록에 올라가 있는지 정보를 알고 있음"),$k.forEach(l),zd=u(Ra),Dp=r(Ra,"LI",{});var Ak=a(Dp);Od=s(Ak,"한편 이 RDD에 map을 한 결과물은 동일한 partition을 가지지만, 요소를 계산할 때 parent data에 map 함수를 적용한다."),Ak.forEach(l),Ra.forEach(l),wL.forEach(l),st.forEach(l),RD=u(e),m(Bt.$$.fragment,e),LD=s(e,`
RDD간의 종속성(Dependency)를 나타내는 인터페이스는 두 종류가 있음
`),le=r(e,"UL",{});var La=a(le);vp=r(La,"LI",{});var hk=a(vp);Td=s(hk,"narrow dependency: 1개의 Parent RDD에 1개의 Child RDD가 종속"),hk.forEach(l),qd=u(La),mp=r(La,"LI",{});var xk=a(mp);Jd=s(xk,"wide dependency : 1개의 Parent RDD에 여러 개의 Child RDD가 종속될 수 있음"),xk.forEach(l),Qd=u(La),Ep=r(La,"LI",{});var wk=a(Ep);Gd=s(wk,"예를 들어 map은 narrow dependency이고, join은 (parent가 hash-partitioned 되어있는 게 아니라면) wide dependency임."),wk.forEach(l),La.forEach(l),ID=u(e),Xi=r(e,"P",{});var Mk=a(Xi);Kd=s(Mk,"이렇게 narrow와 wide로 구분하는 게 유용한 이유가 두 가지 있음."),Mk.forEach(l),kD=u(e),fl=r(e,"OL",{});var Lm=a(fl);_p=r(Lm,"LI",{});var Hk=a(_p);cp=r(Hk,"P",{});var Uk=a(cp);Wd=s(Uk,`narrow dependency는 모든 parent partition을 계산할 수 있는 하나의 cluster node에서 pipelined execution이 가능함.
=> 예를 들면 각 요소마다 filter 이후 map을 적용할 수 있음
=> 반면 wide dependency에서는, MapReduce처럼 Parent Patrtition의 모든 데이터가 Child들에 Shuffle되어야 한다.`),Uk.forEach(l),Hk.forEach(l),Vd=u(Lm),dp=r(Lm,"LI",{});var Ck=a(dp);Rp=r(Ck,"P",{});var jk=a(Rp);Zd=s(jk,`node failure 이후 회복할 때는 narrow dependency에서 더 효율적임
=> 손실이 발생한 parent partition만 회복하면 되기 때문이며, 이는 다른 노드에서 병렬적으로 재연산이 가능
=> 반면 wide dependency의 lineage graph에서는, 특정 단일 노드에서 failure가 발생하면 해당 RDD의 조상으로부터 형성된 특정 파티션을 잃어버릴 수도 있으며, 이 경우 완전히 재실행해야 할 수도 있음.`),jk.forEach(l),Ck.forEach(l),Lm.forEach(l),bD=u(e),Yi=r(e,"P",{});var Bk=a(Yi);Xd=s(Bk,`Spark에서, 이러한 RDD의 공통적인 인터페이스는 대부분의 transformation을 20줄 이내로 수행할 수 있게 하였음.
아래 내용은 여러 RDD 구현이 요약된 것임`),Bk.forEach(l),yD=u(e),gi=r(e,"P",{});var Nk=a(gi);Yd=s(Nk,"HDFS Files"),Nk.forEach(l),SD=u(e),N=r(e,"UL",{});var nt=a(N);Lp=r(nt,"LI",{});var Fk=a(Lp);gd=s(Fk,"RDD가 HDFS의 파일인 경우, partitions()는 파일의 각 블록당 한 개의 partition이 반환된다."),Fk.forEach(l),e4=u(nt),Ip=r(nt,"LI",{});var zk=a(Ip);l4=s(zk,"각 Partition 객체에 block offset이 포함되어 있다"),zk.forEach(l),t4=u(nt),kp=r(nt,"LI",{});var Ok=a(kp);i4=s(Ok,"prefferedLocation()은 블록이 존재하는 노드를 반환한다."),Ok.forEach(l),r4=u(nt),bp=r(nt,"LI",{});var Tk=a(bp);a4=s(Tk,"iterator()는 블록을 읽는다."),Tk.forEach(l),nt.forEach(l),PD=u(e),er=r(e,"P",{});var qk=a(er);o4=s(qk,"map"),qk.forEach(l),$D=u(e),pl=r(e,"UL",{});var Im=a(pl);yp=r(Im,"LI",{});var Jk=a(yp);f4=s(Jk,"임의의 RDD에서 map을 호출하면 MappedRDD 객체가 반환된다"),Jk.forEach(l),p4=u(Im),Sp=r(Im,"LI",{});var Qk=a(Sp);s4=s(Qk,"이 객체는 parent와 동일한 partition 및 preferred location을 가지지만, Iterator()는 parent의 record와 매핑하기 위해 전달된 함수를 적용한다."),Qk.forEach(l),Im.forEach(l),AD=u(e),lr=r(e,"P",{});var Gk=a(lr);n4=s(Gk,"union"),Gk.forEach(l),hD=u(e),sl=r(e,"UL",{});var km=a(sl);Pp=r(km,"LI",{});var Kk=a(Pp);u4=s(Kk,"두 개의 RDD에서 union을 호출하면, 각 부모의 partition이 합쳐진 partition을 가진 RDD가 반환됨"),Kk.forEach(l),D4=u(km),$p=r(km,"LI",{});var Wk=a($p);v4=s(Wk,"각각의 Child Partition은 parent에 대한 narrow dependency를 통해 계산됨"),Wk.forEach(l),km.forEach(l),xD=u(e),tr=r(e,"P",{});var Vk=a(tr);m4=s(Vk,"sample"),Vk.forEach(l),wD=u(e),ir=r(e,"UL",{});var Zk=a(ir);Ap=r(Zk,"LI",{});var Xk=a(Ap);E4=s(Xk,"sample은 map과 비슷하지만, RDD가 parent record를 deterministically하게 샘플링하기 위해 각 partition마다 random number seed를 저장한다는 차이가 있음"),Xk.forEach(l),Zk.forEach(l),MD=u(e),rr=r(e,"P",{});var Yk=a(rr);_4=s(Yk,"join"),Yk.forEach(l),HD=u(e),$=r(e,"UL",{});var me=a($);hp=r(me,"LI",{});var gk=a(hp);c4=s(gk,"두 RDD를 join하는 연산은 세 가지 경우가 있음."),gk.forEach(l),d4=u(me),xp=r(me,"LI",{});var e9=a(xp);R4=s(e9,"두 RDD가 동일 partition에 hash/range partition된 경우(partitioner가 같은 경우), 둘 다 narrow dependency"),e9.forEach(l),L4=u(me),wp=r(me,"LI",{});var l9=a(wp);I4=s(l9,"둘 중 하나만 hash/range partition된 경우(partitioner를 가짐), narrow와 wide 혼합"),l9.forEach(l),k4=u(me),Mp=r(me,"LI",{});var t9=a(Mp);b4=s(t9,"아니면, 둘 다 wide dependency임"),t9.forEach(l),y4=u(me),Hp=r(me,"LI",{});var i9=a(Hp);S4=s(i9,"어떤 경우이든 결과물인 RDD는 partitioner를 가지며, parent로부터 물려받거나 default hash partitioner를 가짐"),i9.forEach(l),me.forEach(l),UD=u(e),CD=r(e,"BR",{}),jD=r(e,"BR",{}),BD=u(e),nl=r(e,"H2",{id:!0});var HL=a(nl);ul=r(HL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var r9=a(ul);Up=r(r9,"SPAN",{class:!0}),a(Up).forEach(l),r9.forEach(l),P4=s(HL,"Implementation"),HL.forEach(l),ND=u(e),FD=r(e,"HR",{}),zD=u(e),ar=r(e,"P",{});var a9=a(ar);$4=s(a9,"Spark 시스템은 Mesos cluster manager 위에서 동작하며, Hadoop, MPI(Message Passing Interface) 등 다른 어플리케이션과 리소스를 공유할 수 있다."),a9.forEach(l),OD=u(e),Dl=r(e,"UL",{});var bm=a(Dl);Cp=r(bm,"LI",{});var o9=a(Cp);A4=s(o9,"각각의 Spark 프로그램은 driver(master)와 worker를 가진 별도의 Mesos Application으로 동작한다."),o9.forEach(l),h4=u(bm),jp=r(bm,"LI",{});var f9=a(jp);x4=s(f9,"애플리케이션 간의 자원 관리는 Mesos에 의해 처리된다."),f9.forEach(l),bm.forEach(l),TD=u(e),or=r(e,"P",{});var p9=a(or);w4=s(p9,"Spark는 HDFS, HBase 등 Hadoop의 입력 소스를 통해 데이터를 읽어올 수 있다."),p9.forEach(l),qD=u(e),vl=r(e,"UL",{});var ym=a(vl);Bp=r(ym,"LI",{});var s9=a(Bp);M4=s(s9,"기존의 Hadoop에서 사용하는 input plugin API를 사용한다."),s9.forEach(l),H4=u(ym),Np=r(ym,"LI",{});var n9=a(Np);U4=s(n9,"특별히 수정된 Scala 버전을 사용하지 않아도 된다."),n9.forEach(l),ym.forEach(l),JD=u(e),ml=r(e,"H3",{id:!0});var UL=a(ml);El=r(UL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var u9=a(El);Fp=r(u9,"SPAN",{class:!0}),a(Fp).forEach(l),u9.forEach(l),C4=s(UL,"Job Scheduling"),UL.forEach(l),QD=u(e),m(Nt.$$.fragment,e),GD=s(e,`  
그림에서 검정색은 이미 메모리에 올라가 있는 부분임.  
stage 1의 결과물이 이미 RAM에 올라가 있으므로, stage 3의 RDD를 얻기 위해서는 stage 2, 3만 하면 됨
`),fr=r(e,"P",{});var D9=a(fr);j4=s(D9,"Spark scheduler는 4장에서 다루었던 RDD 표현을 사용한다. Spark의 scheduler는 Dryad의 scheduler와 비슷하지만, persistent RDD의 어떤 partition을 메모리에 올릴지도 고려한다."),D9.forEach(l),KD=u(e),A=r(e,"UL",{});var Ee=a(A);zp=r(Ee,"LI",{});var v9=a(zp);B4=s(v9,"위 그림처럼, 유저가 RDD에 대한 action을 수행할 때마다 scheduler는 실행할 stage의 DAG를 만들기 위해 RDD의 lineage graph를 검사한다."),v9.forEach(l),N4=u(Ee),Op=r(Ee,"LI",{});var m9=a(Op);F4=s(m9,"DAG : Directed Acyclic Graph. Cycle이 없는 Directed Graph"),m9.forEach(l),z4=u(Ee),Tp=r(Ee,"LI",{});var E9=a(Tp);O4=s(E9,"각 stage는 narrow dependency로 구성할 수 있는, 여러 transform의 파이프라인으로 구성되어 있음"),E9.forEach(l),T4=u(Ee),qp=r(Ee,"LI",{});var _9=a(qp);q4=s(_9,"각 stage를 구분하는 것은 wide dependency에 필요한 shuffle 연산 또는 parent RDD의 계산을 단순화할 수 있는 이미 계산된 partition이다."),_9.forEach(l),J4=u(Ee),Jp=r(Ee,"LI",{});var c9=a(Jp);Q4=s(c9,"Scheduler는 대상 RDD가 계산될 때까지, 각 stage의 missing partition을 연산하는 작업을 생성한다."),c9.forEach(l),Ee.forEach(l),WD=u(e),pr=r(e,"P",{});var d9=a(pr);G4=s(d9,"Spark의 scheduler는 delay scheduling을 사용하여, data locality에 따라 machine에 작업 할당"),d9.forEach(l),VD=u(e),te=r(e,"UL",{});var Ia=a(te);Qp=r(Ia,"LI",{});var R9=a(Qp);K4=s(R9,"만약 task가 어느 노드의 메모리에서 사용 가능한 partition을 처리해야 할 경우, 해당 노드로 보낸다."),R9.forEach(l),W4=u(Ia),Gp=r(Ia,"LI",{});var L9=a(Gp);V4=s(L9,`또는 task가 HDFS처럼 preferred location이 존재하는 RDD의 partition을 처리하는 경우, 해당 파티션으로 보냄
Wide Dependency(shuffle)의 경우, 오류 복구를 단순화하기 위해 parent partition을 보유한 노드에 있는 intermediate record를 materialize함.`),L9.forEach(l),Z4=u(Ia),Kp=r(Ia,"LI",{});var I9=a(Kp);X4=s(I9,"MapReduce가 map output을 materialize하는 것과 유사"),I9.forEach(l),Ia.forEach(l),ZD=u(e),_l=r(e,"OL",{});var Sm=a(_l);Wp=r(Sm,"LI",{});var k9=a(Wp);Y4=s(k9,"만약 task가 failure하면, 해당 stage의 parent가 살아있는 한 다른 node에서 작업을 다시 실행함."),k9.forEach(l),g4=u(Sm),sr=r(Sm,"LI",{});var CL=a(sr);e5=s(CL,"만약 특정 stage 자체를 사용할 수 없는 경우(예를 들면 shuffle 중 map side의 출력값이 손실된 경우), 병렬적으로 missing partition을 계산하기 위해 task를 다시 전송한다."),Vp=r(CL,"UL",{});var b9=a(Vp);Zp=r(b9,"LI",{});var y9=a(Zp);l5=s(y9,"RDD linage graph를 replicating하는 것은 간단하지만, scheduler 실패는 아직 핸들링하기 어려움"),y9.forEach(l),b9.forEach(l),CL.forEach(l),Sm.forEach(l),XD=u(e),nr=r(e,"P",{});var S9=a(nr);t5=s(S9,"Spark의 모든 연산은 driver 프로그램에서 action이 호출되면 그에 따라 실행됨"),S9.forEach(l),YD=u(e),cl=r(e,"UL",{});var Pm=a(cl);Xp=r(Pm,"LI",{});var P9=a(Xp);i5=s(P9,"하지만 map과 같은 cluster의 작업이 조회 작업을 호출하도록 하여, hash-partition된 RDD의 요소에 key값을 통해 random access할 수 있게 하는 실험도 하고 있음"),P9.forEach(l),r5=u(Pm),Yp=r(Pm,"LI",{});var $9=a(Yp);a5=s($9,"이 경우, task는 scheduler에게 필요한 partition이 missing 상태일 경우 이를 계산하게끔 지시해야 함."),$9.forEach(l),Pm.forEach(l),gD=u(e),dl=r(e,"H3",{id:!0});var jL=a(dl);Rl=r(jL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var A9=a(Rl);gp=r(A9,"SPAN",{class:!0}),a(gp).forEach(l),A9.forEach(l),o5=s(jL,"Interpreter Integration"),jL.forEach(l),e2=u(e),ur=r(e,"P",{});var h9=a(ur);f5=s(h9,"Scala는 Python이나 Ruby처럼 interactive shell을 제공함"),h9.forEach(l),l2=u(e),Dr=r(e,"UL",{});var x9=a(Dr);es=r(x9,"LI",{});var w9=a(es);p5=s(w9,"데이터를 in-memory로 처리하여 latency가 낮기 때문에, 사용자는 Spark Interpreter를 통해 interactive하게 많은 양의 데이터에 query를 날릴 수 있음"),w9.forEach(l),x9.forEach(l),t2=u(e),vr=r(e,"P",{});var M9=a(vr);s5=s(M9,"Scala interpreter는 사용가 입력한 클래스가 있는 라인을 컴파일하여 JVM에 로드하고, 그 위에서 함수를 호출함."),M9.forEach(l),i2=u(e),F=r(e,"UL",{});var ut=a(F);ls=r(ut,"LI",{});var H9=a(ls);n5=s(H9,"이러한 클래스는 그 라인에서 선언된 변수나 함수를 포함하며, initialize method로 그 라인을 실행하는 singleton object를 포함함."),H9.forEach(l),u5=u(ut),ts=r(ut,"LI",{});var U9=a(ts);D5=s(U9,"singleton object : class의 instance가 오직 1개만 생성됨"),U9.forEach(l),v5=u(ut),is=r(ut,"LI",{});var C9=a(is);m5=s(C9,"예를 들면, 만약 유저가 var x = 5를 입력하고 그 다음 println(x)를 입력했다고 가정"),C9.forEach(l),E5=u(ut),rs=r(ut,"LI",{});var j9=a(rs);_5=s(j9,"인터프리터는 x를 포함하는 Line1이라는 클래스를 만들고, println(Line1.getInstance().x)로 컴파일"),j9.forEach(l),ut.forEach(l),r2=u(e),mr=r(e,"P",{});var B9=a(mr);c5=s(B9,"Spark interpreter에서는 두 가지의 변화를 줬음"),B9.forEach(l),a2=u(e),Ll=r(e,"OL",{});var $m=a(Ll);as=r($m,"LI",{});var N9=a(as);d5=s(N9,"Class Shipping: worker 노드가 각 라인에 선언된 클래스의 바이트 코드를 읽어올 수 있게끔, interpreter는 이런 클래스를 HTTP로 전송함."),N9.forEach(l),R5=u($m),Er=r($m,"LI",{});var BL=a(Er);L5=s(BL,"수정된 코드 생성: 일반적으로 코드의 각 라인마다 생성된 Singleton Object는 해당 클래스의 static method를 통해 접근함."),Ft=r(BL,"UL",{});var Am=a(Ft);os=r(Am,"LI",{});var F9=a(os);I5=s(F9,"위 예제(Line1.getInstance().x)처럼 이전 라인에서 정의된 변수를 참조하는 closure를 serialize할 때, Java는 object graph를 추적하여 x를 감싸는 Line1 인스턴스를 전달하지 않음. 따라서 worker 노드는 x를 받지 않을 것임."),F9.forEach(l),k5=u(Am),fs=r(Am,"LI",{});var z9=a(fs);b5=s(z9,"code generation logic을 수정하여, 참조를 하려고 할 시 각 라인의 object의 instance를 직접 참조하게끔 변경하였음"),z9.forEach(l),Am.forEach(l),BL.forEach(l),$m.forEach(l),o2=u(e),m(zt.$$.fragment,e),f2=s(e,`  
위 그림은 사용자가 입력한 라인을 interpreter가 어떻게 해석하는지 보여줌
`),_r=r(e,"P",{});var O9=a(_r);y5=s(O9,"Spark interpreter를 쓰면 HDFS에 저장된 dataset을 탐색하거나, trace를 추적(아마 lineage graph?)하는데 유용하다는 것을 발견하였음."),O9.forEach(l),p2=u(e),Il=r(e,"H3",{id:!0});var NL=a(Il);kl=r(NL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var T9=a(kl);ps=r(T9,"SPAN",{class:!0}),a(ps).forEach(l),T9.forEach(l),S5=s(NL,"Memory Management"),NL.forEach(l),s2=u(e),cr=r(e,"P",{});var q9=a(cr);P5=s(q9,"Spark는 persistent RDD를 저장하기 위한 세 가지 옵션을 제공한다."),q9.forEach(l),n2=u(e),ie=r(e,"OL",{});var ka=a(ie);dr=r(ka,"LI",{});var FL=a(dr);$5=s(FL,"in-memory storage - deserialized Java object"),ss=r(FL,"UL",{});var J9=a(ss);ns=r(J9,"LI",{});var Q9=a(ns);A5=s(Q9,"JVM이 RDD 요소를 native하게 접근할 수 있기 때문에 가장 빠름"),Q9.forEach(l),J9.forEach(l),FL.forEach(l),h5=u(ka),Rr=r(ka,"LI",{});var zL=a(Rr);x5=s(zL,"in-memory storage – serialized data"),us=r(zL,"UL",{});var G9=a(us);Ds=r(G9,"LI",{});var K9=a(Ds);w5=s(K9,"Java의 object graph보다 메모리 측면에서는 효율적이지만, 성능은 감소"),K9.forEach(l),G9.forEach(l),zL.forEach(l),M5=u(ka),Lr=r(ka,"LI",{});var OL=a(Lr);H5=s(OL,"on-disk storage"),vs=r(OL,"UL",{});var W9=a(vs);ms=r(W9,"LI",{});var V9=a(ms);U5=s(V9,"RDD가 너무 커서 RAM에 저장하기엔 너무 크지만 사용할 때마다 재계산하기에는 비용이 너무 많이 드는 RDD에 유용함"),V9.forEach(l),W9.forEach(l),OL.forEach(l),ka.forEach(l),u2=u(e),Ir=r(e,"P",{});var Z9=a(Ir);C5=s(Z9,"사용 가능한 메모리는 제한적이므로, RDD 레벨에서 LRU 제거 정책을 사용함."),Z9.forEach(l),D2=u(e),z=r(e,"UL",{});var Dt=a(z);Es=r(Dt,"LI",{});var X9=a(Es);j5=s(X9,"새로운 RDD Partition이 계산될 때 이를 저장할 공간이 충분치 않다면, 가장 예전에 access된 RDD를 쫓아냄."),X9.forEach(l),B5=u(Dt),_s=r(Dt,"LI",{});var Y9=a(_s);N5=s(Y9,"예외적으로, 새로운 partition이 있는 RDD와 동일한 RDD는 쫓아내지 않는데, cycling partition이 일어나지 않게끔 하기 위함"),Y9.forEach(l),F5=u(Dt),cs=r(Dt,"LI",{});var g9=a(cs);z5=s(g9,"대부분의 작업은 RDD 전체에서 수행되기 때문에, 이는 굉장히 중요함. 이미 메모리에 있는 파티션이 미래에 필요할 가능성이 높음."),g9.forEach(l),O5=u(Dt),ds=r(Dt,"LI",{});var eb=a(ds);T5=s(eb,"메모리 관리 정책의 기본값인 이 방식도 잘 동작하지만, 사용자는 각 RDD에 persistence priority를 부여하여 제어할 수도 있음."),eb.forEach(l),Dt.forEach(l),v2=u(e),bl=r(e,"H3",{id:!0});var TL=a(bl);yl=r(TL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var lb=a(yl);Rs=r(lb,"SPAN",{class:!0}),a(Rs).forEach(l),lb.forEach(l),q5=s(TL,"Support for Checkpointing"),TL.forEach(l),m2=u(e),kr=r(e,"P",{});var tb=a(kr);J5=s(tb,"RDD가 failure한 이후 lineage를 통해 복구할 수 있지만, lineage chain이 너무 길면 복구 과정에서 시간이 너무 오래 걸릴 수 있음"),tb.forEach(l),E2=u(e),br=r(e,"UL",{});var ib=a(br);Ls=r(ib,"LI",{});var rb=a(Ls);Q5=s(rb,"RDD를 stable storage에 checkpointing하면 유용함"),rb.forEach(l),ib.forEach(l),_2=u(e),yr=r(e,"P",{});var ab=a(yr);G5=s(ab,"일반적으로 Checkpoint는 wide dependency를 포함하는, 긴 lineage graph의 RDD에 대해 유용함"),ab.forEach(l),c2=u(e),re=r(e,"UL",{});var ba=a(re);Is=r(ba,"LI",{});var ob=a(Is);K5=s(ob,"만약 이 경우 클러스터 안의 노드의 falilure는 각각의 parent RDD로부터 온 데이터 조각의 손실로 이어질 수 있음. 이 경우 모든 데이터를 다시 계산해야 함"),ob.forEach(l),W5=u(ba),ks=r(ba,"LI",{});var fb=a(ks);V5=s(fb,"반면 narrow dependency의 경우에는, Checkpointing이 불필요함."),fb.forEach(l),Z5=u(ba),bs=r(ba,"LI",{});var pb=a(bs);X5=s(pb,"노드가 실패하여 lost partition을 계산하려면 전체 RDD를 복제하는 비용의 극히 일부만으로 다른 노드에서 병렬적으로 재계산할 수 있기 때문"),pb.forEach(l),ba.forEach(l),d2=u(e),Sr=r(e,"P",{});var sb=a(Sr);Y5=s(sb,"Spark는 (persist() method의 REPLICATE flag 등) checkpointing API를 제공함."),sb.forEach(l),R2=u(e),Sl=r(e,"UL",{});var hm=a(Sl);ys=r(hm,"LI",{});var nb=a(ys);g5=s(nb,"다만 어떤 데이터를 checkpointing할지는 유저가 결정"),nb.forEach(l),eR=u(hm),Ss=r(hm,"LI",{});var ub=a(Ss);lR=s(ub,"시스템 복구 시간을 최소화할 수 있도록 자동으로 checkpointing하는 방법을 연구 중에 있음"),ub.forEach(l),hm.forEach(l),L2=u(e),Pr=r(e,"P",{});var Db=a(Pr);tR=s(Db,"RDD의 read-only라는 특성 덕에 일반적인 shared memory보다 checkpointing하기 쉬움."),Db.forEach(l),I2=u(e),Pl=r(e,"UL",{});var xm=a(Pl);Ps=r(xm,"LI",{});var vb=a(Ps);iR=s(vb,"data consistency를 고려할 필요가 없음"),vb.forEach(l),rR=u(xm),$s=r(xm,"LI",{});var mb=a($s);aR=s(mb,"checkpointing을 background에서 진행하면서, 작동중인 프로그램을 멈추거나 특별한 분산 스냅샷 스키마를 사용할 필요가 없음. (동시에 가능)"),mb.forEach(l),xm.forEach(l),k2=u(e),b2=r(e,"BR",{}),y2=r(e,"BR",{}),S2=u(e),$l=r(e,"H2",{id:!0});var qL=a($l);Al=r(qL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Eb=a(Al);As=r(Eb,"SPAN",{class:!0}),a(As).forEach(l),Eb.forEach(l),oR=s(qL,"Evaluation"),qL.forEach(l),P2=u(e),$2=r(e,"HR",{}),A2=u(e),$r=r(e,"P",{});var _b=a($r);fR=s(_b,"EC2에 올려서 Spark와 RDD, 및 이를 사용하는 User Application의 성능을 검사하였음"),_b.forEach(l),h2=u(e),O=r(e,"OL",{});var vt=a(O);Ar=r(vt,"LI",{});var JL=a(Ar);pR=s(JL,"스파크는 반복적인 기계 학습 및 그래프 애플리케이션에서 하둡을 최대 20배 능가함"),hs=r(JL,"UL",{});var cb=a(hs);xs=r(cb,"LI",{});var db=a(xs);sR=s(db,"데이터를 자바 객체로 메모리에 저장함으로써 입출력 및 역직렬화 비용을 피할 수 있기 때문에 속도가 향상된다."),db.forEach(l),cb.forEach(l),JL.forEach(l),nR=u(vt),hr=r(vt,"LI",{});var QL=a(hr);uR=s(QL,"사용자가 작성한 애플리케이션에 올라간 Spark는 성능과 확장성이 뛰어나다."),ws=r(QL,"UL",{});var Rb=a(ws);Ms=r(Rb,"LI",{});var Lb=a(Ms);DR=s(Lb,"analytics report 할 때 하둡보다 40배 빨랐음"),Lb.forEach(l),Rb.forEach(l),QL.forEach(l),vR=u(vt),Hs=r(vt,"LI",{});var Ib=a(Hs);mR=s(Ib,"노드에 장애가 발생하면 스파크는 손실된 RDD 파티션만 재구성하여 신속하게 복구할 수 있다."),Ib.forEach(l),ER=u(vt),Us=r(vt,"LI",{});var kb=a(Us);_R=s(kb,"스파크는 1TB 데이터 세트를 5-7초의 지연시간(latency)으로 대화식(interactively)으로 쿼리하는 데 사용할 수 있다"),kb.forEach(l),vt.forEach(l),x2=u(e),hl=r(e,"H3",{id:!0});var GL=a(hl);xl=r(GL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var bb=a(xl);Cs=r(bb,"SPAN",{class:!0}),a(Cs).forEach(l),bb.forEach(l),cR=s(GL,"Iterative Machine Learning Applications"),GL.forEach(l),w2=u(e),m(Ot.$$.fragment,e),M2=u(e),ae=r(e,"UL",{});var ya=a(ae);js=r(ya,"LI",{});var yb=a(js);dR=s(yb,"Logistic Regression: I/O 및 serialization sensitive"),yb.forEach(l),RR=u(ya),Bs=r(ya,"LI",{});var Sb=a(Bs);LR=s(Sb,"K-Means: compute-intensive"),Sb.forEach(l),IR=u(ya),xr=r(ya,"LI",{});var KL=a(xr);kR=s(KL,"HadoopBinMem"),Tt=r(KL,"UL",{});var wm=a(Tt);Ns=r(wm,"LI",{});var Pb=a(Ns);bR=s(Pb,"input data를 binary format으로 바꾸는 hadoop 버전"),Pb.forEach(l),yR=u(wm),Fs=r(wm,"LI",{});var $b=a(Fs);SR=s($b,"데이터를 in-memory HDFS 인스턴스에 저장"),$b.forEach(l),wm.forEach(l),KL.forEach(l),ya.forEach(l),H2=u(e),wr=r(e,"P",{});var Ab=a(wr);PR=s(Ab,"그림 7의 First iteration: HadoopBM > Hadoop > Spark"),Ab.forEach(l),U2=u(e),oe=r(e,"UL",{});var Sa=a(oe);zs=r(Sa,"LI",{});var hb=a(zs);$R=s(hb,"HadoopBM : 데이터를 binary로 바꾸는 추가적인 작업 및 in-memory HDFS를 replicate하는 overhead로 인해 가장 느림"),hb.forEach(l),AR=u(Sa),Os=r(Sa,"LI",{});var xb=a(Os);hR=s(xb,"Hadoop : heartbeat를 보내기 위한 Signaling overhead로 인해 Spark보다 느림"),xb.forEach(l),xR=u(Sa),Ts=r(Sa,"LI",{});var wb=a(Ts);wR=s(wb,"Spark: 이후의 Iteration부터는 RDD로 인해 데이터가 reuse되어 빨라짐"),wb.forEach(l),Sa.forEach(l),C2=u(e),Mr=r(e,"P",{});var Mb=a(Mr);MR=s(Mb,"그림 8: 그냥 machine 수 달리해서 재 본거임. 역시 spark가 제일 빠름"),Mb.forEach(l),j2=u(e),Hr=r(e,"P",{});var Hb=a(Hr);HR=s(Hb,"하둡이 느린 이유"),Hb.forEach(l),B2=u(e),fe=r(e,"OL",{});var Pa=a(fe);qs=r(Pa,"LI",{});var Ub=a(qs);UR=s(Ub,`하둡의 소프트웨어 스택의 오버헤드
=> 하둡은 job을 수행할 때 job 설정, task 시작, 정리 등의 overhead 등으로 인해, 최소 25초의 오버헤드가 발생`),Ub.forEach(l),CR=u(Pa),Js=r(Pa,"LI",{});var Cb=a(Js);jR=s(Cb,`데이터를 서빙할 때 HDFS의 오버헤드
=> HDFS는 여러 개의 메모리 복사본을 각 블록에 전송하며, 각 블록에 체크섬을 수행하기 때문에 오버헤드 발생`),Cb.forEach(l),BR=u(Pa),Qs=r(Pa,"LI",{});var jb=a(Qs);NR=s(jb,"binary record를 Java object로 변경하기 위한 deserialization 비용"),jb.forEach(l),Pa.forEach(l),N2=u(e),m(qt.$$.fragment,e),F2=s(e,`  
Text – binary 시간 차이 : parsing에 소요되는 시간
`),wl=r(e,"UL",{});var Mm=a(wl);Gs=r(Mm,"LI",{});var Bb=a(Gs);FR=s(Bb,"Hadoop은 binary data를 Java object로 변환하는데 시간이 필요함"),Bb.forEach(l),zR=u(Mm),Ks=r(Mm,"LI",{});var Nb=a(Ks);OR=s(Nb,"Spark는 RDD 요소를 메모리에 Java object로 바로 저장하므로, 오버헤드를 회피함"),Nb.forEach(l),Mm.forEach(l),z2=u(e),Ml=r(e,"H3",{id:!0});var WL=a(Ml);Hl=r(WL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Fb=a(Hl);Ws=r(Fb,"SPAN",{class:!0}),a(Ws).forEach(l),Fb.forEach(l),TR=s(WL,"PageRank"),WL.forEach(l),O2=u(e),m(Jt.$$.fragment,e),T2=s(e,`  
PageRank에서도 Spark가 빠르게 나옴
`),Ul=r(e,"UL",{});var Hm=a(Ul);Vs=r(Hm,"LI",{});var zb=a(Vs);qR=s(zb,"Controlled Partitioning을 해주면, data access가 일관되게 일어나기 때문에 속도를 향상시킬 수 있다"),zb.forEach(l),JR=u(Hm),Zs=r(Hm,"LI",{});var Ob=a(Zs);QR=s(Ob,"또한 Pregel에서 PageRank를 돌려도, Pregel은 추가적인 연산을 하기 때문에 Spark의 버전보다 4초정도 더 길게 나옴."),Ob.forEach(l),Hm.forEach(l),q2=u(e),Cl=r(e,"H3",{id:!0});var VL=a(Cl);jl=r(VL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Tb=a(jl);Xs=r(Tb,"SPAN",{class:!0}),a(Xs).forEach(l),Tb.forEach(l),GR=s(VL,"Fault Recovery"),VL.forEach(l),J2=u(e),m(Qt.$$.fragment,e),Q2=s(e,`  
K-means를 돌릴 때 failure가 발생한 경우 recovery에 얼마나 시간이 걸리는지 보여줌
`),pe=r(e,"UL",{});var $a=a(pe);Ys=r($a,"LI",{});var qb=a(Ys);KR=s(qb,"6번째 iteration에서 machine 하나 죽여서, 그 machine에서 돌아가는 task가 실패"),qb.forEach(l),WR=u($a),gs=r($a,"LI",{});var Jb=a(gs);VR=s(Jb,"다른 machone에서 task를 다시 실행"),Jb.forEach(l),ZR=u($a),en=r($a,"LI",{});var Qb=a(en);XR=s(Qb,"해당 task의 input data와 RDD lineage를 다시 읽고, RDD Partition을 재구성"),Qb.forEach(l),$a.forEach(l),G2=u(e),Ur=r(e,"P",{});var Gb=a(Ur);YR=s(Gb,"checkpoint 기반의 장애 복구 메커니즘은 체크포인트 빈도에 따라 작업을 여러번 반복해야 할수도 있음"),Gb.forEach(l),K2=u(e),se=r(e,"UL",{});var Aa=a(se);ln=r(Aa,"LI",{});var Kb=a(ln);gR=s(Kb,"또한 시스템은 네트워크를 통해 대용량의 working set을 replicate해야 함"),Kb.forEach(l),e6=u(Aa),tn=r(Aa,"LI",{});var Wb=a(tn);l6=s(Wb,"이를 RAM에 복제하면 Spark의 두 배 메모리를 쓰는 거고, DISK에 복제하면 대용량의 데이터를 쓰는 것을 기다려야 함"),Wb.forEach(l),t6=u(Aa),rn=r(Aa,"LI",{});var Vb=a(rn);i6=s(Vb,"Spark의 RDD lineage graph는 크기가 10kb 미만"),Vb.forEach(l),Aa.forEach(l),W2=u(e),Bl=r(e,"H3",{id:!0});var ZL=a(Bl);Nl=r(ZL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Zb=a(Nl);an=r(Zb,"SPAN",{class:!0}),a(an).forEach(l),Zb.forEach(l),r6=s(ZL,"Behavior with Insufficient Memory"),ZL.forEach(l),V2=u(e),m(Gt.$$.fragment,e),Z2=s(e,`  
성능이 감소되긴 하지만 Graceful하게(어느정도 하락폭을 예측할 수 있게) 감소됨
`),Fl=r(e,"H3",{id:!0});var XL=a(Fl);zl=r(XL,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Xb=a(zl);on=r(Xb,"SPAN",{class:!0}),a(on).forEach(l),Xb.forEach(l),a6=s(XL,"User Applications Built with Spark"),XL.forEach(l),X2=u(e),Cr=r(e,"P",{});var Yb=a(Cr);o6=s(Yb,"In-memory Analytics:"),Yb.forEach(l),Y2=u(e),jr=r(e,"UL",{});var gb=a(jr);Br=r(gb,"LI",{});var YL=a(Br);f6=s(YL,"영상 배포하는 Conviva Inc라는 회사는 analytic report를 만들기 위해 하둡을 쓰다가 Spark를 사용"),fn=r(YL,"UL",{});var ey=a(fn);pn=r(ey,"LI",{});var ly=a(pn);p6=s(ly,"40배 빨라짐"),ly.forEach(l),ey.forEach(l),YL.forEach(l),gb.forEach(l),g2=u(e),m(Kt.$$.fragment,e),ev=u(e),Nr=r(e,"P",{});var ty=a(Nr);s6=s(ty,"Traffic Modeling:"),ty.forEach(l),lv=u(e),Fr=r(e,"UL",{});var iy=a(Fr);zr=r(iy,"LI",{});var gL=a(zr);n6=s(gL,"산발적으로 수집된 자동차 GPS 측정치에서 교통 현황을 추정하기 위한 학습 알고리즘을 병렬적으로 구성함."),sn=r(gL,"UL",{});var ry=a(sn);nn=r(ry,"LI",{});var ay=a(nn);u6=s(ay,"두 개의 map과 reduceByKey를 반복적으로 적용하여 모델을 학습시켰고, 성능이 선형적으로 확장됨 (분산처리가 잘 되고 있음)"),ay.forEach(l),ry.forEach(l),gL.forEach(l),iy.forEach(l),tv=u(e),Or=r(e,"P",{});var oy=a(Or);D6=s(oy,"Twitter Spam Classification:"),oy.forEach(l),iv=u(e),Tr=r(e,"UL",{});var fy=a(Tr);qr=r(fy,"LI",{});var e0=a(qr);v6=s(e0,"트위터의 스팸 메시지에서 link를 검증하기 위해 Spark 사용"),Le=r(e0,"UL",{});var ha=a(Le);un=r(ha,"LI",{});var py=a(un);m6=s(py,"앞서 봤던 logistic regression를 사용하였고, URL이 가리키는 페이지 정보를 수집함."),py.forEach(l),E6=u(ha),Dn=r(ha,"LI",{});var sy=a(Dn);_6=s(sy,"성능이 linear하게 늘어나지는 않았음 (communication cost가 iteration보다 높아지기 때문)"),sy.forEach(l),c6=u(ha),vn=r(ha,"LI",{});var ny=a(vn);d6=s(ny,"아마 네트워크에 접속해서 페이지 정보를 읽어와야 하기 때문인 듯"),ny.forEach(l),ha.forEach(l),e0.forEach(l),fy.forEach(l),rv=u(e),Ol=r(e,"H3",{id:!0});var l0=a(Ol);Tl=r(l0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var uy=a(Tl);mn=r(uy,"SPAN",{class:!0}),a(mn).forEach(l),uy.forEach(l),R6=s(l0,"Interactive Data Mining"),l0.forEach(l),av=u(e),m(Wt.$$.fragment,e),ov=s(e,`  
Spark는 거대한 dataset에 대화식 query를 날릴 수 있음
`),ne=r(e,"UL",{});var xa=a(ne);En=r(xa,"LI",{});var Dy=a(En);L6=s(Dy,"(1) => 전체 페이지에 query하여 조회수 확인"),Dy.forEach(l),I6=u(xa),_n=r(xa,"LI",{});var vy=a(_n);k6=s(vy,"(2) => 제목이 주어진 단어와 같은 페이지만 조회수 확인"),vy.forEach(l),b6=u(xa),Jr=r(xa,"LI",{});var t0=a(Jr);y6=s(t0,"(3) => 제목이 부분적으로 일치하는 페이지만 조회수 확인"),cn=r(t0,"UL",{});var my=a(cn);dn=r(my,"LI",{});var Ey=a(dn);S6=s(Ey,"response time이 on-disk에서 하는 것보다 훨씬 빠름 (on-disk는 170초 걸렸다고 함)"),Ey.forEach(l),my.forEach(l),t0.forEach(l),xa.forEach(l),fv=u(e),pv=r(e,"BR",{}),sv=r(e,"BR",{}),nv=u(e),ql=r(e,"H2",{id:!0});var i0=a(ql);Jl=r(i0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var _y=a(Jl);Rn=r(_y,"SPAN",{class:!0}),a(Rn).forEach(l),_y.forEach(l),P6=s(i0,"Discussions"),i0.forEach(l),uv=u(e),Dv=r(e,"HR",{}),vv=u(e),Qr=r(e,"P",{});var cy=a(Qr);$6=s(cy,"RDD는 immutable하고 coarse-grained transformation을 하므로, 제한된 interface만을 제공하는 것처럼 보이지만, 다양한 application에 적합함"),cy.forEach(l),mv=u(e),Ql=r(e,"H3",{id:!0});var r0=a(Ql);Gl=r(r0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var dy=a(Gl);Ln=r(dy,"SPAN",{class:!0}),a(Ln).forEach(l),dy.forEach(l),A6=s(r0,"Expressing Existing Programming Models"),r0.forEach(l),Ev=u(e),Gr=r(e,"P",{});var Ry=a(Gr);h6=s(Ry,"RDD는 지금까지 제안되어 온 다양한 클러스터 프로그래밍 모델을 “효율적으로” 표현할 수 있음"),Ry.forEach(l),_v=u(e),Kl=r(e,"UL",{});var Um=a(Kl);In=r(Um,"LI",{});var Ly=a(In);x6=s(Ly,"효율적이라는 말은, 단순히 이러한 모델로 작성한 프로그램과 동일한 output을 얻을 수 있을 뿐 아니라, 최적화까지 가능함."),Ly.forEach(l),w6=u(Um),kn=r(Um,"LI",{});var Iy=a(kn);M6=s(Iy,"데이터를 memory에 보관하고, communication을 minimize하기 위해 잘 partitioning하고, failure를 효율적으로 recovery함"),Iy.forEach(l),Um.forEach(l),cv=u(e),Kr=r(e,"P",{});var ky=a(Kr);H6=s(ky,"RDD로 표현 가능한 모델"),ky.forEach(l),dv=u(e),T=r(e,"UL",{});var mt=a(T);bn=r(mt,"LI",{});var by=a(bn);U6=s(by,"MapReduce: flatMap, GroupByKey, reduceByKey가 각각 Mapper, Reducer, Combiner에 해당"),by.forEach(l),C6=u(mt),yn=r(mt,"LI",{});var yy=a(yn);j6=s(yy,"DryadLINQ: Spark로도 할 수 있음"),yy.forEach(l),B6=u(mt),Sn=r(mt,"LI",{});var Sy=a(Sn);N6=s(Sy,"SQL: SQL query를 날려서 data-parallel operation을 수행할 수 있음"),Sy.forEach(l),F6=u(mt),Wr=r(mt,"LI",{});var a0=a(Wr);z6=s(a0,"Pregel: Google Pregel은 iterative graph application에 특화된 모델임"),Pn=r(a0,"UL",{});var Py=a(Pn);$n=r(Py,"LI",{});var $y=a($n);O6=s($y,"RDD를 사용하면 Pregel이 하는 것처럼 vertex state를 메모리에 유지하고, Partitioning을 제어하고, 통신을 최소화하고, 장애 시 부분적인 복구를 수행할 수 있다."),$y.forEach(l),Py.forEach(l),a0.forEach(l),mt.forEach(l),Rv=u(e),Vr=r(e,"P",{});var Ay=a(Vr);T6=s(Ay,"Iterative MapReduce"),Ay.forEach(l),Lv=u(e),q=r(e,"UL",{});var Et=a(q);An=r(Et,"LI",{});var hy=a(An);q6=s(hy,"HaLoop 및 Twister 등 MapReduce를 Iterative하게 돌리기 위한 시스템이 있음"),hy.forEach(l),J6=u(Et),hn=r(Et,"LI",{});var xy=a(hn);Q6=s(xy,`얘네의 핵심은 partitioning 및 메모리에 올려놓고 reuse하는 것인데, 이것도 Spark 200줄로 표현이 가능했음
Batched Stream Processing`),xy.forEach(l),G6=u(Et),xn=r(Et,"LI",{});var wy=a(xn);K6=s(wy,"새로운 데이터를 받아서 주기적으로 결과를 업데이트하는 점진적인 시스템"),wy.forEach(l),W6=u(Et),wn=r(Et,"LI",{});var My=a(wn);V6=s(My,"Intermediate state를 RDD로 두면 처리 속도가 향상됨."),My.forEach(l),Et.forEach(l),Iv=u(e),Zr=r(e,"P",{});var Hy=a(Zr);Z6=s(Hy,"RDD가 이렇게 다양한 프로그래밍 모델을 표현할 수 있는 이유는, RDD의 제약조건이 다수의 병렬 어플리케이션에서 큰 의미가 없기 때문임."),Hy.forEach(l),kv=u(e),J=r(e,"UL",{});var _t=a(J);Mn=r(_t,"LI",{});var Uy=a(Mn);X6=s(Uy,"RDD는 오직 transformation을 거쳐서 생성될 수 있음"),Uy.forEach(l),Y6=u(_t),Hn=r(_t,"LI",{});var Cy=a(Hn);g6=s(Cy,"근데 대부분의 병렬 프로그램이 표현을 쉽게 하려고 원래 동일한 연산을 record에 적용하고 있음."),Cy.forEach(l),e7=u(_t),Un=r(_t,"LI",{});var jy=a(Un);l7=s(jy,"동일한 dataset의 버전을 나타내기 위해 여러 개의 RDD를 생성할 수 있기 때문에, RDD의 immutability는 장애물이 아님."),jy.forEach(l),t7=u(_t),Cn=r(_t,"LI",{});var By=a(Cn);i7=s(By,"실제로, 대부분의 MapReduce 애플리케이션은 HDFS 등 파일 업데이트를 허용하지 않는 파일 시스템에서 실행됨."),By.forEach(l),_t.forEach(l),bv=u(e),Xr=r(e,"P",{});var Ny=a(Xr);r7=s(Ny,"이전 프레임워크들은 데이터 공유를 위한 abstraction이 부족했기 때문에 이런 범용성을 가지지 못한 것 같음"),Ny.forEach(l),yv=u(e),Wl=r(e,"H3",{id:!0});var o0=a(Wl);Vl=r(o0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Fy=a(Vl);jn=r(Fy,"SPAN",{class:!0}),a(jn).forEach(l),Fy.forEach(l),a7=s(o0,"Leveraging RDDs for Debugging"),o0.forEach(l),Sv=u(e),Yr=r(e,"P",{});var zy=a(Yr);o7=s(zy,"DD는 fault tolerance를 위해 deterministical하게 다시 계산할 수 있게끔 설계되었지만, 이러한 특성 덕분에 디버깅도 잘함"),zy.forEach(l),Pv=u(e),gr=r(e,"UL",{});var Oy=a(gr);Bn=r(Oy,"LI",{});var Ty=a(Bn);f7=s(Ty,"작업 중 RDD의 lineage를 기록함으로써, RDD를 나중에 재구성하여 사용자가 대화식으로 query할 수 있고, RDD 종속된 파티션을 다시 계산하여 단일 프로세스 디버거에서 job의 모든 task를 다시 실행할 수 있음"),Ty.forEach(l),Oy.forEach(l),$v=u(e),ea=r(e,"P",{});var qy=a(ea);p7=s(qy,"여러 노드에서 이벤트 순서를 캡쳐해야 하는 기존의 general distributed system에서의 replay debugger와는 달리, 이 방식은 RDD lineage graph만을 기록하기 때문에 recording overhead가 거의 없음."),qy.forEach(l),Av=u(e),hv=r(e,"BR",{}),xv=r(e,"BR",{}),wv=u(e),Zl=r(e,"H2",{id:!0});var f0=a(Zl);Xl=r(f0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Jy=a(Xl);Nn=r(Jy,"SPAN",{class:!0}),a(Nn).forEach(l),Jy.forEach(l),s7=s(f0,"Related Work"),f0.forEach(l),Mv=u(e),Hv=r(e,"HR",{}),Uv=u(e),la=r(e,"P",{});var Qy=a(la);n7=s(Qy,"Cluster Programming Models:"),Qy.forEach(l),Cv=u(e),Q=r(e,"OL",{});var ct=a(Q);Vt=r(ct,"LI",{});var Cm=a(Vt);Fn=r(Cm,"P",{});var Gy=a(Fn);u7=s(Gy,"data flow model"),Gy.forEach(l),D7=u(Cm),Zt=r(Cm,"UL",{});var jm=a(Zt);zn=r(jm,"LI",{});var Ky=a(zn);v7=s(Ky,"MapReduce, Dryad, Ciel 등은 데이터 프로세싱을 위한 다양한 Operator 제공"),Ky.forEach(l),m7=u(jm),On=r(jm,"LI",{});var Wy=a(On);E7=s(Wy,"반면 RDD는 data replication, I/O 및 serization의 높은 비용을 피하기 위해 stable storage보다 더 효율적인 abstraction을 제공함."),Wy.forEach(l),jm.forEach(l),Cm.forEach(l),_7=u(ct),Xt=r(ct,"LI",{});var Bm=a(Xt);Tn=r(Bm,"P",{});var Vy=a(Tn);c7=s(Vy,"High level programming interface for data flow system"),Vy.forEach(l),d7=u(Bm),Ie=r(Bm,"UL",{});var wa=a(Ie);qn=r(wa,"LI",{});var Zy=a(qn);R7=s(Zy,"DryadLINQ, FlumeJava는 사용자가 map, join 등의 연산자로 parallel collection에 접근할 수 있는 language-integrated API를 제공"),Zy.forEach(l),L7=u(wa),Jn=r(wa,"LI",{});var Xy=a(Jn);I7=s(Xy,"하지만 이러한 시스템들은 query의 결과를 다른 query로 pipeline하기 어려움"),Xy.forEach(l),k7=u(wa),Qn=r(wa,"LI",{});var Yy=a(Qn);b7=s(Yy,"Spark는 이것이 가능하기 때문에, 다양한 Application에서 활용할 수 있음"),Yy.forEach(l),wa.forEach(l),Bm.forEach(l),y7=u(ct),Yt=r(ct,"LI",{});var Nm=a(Yt);Gn=r(Nm,"P",{});var gy=a(Gn);S7=s(gy,"Pregel, HaLoop, Twister 등은 generic abstraction을 제공하지 않아서 정해진 용도 이외의 용도로 사용하기 어려움."),gy.forEach(l),P7=u(Nm),Kn=r(Nm,"UL",{});var eS=a(Kn);Wn=r(eS,"LI",{});var lS=a(Wn);$7=s(lS,"RDD는 distributed storage abstraction을 제공하여, interactive data mining 등 위의 시스템이 하기 어려운 것도 가능함"),lS.forEach(l),eS.forEach(l),Nm.forEach(l),A7=u(ct),gt=r(ct,"LI",{});var Fm=a(gt);Vn=r(Fm,"P",{});var tS=a(Vn);h7=s(tS,"Piccolo나 RAMCloud 등의 Distributed Shared Memory 기반의 시스템은 사용자가 in-memory computation을 수행할 수 있게끔, shared mutable state를 노출시킴."),tS.forEach(l),x7=u(Fm),ke=r(Fm,"UL",{});var Ma=a(ke);Zn=r(Ma,"LI",{});var iS=a(Zn);w7=s(iS,"RDD는 두 가지 측면에서 이러한 시스템과 다름"),iS.forEach(l),M7=u(Ma),Xn=r(Ma,"LI",{});var rS=a(Xn);H7=s(rS,"RDD는 map, sort, join 등 high level interface를 제공하는 반면, 위의 애들은 table cell에 대한 read/update밖에 지원하지 않음"),rS.forEach(l),U7=u(Ma),Yn=r(Ma,"LI",{});var aS=a(Yn);C7=s(aS,"RDD는 Lineage based라서, 위 애들보다 checkpoint 및 rollback이 덜 무거움"),aS.forEach(l),Ma.forEach(l),Fm.forEach(l),ct.forEach(l),jv=u(e),Yl=r(e,"P",{});var zm=a(Yl);j7=s(zm,"Caching System:"),B7=r(zm,"BR",{}),N7=s(zm,`
Nectar는 DryadLINQ 작업에서 intermediate data를 재사용할 수 있음.`),zm.forEach(l),Bv=u(e),G=r(e,"UL",{});var dt=a(G);gn=r(dt,"LI",{});var oS=a(gn);F7=s(oS,"RDD에서도 이러한 능력을 본땄음"),oS.forEach(l),z7=u(dt),eu=r(dt,"LI",{});var fS=a(eu);O7=s(fS,"근데 Nectar는 in-memory caching을 제공하지 않고, 사용자가 원하는 dataset을 persist 및 partitioning control하게끔 하는 기능이 없음."),fS.forEach(l),T7=u(dt),lu=r(dt,"LI",{});var pS=a(lu);q7=s(pS,"CIel 및 FlumeJava는 in-memory로 caching을 지원하지 않고, 원하는 데이터를 caching할 수 없음"),pS.forEach(l),J7=u(dt),tu=r(dt,"LI",{});var sS=a(tu);Q7=s(sS,"분산 파일 시스템에 대한 인메모리 캐시도 제시되었지만, RDD처럼 중간 결과를 sharing하는 것보다는 약간 모자람"),sS.forEach(l),dt.forEach(l),Nv=u(e),gl=r(e,"P",{});var Om=a(gl);G7=s(Om,"Lineage:"),K7=r(Om,"BR",{}),W7=s(Om,`
Lineage를 capture하는 것은 오랜 연구 주제였음.`),Om.forEach(l),Fv=u(e),ue=r(e,"UL",{});var Ha=a(ue);iu=r(Ha,"LI",{});var nS=a(iu);V7=s(nS,"RDD는 fine-grained lineage를 capture하는 데 비용이 적게 드는 병렬 프로그래밍 모델을 제공하여, 장애 복구에 사용할 수 있도록 함."),nS.forEach(l),Z7=u(Ha),ru=r(Ha,"LI",{});var uS=a(ru);X7=s(uS,"이러한 lineage based의 회복 매커니즘은 MapReduce나 Dryad의 메커니즘하고 비슷하지만, 얘네들은 job이 끝나면 lineage를 잃어버리므로, 컴퓨팅 간에 데이터를 공유하려면 replicated storage를 사용해야 함"),uS.forEach(l),Y7=u(Ha),au=r(Ha,"LI",{});var DS=a(au);g7=s(DS,"반면 RDD는 disk I/O나 replication 없이 lineage를 써서, 데이터가 메모리에 지속되게 하여 효율적으로 데이터를 공유할 수 있음."),DS.forEach(l),Ha.forEach(l),zv=u(e),et=r(e,"P",{});var Tm=a(et);eL=s(Tm,"Relational Database:"),lL=r(Tm,"BR",{}),tL=s(Tm,`
RDMS는 fine-grained이며 모든 record에 대한 read/write 접근을 허용함. 또한 fault tolerance, logging operation, consistency를 유지해야 함`),Tm.forEach(l),Ov=u(e),ta=r(e,"UL",{});var vS=a(ta);ou=r(vS,"LI",{});var mS=a(ou);iL=s(mS,"반면 RDS는 coarse-grained이므로 이런거 할 필요가 없음"),mS.forEach(l),vS.forEach(l),Tv=u(e),qv=r(e,"BR",{}),Jv=r(e,"BR",{}),Qv=u(e),lt=r(e,"H2",{id:!0});var p0=a(lt);tt=r(p0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ES=a(tt);fu=r(ES,"SPAN",{class:!0}),a(fu).forEach(l),ES.forEach(l),rL=s(p0,"Conclusion"),p0.forEach(l),Gv=u(e),Kv=r(e,"HR",{}),Wv=u(e),ia=r(e,"P",{});var _S=a(ia);aL=s(_S,"RDD : cluster application에서 데이터를 sharing하는 abstraction"),_S.forEach(l),Vv=u(e),ra=r(e,"UL",{});var cS=a(ra);pu=r(cS,"LI",{});var dS=a(pu);oL=s(dS,"효율적인, general-purpose, fault-tolerance를 제공"),dS.forEach(l),cS.forEach(l),Zv=u(e),aa=r(e,"P",{});var RS=a(aa);fL=s(RS,"RDD는 다양한 종류의 병렬 application을 표현할 수 있음"),RS.forEach(l),Xv=u(e),oa=r(e,"UL",{});var LS=a(oa);su=r(LS,"LI",{});var IS=a(su);pL=s(IS,"iterative computation을 위해 제안된 많은 특화된 프로그래밍 모델과, 이러한 모델이 캡처하지 못하는 새로운 응용 프로그램 등 다양한 병렬 애플리케이션을 표현할 수 있음."),IS.forEach(l),LS.forEach(l),Yv=u(e),fa=r(e,"P",{});var kS=a(fa);sL=s(kS,"fault tolerance를 위해 data replicating을 선택하는 기존 cluster의 storage abstraction과는 달리, RDD는 coarse-grained transformation 기반의 API를 제공"),kS.forEach(l),gv=u(e),pa=r(e,"UL",{});var bS=a(pa);nu=r(bS,"LI",{});var yS=a(nu);nL=s(yS,"lineage를 통해 효율적으로 recover 가능"),yS.forEach(l),bS.forEach(l),em=u(e),sa=r(e,"P",{});var SS=a(sa);uL=s(SS,`RDD가 구현된 시스템인 Spark의 성능은 interactive application에서 Hadoop보다 20배 뛰어남.
또한 100기가바이트 대의 데이터에 대화형 쿼리를 날릴 수도 있다.`),SS.forEach(l),this.h()},h(){D(Rt,"class","icon icon-link"),D(S,"aria-hidden","true"),D(S,"tabindex","-1"),D(S,"href","#abstraction"),D(y,"id","abstraction"),D(Ka,"class","icon icon-link"),D(ye,"aria-hidden","true"),D(ye,"tabindex","-1"),D(ye,"href","#introduce"),D(be,"id","introduce"),D(_o,"class","icon icon-link"),D(xe,"aria-hidden","true"),D(xe,"tabindex","-1"),D(xe,"href","#resilient-distributed-datasetsrdd"),D(he,"id","resilient-distributed-datasetsrdd"),D(co,"class","icon icon-link"),D(Me,"aria-hidden","true"),D(Me,"tabindex","-1"),D(Me,"href","#rdd-abstraction"),D(we,"id","rdd-abstraction"),D($o,"class","icon icon-link"),D(Ce,"aria-hidden","true"),D(Ce,"tabindex","-1"),D(Ce,"href","#spark-programming-interface"),D(Ue,"id","spark-programming-interface"),D(No,"class","icon icon-link"),D(Be,"aria-hidden","true"),D(Be,"tabindex","-1"),D(Be,"href","#example-console-log-mining"),D(je,"id","example-console-log-mining"),D(Zo,"class","icon icon-link"),D(Te,"aria-hidden","true"),D(Te,"tabindex","-1"),D(Te,"href","#advantages-of-the-rdd-model"),D(Oe,"id","advantages-of-the-rdd-model"),D(ht,"start","2"),D(Df,"class","icon icon-link"),D(Qe,"aria-hidden","true"),D(Qe,"tabindex","-1"),D(Qe,"href","#application-not-suitable-for-rdds"),D(Je,"id","application-not-suitable-for-rdds"),D(df,"class","icon icon-link"),D(Ke,"aria-hidden","true"),D(Ke,"tabindex","-1"),D(Ke,"href","#spark-programming-interfaces"),D(Ge,"id","spark-programming-interfaces"),D($f,"class","icon icon-link"),D(Xe,"aria-hidden","true"),D(Xe,"tabindex","-1"),D(Xe,"href","#rdd-operations-in-spark"),D(Ze,"id","rdd-operations-in-spark"),D(Mf,"class","icon icon-link"),D(el,"aria-hidden","true"),D(el,"tabindex","-1"),D(el,"href","#example-logistic-regression"),D(ge,"id","example-logistic-regression"),D(Ff,"class","icon icon-link"),D(il,"aria-hidden","true"),D(il,"tabindex","-1"),D(il,"href","#example-pagerank"),D(tl,"id","example-pagerank"),D(ip,"class","icon icon-link"),D(ol,"aria-hidden","true"),D(ol,"tabindex","-1"),D(ol,"href","#representing-rdds"),D(al,"id","representing-rdds"),D(Up,"class","icon icon-link"),D(ul,"aria-hidden","true"),D(ul,"tabindex","-1"),D(ul,"href","#implementation"),D(nl,"id","implementation"),D(Fp,"class","icon icon-link"),D(El,"aria-hidden","true"),D(El,"tabindex","-1"),D(El,"href","#job-scheduling"),D(ml,"id","job-scheduling"),D(gp,"class","icon icon-link"),D(Rl,"aria-hidden","true"),D(Rl,"tabindex","-1"),D(Rl,"href","#interpreter-integration"),D(dl,"id","interpreter-integration"),D(ps,"class","icon icon-link"),D(kl,"aria-hidden","true"),D(kl,"tabindex","-1"),D(kl,"href","#memory-management"),D(Il,"id","memory-management"),D(Rs,"class","icon icon-link"),D(yl,"aria-hidden","true"),D(yl,"tabindex","-1"),D(yl,"href","#support-for-checkpointing"),D(bl,"id","support-for-checkpointing"),D(As,"class","icon icon-link"),D(Al,"aria-hidden","true"),D(Al,"tabindex","-1"),D(Al,"href","#evaluation"),D($l,"id","evaluation"),D(Cs,"class","icon icon-link"),D(xl,"aria-hidden","true"),D(xl,"tabindex","-1"),D(xl,"href","#iterative-machine-learning-applications"),D(hl,"id","iterative-machine-learning-applications"),D(Ws,"class","icon icon-link"),D(Hl,"aria-hidden","true"),D(Hl,"tabindex","-1"),D(Hl,"href","#pagerank"),D(Ml,"id","pagerank"),D(Xs,"class","icon icon-link"),D(jl,"aria-hidden","true"),D(jl,"tabindex","-1"),D(jl,"href","#fault-recovery"),D(Cl,"id","fault-recovery"),D(an,"class","icon icon-link"),D(Nl,"aria-hidden","true"),D(Nl,"tabindex","-1"),D(Nl,"href","#behavior-with-insufficient-memory"),D(Bl,"id","behavior-with-insufficient-memory"),D(on,"class","icon icon-link"),D(zl,"aria-hidden","true"),D(zl,"tabindex","-1"),D(zl,"href","#user-applications-built-with-spark"),D(Fl,"id","user-applications-built-with-spark"),D(mn,"class","icon icon-link"),D(Tl,"aria-hidden","true"),D(Tl,"tabindex","-1"),D(Tl,"href","#interactive-data-mining"),D(Ol,"id","interactive-data-mining"),D(Rn,"class","icon icon-link"),D(Jl,"aria-hidden","true"),D(Jl,"tabindex","-1"),D(Jl,"href","#discussions"),D(ql,"id","discussions"),D(Ln,"class","icon icon-link"),D(Gl,"aria-hidden","true"),D(Gl,"tabindex","-1"),D(Gl,"href","#expressing-existing-programming-models"),D(Ql,"id","expressing-existing-programming-models"),D(jn,"class","icon icon-link"),D(Vl,"aria-hidden","true"),D(Vl,"tabindex","-1"),D(Vl,"href","#leveraging-rdds-for-debugging"),D(Wl,"id","leveraging-rdds-for-debugging"),D(Nn,"class","icon icon-link"),D(Xl,"aria-hidden","true"),D(Xl,"tabindex","-1"),D(Xl,"href","#related-work"),D(Zl,"id","related-work"),D(fu,"class","icon icon-link"),D(tt,"aria-hidden","true"),D(tt,"tabindex","-1"),D(tt,"href","#conclusion"),D(lt,"id","conclusion")},m(e,o){f(e,y,o),t(y,S),t(S,Rt),t(y,Jm),f(e,mu,o),f(e,ei,o),t(ei,Qm),f(e,Eu,o),f(e,k,o),t(k,Ua),t(Ua,Ca),t(Ca,Gm),t(k,Km),t(k,ja),t(ja,Ba),t(Ba,Wm),t(k,Vm),t(k,Lt),t(Lt,Na),t(Na,Zm),t(Lt,Xm),t(Lt,It),t(It,Fa),t(Fa,Ym),t(It,gm),t(It,za),t(za,eE),t(k,lE),t(k,Oa),t(Oa,Ta),t(Ta,tE),t(k,iE),t(k,qa),t(qa,Ja),t(Ja,rE),t(k,aE),t(k,Qa),t(Qa,Ga),t(Ga,oE),f(e,_u,o),f(e,cu,o),f(e,du,o),f(e,Ru,o),f(e,be,o),t(be,ye),t(ye,Ka),t(be,fE),f(e,Lu,o),f(e,Iu,o),f(e,ku,o),f(e,li,o),t(li,pE),f(e,bu,o),f(e,W,o),t(W,Wa),t(Wa,sE),t(W,nE),t(W,Va),t(Va,uE),t(W,DE),t(W,Za),t(Za,vE),f(e,yu,o),f(e,ti,o),t(ti,mE),f(e,Su,o),f(e,w,o),t(w,Xa),t(Xa,EE),t(w,_E),t(w,Ya),t(Ya,cE),t(w,dE),t(w,ga),t(ga,RE),t(w,LE),t(w,eo),t(eo,IE),f(e,Pu,o),f(e,ii,o),t(ii,kE),f(e,$u,o),f(e,V,o),t(V,lo),t(lo,bE),t(V,yE),t(V,to),t(to,SE),t(V,PE),t(V,io),t(io,$E),f(e,Au,o),f(e,ri,o),t(ri,AE),f(e,hu,o),f(e,Se,o),t(Se,ro),t(ro,hE),t(Se,xE),t(Se,ao),t(ao,wE),f(e,xu,o),f(e,ai,o),t(ai,ME),f(e,wu,o),f(e,M,o),t(M,oo),t(oo,HE),t(M,UE),t(M,fo),t(fo,CE),t(M,jE),t(M,po),t(po,BE),t(M,NE),t(M,so),t(so,FE),f(e,Mu,o),f(e,oi,o),t(oi,zE),f(e,Hu,o),f(e,Pe,o),t(Pe,no),t(no,OE),t(Pe,TE),t(Pe,uo),t(uo,qE),f(e,Uu,o),f(e,fi,o),t(fi,JE),f(e,Cu,o),f(e,$e,o),t($e,Do),t(Do,QE),t($e,GE),t($e,vo),t(vo,KE),f(e,ju,o),f(e,pi,o),t(pi,WE),f(e,Bu,o),f(e,Ae,o),t(Ae,mo),t(mo,VE),t(Ae,ZE),t(Ae,Eo),t(Eo,XE),f(e,Nu,o),f(e,Fu,o),f(e,zu,o),f(e,Ou,o),f(e,he,o),t(he,xe),t(xe,_o),t(he,YE),f(e,Tu,o),f(e,qu,o),f(e,Ju,o),f(e,we,o),t(we,Me),t(Me,co),t(we,gE),f(e,Qu,o),f(e,si,o),t(si,e_),f(e,Gu,o),f(e,Z,o),t(Z,Ro),t(Ro,l_),t(Z,t_),t(Z,Lo),t(Lo,i_),t(Z,r_),t(Z,Io),t(Io,a_),f(e,Ku,o),f(e,ni,o),t(ni,o_),f(e,Wu,o),f(e,He,o),t(He,ko),t(ko,f_),t(He,p_),t(He,bo),t(bo,s_),f(e,Vu,o),f(e,ui,o),t(ui,n_),f(e,Zu,o),f(e,X,o),t(X,yo),t(yo,u_),t(X,D_),t(X,So),t(So,v_),t(X,m_),t(X,Po),t(Po,E_),f(e,Xu,o),f(e,Ue,o),t(Ue,Ce),t(Ce,$o),t(Ue,__),f(e,Yu,o),f(e,Di,o),t(Di,c_),f(e,gu,o),f(e,vi,o),t(vi,Ao),t(Ao,d_),f(e,e1,o),f(e,mi,o),t(mi,R_),f(e,l1,o),f(e,Y,o),t(Y,ho),t(ho,L_),t(Y,I_),t(Y,Ei),t(Ei,k_),t(Ei,_e),t(_e,xo),t(xo,b_),t(_e,y_),t(_e,wo),t(wo,S_),t(_e,P_),t(_e,Mo),t(Mo,$_),t(Y,A_),t(Y,Ho),t(Ho,h_),f(e,t1,o),f(e,_i,o),t(_i,x_),f(e,i1,o),f(e,H,o),t(H,Uo),t(Uo,w_),t(H,M_),t(H,Co),t(Co,H_),t(H,U_),t(H,jo),t(jo,C_),t(H,j_),t(H,Bo),t(Bo,B_),f(e,r1,o),f(e,je,o),t(je,Be),t(Be,No),t(je,N_),f(e,a1,o),f(e,ci,o),t(ci,F_),f(e,o1,o),f(e,di,o),t(di,kt),t(kt,z_),E(bt,kt,null),t(kt,O_),f(e,f1,o),f(e,Ri,o),t(Ri,T_),f(e,p1,o),E(yt,e,o),f(e,s1,o),f(e,Li,o),t(Li,q_),f(e,n1,o),E(St,e,o),f(e,u1,o),f(e,ce,o),t(ce,Fo),t(Fo,J_),t(ce,Q_),t(ce,zo),t(zo,G_),t(ce,K_),f(e,D1,o),f(e,Ne,o),t(Ne,Oo),E(Fe,Oo,null),t(Ne,W_),t(Ne,To),t(To,V_),f(e,v1,o),f(e,Ii,o),t(Ii,Z_),f(e,m1,o),E(Pt,e,o),f(e,E1,o),f(e,U,o),t(U,ki),t(ki,X_),t(ki,de),t(de,$t),t($t,Y_),t($t,qo),t(qo,g_),t($t,e3),t(de,l3),t(de,Jo),t(Jo,t3),t(de,i3),t(de,Qo),t(Qo,r3),t(U,a3),t(U,Go),t(Go,o3),t(U,f3),t(U,ze),t(ze,Ko),t(Ko,p3),t(ze,s3),t(ze,Wo),t(Wo,n3),t(ze,u3),t(U,D3),t(U,Vo),t(Vo,v3),f(e,_1,o),f(e,Oe,o),t(Oe,Te),t(Te,Zo),t(Oe,m3),f(e,c1,o),E(At,e,o),f(e,d1,o),f(e,bi,o),t(bi,E3),f(e,R1,o),f(e,R,o),t(R,Xo),t(Xo,_3),t(R,c3),t(R,Yo),t(Yo,d3),t(R,R3),t(R,go),t(go,L3),t(R,I3),t(R,ef),t(ef,k3),t(R,b3),t(R,lf),t(lf,y3),t(R,S3),t(R,tf),t(tf,P3),t(R,$3),t(R,rf),t(rf,A3),t(R,h3),t(R,af),t(af,x3),f(e,L1,o),f(e,yi,o),t(yi,w3),f(e,I1,o),f(e,qe,o),t(qe,of),t(of,ff),t(ff,pf),t(pf,M3),t(qe,H3),t(qe,Si),t(Si,ht),t(ht,sf),t(sf,U3),t(ht,C3),t(Si,nf),t(nf,uf),t(uf,j3),f(e,k1,o),f(e,Je,o),t(Je,Qe),t(Qe,Df),t(Je,B3),f(e,b1,o),f(e,Pi,o),t(Pi,N3),f(e,y1,o),f(e,$i,o),t($i,vf),t(vf,F3),f(e,S1,o),f(e,Ai,o),t(Ai,z3),f(e,P1,o),f(e,g,o),t(g,hi),t(hi,O3),t(hi,xt),t(xt,mf),t(mf,T3),t(xt,q3),t(xt,Ef),t(Ef,J3),t(g,Q3),t(g,_f),t(_f,G3),t(g,K3),t(g,cf),t(cf,W3),f(e,$1,o),f(e,A1,o),f(e,h1,o),f(e,x1,o),f(e,Ge,o),t(Ge,Ke),t(Ke,df),t(Ge,V3),f(e,w1,o),f(e,M1,o),f(e,H1,o),f(e,xi,o),t(xi,Z3),f(e,U1,o),f(e,wi,o),t(wi,Rf),t(Rf,X3),f(e,C1,o),f(e,Mi,o),t(Mi,Y3),f(e,j1,o),f(e,ee,o),t(ee,Lf),t(Lf,g3),t(ee,ec),t(ee,If),t(If,lc),t(ee,tc),t(ee,kf),t(kf,ic),f(e,B1,o),f(e,Hi,o),t(Hi,rc),f(e,N1,o),f(e,We,o),t(We,bf),t(bf,ac),t(We,oc),t(We,yf),t(yf,fc),f(e,F1,o),f(e,Ui,o),t(Ui,pc),f(e,z1,o),f(e,Ve,o),t(Ve,Sf),t(Sf,sc),t(Ve,nc),t(Ve,Pf),t(Pf,uc),f(e,O1,o),f(e,Ze,o),t(Ze,Xe),t(Xe,$f),t(Ze,Dc),f(e,T1,o),E(wt,e,o),f(e,q1,o),f(e,Ye,o),t(Ye,Af),t(Af,vc),t(Ye,mc),t(Ye,hf),t(hf,Ec),f(e,J1,o),f(e,Ci,o),t(Ci,_c),f(e,Q1,o),f(e,ji,o),t(ji,xf),t(xf,cc),f(e,G1,o),f(e,Bi,o),t(Bi,dc),f(e,K1,o),f(e,Ni,o),t(Ni,wf),t(wf,Rc),f(e,W1,o),f(e,ge,o),t(ge,el),t(el,Mf),t(ge,Lc),f(e,V1,o),f(e,Fi,o),t(Fi,Ic),f(e,Z1,o),f(e,ll,o),t(ll,Hf),t(Hf,kc),t(ll,bc),t(ll,Uf),t(Uf,yc),f(e,X1,o),E(Mt,e,o),f(e,Y1,o),f(e,zi,o),t(zi,Sc),f(e,g1,o),f(e,C,o),t(C,Cf),t(Cf,Pc),t(C,$c),t(C,Oi),t(Oi,Ac),t(Oi,jf),t(jf,hc),t(C,xc),t(C,Ht),t(Ht,wc),t(Ht,Bf),t(Bf,Mc),t(Ht,Hc),t(C,Uc),t(C,Nf),t(Nf,Cc),f(e,eD,o),f(e,tl,o),t(tl,il),t(il,Ff),t(tl,jc),f(e,lD,o),f(e,Ti,o),t(Ti,zf),t(zf,Bc),f(e,tD,o),f(e,qi,o),t(qi,Nc),f(e,iD,o),f(e,rl,o),t(rl,Of),t(Of,Fc),t(rl,zc),t(rl,Tf),t(Tf,Oc),f(e,rD,o),f(e,Ji,o),t(Ji,Tc),f(e,aD,o),E(Ut,e,o),f(e,oD,o),f(e,I,o),t(I,x),t(x,qc),t(x,qf),t(qf,Jc),t(x,Qc),t(x,Jf),t(Jf,Gc),t(x,Kc),t(x,Qf),t(Qf,Wc),t(x,Vc),t(x,Gf),t(Gf,Zc),t(x,Xc),t(I,Yc),t(I,Kf),t(Kf,gc),t(I,ed),t(I,Wf),t(Wf,ld),t(I,td),t(I,Vf),t(Vf,id),t(I,rd),t(I,Zf),t(Zf,ad),t(I,od),t(I,Xf),t(Xf,fd),t(I,pd),t(I,Yf),t(Yf,sd),f(e,fD,o),f(e,Qi,o),t(Qi,nd),f(e,pD,o),f(e,P,o),t(P,gf),t(gf,ud),t(P,Dd),t(P,ep),t(ep,vd),t(P,md),t(P,lp),t(lp,Ed),t(P,_d),t(P,Gi),t(Gi,cd),E(Ct,Gi,null),t(P,dd),t(P,tp),t(tp,Rd),f(e,sD,o),f(e,nD,o),f(e,uD,o),f(e,DD,o),f(e,al,o),t(al,ol),t(ol,ip),t(al,Ld),f(e,vD,o),f(e,mD,o),f(e,ED,o),f(e,Ki,o),t(Ki,Id),f(e,_D,o),f(e,j,o),t(j,rp),t(rp,kd),t(j,bd),t(j,ap),t(ap,yd),t(j,Sd),t(j,op),t(op,Pd),t(j,$d),t(j,fp),t(fp,Ad),f(e,cD,o),f(e,Wi,o),t(Wi,hd),f(e,dD,o),f(e,B,o),t(B,pp),t(pp,xd),t(B,wd),t(B,sp),t(sp,Md),t(B,Hd),t(B,np),t(np,Ud),t(B,Cd),t(B,Vi),t(Vi,jd),t(Vi,Re),t(Re,Zi),t(Zi,Bd),E(jt,Zi,null),t(Re,Nd),t(Re,up),t(up,Fd),t(Re,zd),t(Re,Dp),t(Dp,Od),f(e,RD,o),E(Bt,e,o),f(e,LD,o),f(e,le,o),t(le,vp),t(vp,Td),t(le,qd),t(le,mp),t(mp,Jd),t(le,Qd),t(le,Ep),t(Ep,Gd),f(e,ID,o),f(e,Xi,o),t(Xi,Kd),f(e,kD,o),f(e,fl,o),t(fl,_p),t(_p,cp),t(cp,Wd),t(fl,Vd),t(fl,dp),t(dp,Rp),t(Rp,Zd),f(e,bD,o),f(e,Yi,o),t(Yi,Xd),f(e,yD,o),f(e,gi,o),t(gi,Yd),f(e,SD,o),f(e,N,o),t(N,Lp),t(Lp,gd),t(N,e4),t(N,Ip),t(Ip,l4),t(N,t4),t(N,kp),t(kp,i4),t(N,r4),t(N,bp),t(bp,a4),f(e,PD,o),f(e,er,o),t(er,o4),f(e,$D,o),f(e,pl,o),t(pl,yp),t(yp,f4),t(pl,p4),t(pl,Sp),t(Sp,s4),f(e,AD,o),f(e,lr,o),t(lr,n4),f(e,hD,o),f(e,sl,o),t(sl,Pp),t(Pp,u4),t(sl,D4),t(sl,$p),t($p,v4),f(e,xD,o),f(e,tr,o),t(tr,m4),f(e,wD,o),f(e,ir,o),t(ir,Ap),t(Ap,E4),f(e,MD,o),f(e,rr,o),t(rr,_4),f(e,HD,o),f(e,$,o),t($,hp),t(hp,c4),t($,d4),t($,xp),t(xp,R4),t($,L4),t($,wp),t(wp,I4),t($,k4),t($,Mp),t(Mp,b4),t($,y4),t($,Hp),t(Hp,S4),f(e,UD,o),f(e,CD,o),f(e,jD,o),f(e,BD,o),f(e,nl,o),t(nl,ul),t(ul,Up),t(nl,P4),f(e,ND,o),f(e,FD,o),f(e,zD,o),f(e,ar,o),t(ar,$4),f(e,OD,o),f(e,Dl,o),t(Dl,Cp),t(Cp,A4),t(Dl,h4),t(Dl,jp),t(jp,x4),f(e,TD,o),f(e,or,o),t(or,w4),f(e,qD,o),f(e,vl,o),t(vl,Bp),t(Bp,M4),t(vl,H4),t(vl,Np),t(Np,U4),f(e,JD,o),f(e,ml,o),t(ml,El),t(El,Fp),t(ml,C4),f(e,QD,o),E(Nt,e,o),f(e,GD,o),f(e,fr,o),t(fr,j4),f(e,KD,o),f(e,A,o),t(A,zp),t(zp,B4),t(A,N4),t(A,Op),t(Op,F4),t(A,z4),t(A,Tp),t(Tp,O4),t(A,T4),t(A,qp),t(qp,q4),t(A,J4),t(A,Jp),t(Jp,Q4),f(e,WD,o),f(e,pr,o),t(pr,G4),f(e,VD,o),f(e,te,o),t(te,Qp),t(Qp,K4),t(te,W4),t(te,Gp),t(Gp,V4),t(te,Z4),t(te,Kp),t(Kp,X4),f(e,ZD,o),f(e,_l,o),t(_l,Wp),t(Wp,Y4),t(_l,g4),t(_l,sr),t(sr,e5),t(sr,Vp),t(Vp,Zp),t(Zp,l5),f(e,XD,o),f(e,nr,o),t(nr,t5),f(e,YD,o),f(e,cl,o),t(cl,Xp),t(Xp,i5),t(cl,r5),t(cl,Yp),t(Yp,a5),f(e,gD,o),f(e,dl,o),t(dl,Rl),t(Rl,gp),t(dl,o5),f(e,e2,o),f(e,ur,o),t(ur,f5),f(e,l2,o),f(e,Dr,o),t(Dr,es),t(es,p5),f(e,t2,o),f(e,vr,o),t(vr,s5),f(e,i2,o),f(e,F,o),t(F,ls),t(ls,n5),t(F,u5),t(F,ts),t(ts,D5),t(F,v5),t(F,is),t(is,m5),t(F,E5),t(F,rs),t(rs,_5),f(e,r2,o),f(e,mr,o),t(mr,c5),f(e,a2,o),f(e,Ll,o),t(Ll,as),t(as,d5),t(Ll,R5),t(Ll,Er),t(Er,L5),t(Er,Ft),t(Ft,os),t(os,I5),t(Ft,k5),t(Ft,fs),t(fs,b5),f(e,o2,o),E(zt,e,o),f(e,f2,o),f(e,_r,o),t(_r,y5),f(e,p2,o),f(e,Il,o),t(Il,kl),t(kl,ps),t(Il,S5),f(e,s2,o),f(e,cr,o),t(cr,P5),f(e,n2,o),f(e,ie,o),t(ie,dr),t(dr,$5),t(dr,ss),t(ss,ns),t(ns,A5),t(ie,h5),t(ie,Rr),t(Rr,x5),t(Rr,us),t(us,Ds),t(Ds,w5),t(ie,M5),t(ie,Lr),t(Lr,H5),t(Lr,vs),t(vs,ms),t(ms,U5),f(e,u2,o),f(e,Ir,o),t(Ir,C5),f(e,D2,o),f(e,z,o),t(z,Es),t(Es,j5),t(z,B5),t(z,_s),t(_s,N5),t(z,F5),t(z,cs),t(cs,z5),t(z,O5),t(z,ds),t(ds,T5),f(e,v2,o),f(e,bl,o),t(bl,yl),t(yl,Rs),t(bl,q5),f(e,m2,o),f(e,kr,o),t(kr,J5),f(e,E2,o),f(e,br,o),t(br,Ls),t(Ls,Q5),f(e,_2,o),f(e,yr,o),t(yr,G5),f(e,c2,o),f(e,re,o),t(re,Is),t(Is,K5),t(re,W5),t(re,ks),t(ks,V5),t(re,Z5),t(re,bs),t(bs,X5),f(e,d2,o),f(e,Sr,o),t(Sr,Y5),f(e,R2,o),f(e,Sl,o),t(Sl,ys),t(ys,g5),t(Sl,eR),t(Sl,Ss),t(Ss,lR),f(e,L2,o),f(e,Pr,o),t(Pr,tR),f(e,I2,o),f(e,Pl,o),t(Pl,Ps),t(Ps,iR),t(Pl,rR),t(Pl,$s),t($s,aR),f(e,k2,o),f(e,b2,o),f(e,y2,o),f(e,S2,o),f(e,$l,o),t($l,Al),t(Al,As),t($l,oR),f(e,P2,o),f(e,$2,o),f(e,A2,o),f(e,$r,o),t($r,fR),f(e,h2,o),f(e,O,o),t(O,Ar),t(Ar,pR),t(Ar,hs),t(hs,xs),t(xs,sR),t(O,nR),t(O,hr),t(hr,uR),t(hr,ws),t(ws,Ms),t(Ms,DR),t(O,vR),t(O,Hs),t(Hs,mR),t(O,ER),t(O,Us),t(Us,_R),f(e,x2,o),f(e,hl,o),t(hl,xl),t(xl,Cs),t(hl,cR),f(e,w2,o),E(Ot,e,o),f(e,M2,o),f(e,ae,o),t(ae,js),t(js,dR),t(ae,RR),t(ae,Bs),t(Bs,LR),t(ae,IR),t(ae,xr),t(xr,kR),t(xr,Tt),t(Tt,Ns),t(Ns,bR),t(Tt,yR),t(Tt,Fs),t(Fs,SR),f(e,H2,o),f(e,wr,o),t(wr,PR),f(e,U2,o),f(e,oe,o),t(oe,zs),t(zs,$R),t(oe,AR),t(oe,Os),t(Os,hR),t(oe,xR),t(oe,Ts),t(Ts,wR),f(e,C2,o),f(e,Mr,o),t(Mr,MR),f(e,j2,o),f(e,Hr,o),t(Hr,HR),f(e,B2,o),f(e,fe,o),t(fe,qs),t(qs,UR),t(fe,CR),t(fe,Js),t(Js,jR),t(fe,BR),t(fe,Qs),t(Qs,NR),f(e,N2,o),E(qt,e,o),f(e,F2,o),f(e,wl,o),t(wl,Gs),t(Gs,FR),t(wl,zR),t(wl,Ks),t(Ks,OR),f(e,z2,o),f(e,Ml,o),t(Ml,Hl),t(Hl,Ws),t(Ml,TR),f(e,O2,o),E(Jt,e,o),f(e,T2,o),f(e,Ul,o),t(Ul,Vs),t(Vs,qR),t(Ul,JR),t(Ul,Zs),t(Zs,QR),f(e,q2,o),f(e,Cl,o),t(Cl,jl),t(jl,Xs),t(Cl,GR),f(e,J2,o),E(Qt,e,o),f(e,Q2,o),f(e,pe,o),t(pe,Ys),t(Ys,KR),t(pe,WR),t(pe,gs),t(gs,VR),t(pe,ZR),t(pe,en),t(en,XR),f(e,G2,o),f(e,Ur,o),t(Ur,YR),f(e,K2,o),f(e,se,o),t(se,ln),t(ln,gR),t(se,e6),t(se,tn),t(tn,l6),t(se,t6),t(se,rn),t(rn,i6),f(e,W2,o),f(e,Bl,o),t(Bl,Nl),t(Nl,an),t(Bl,r6),f(e,V2,o),E(Gt,e,o),f(e,Z2,o),f(e,Fl,o),t(Fl,zl),t(zl,on),t(Fl,a6),f(e,X2,o),f(e,Cr,o),t(Cr,o6),f(e,Y2,o),f(e,jr,o),t(jr,Br),t(Br,f6),t(Br,fn),t(fn,pn),t(pn,p6),f(e,g2,o),E(Kt,e,o),f(e,ev,o),f(e,Nr,o),t(Nr,s6),f(e,lv,o),f(e,Fr,o),t(Fr,zr),t(zr,n6),t(zr,sn),t(sn,nn),t(nn,u6),f(e,tv,o),f(e,Or,o),t(Or,D6),f(e,iv,o),f(e,Tr,o),t(Tr,qr),t(qr,v6),t(qr,Le),t(Le,un),t(un,m6),t(Le,E6),t(Le,Dn),t(Dn,_6),t(Le,c6),t(Le,vn),t(vn,d6),f(e,rv,o),f(e,Ol,o),t(Ol,Tl),t(Tl,mn),t(Ol,R6),f(e,av,o),E(Wt,e,o),f(e,ov,o),f(e,ne,o),t(ne,En),t(En,L6),t(ne,I6),t(ne,_n),t(_n,k6),t(ne,b6),t(ne,Jr),t(Jr,y6),t(Jr,cn),t(cn,dn),t(dn,S6),f(e,fv,o),f(e,pv,o),f(e,sv,o),f(e,nv,o),f(e,ql,o),t(ql,Jl),t(Jl,Rn),t(ql,P6),f(e,uv,o),f(e,Dv,o),f(e,vv,o),f(e,Qr,o),t(Qr,$6),f(e,mv,o),f(e,Ql,o),t(Ql,Gl),t(Gl,Ln),t(Ql,A6),f(e,Ev,o),f(e,Gr,o),t(Gr,h6),f(e,_v,o),f(e,Kl,o),t(Kl,In),t(In,x6),t(Kl,w6),t(Kl,kn),t(kn,M6),f(e,cv,o),f(e,Kr,o),t(Kr,H6),f(e,dv,o),f(e,T,o),t(T,bn),t(bn,U6),t(T,C6),t(T,yn),t(yn,j6),t(T,B6),t(T,Sn),t(Sn,N6),t(T,F6),t(T,Wr),t(Wr,z6),t(Wr,Pn),t(Pn,$n),t($n,O6),f(e,Rv,o),f(e,Vr,o),t(Vr,T6),f(e,Lv,o),f(e,q,o),t(q,An),t(An,q6),t(q,J6),t(q,hn),t(hn,Q6),t(q,G6),t(q,xn),t(xn,K6),t(q,W6),t(q,wn),t(wn,V6),f(e,Iv,o),f(e,Zr,o),t(Zr,Z6),f(e,kv,o),f(e,J,o),t(J,Mn),t(Mn,X6),t(J,Y6),t(J,Hn),t(Hn,g6),t(J,e7),t(J,Un),t(Un,l7),t(J,t7),t(J,Cn),t(Cn,i7),f(e,bv,o),f(e,Xr,o),t(Xr,r7),f(e,yv,o),f(e,Wl,o),t(Wl,Vl),t(Vl,jn),t(Wl,a7),f(e,Sv,o),f(e,Yr,o),t(Yr,o7),f(e,Pv,o),f(e,gr,o),t(gr,Bn),t(Bn,f7),f(e,$v,o),f(e,ea,o),t(ea,p7),f(e,Av,o),f(e,hv,o),f(e,xv,o),f(e,wv,o),f(e,Zl,o),t(Zl,Xl),t(Xl,Nn),t(Zl,s7),f(e,Mv,o),f(e,Hv,o),f(e,Uv,o),f(e,la,o),t(la,n7),f(e,Cv,o),f(e,Q,o),t(Q,Vt),t(Vt,Fn),t(Fn,u7),t(Vt,D7),t(Vt,Zt),t(Zt,zn),t(zn,v7),t(Zt,m7),t(Zt,On),t(On,E7),t(Q,_7),t(Q,Xt),t(Xt,Tn),t(Tn,c7),t(Xt,d7),t(Xt,Ie),t(Ie,qn),t(qn,R7),t(Ie,L7),t(Ie,Jn),t(Jn,I7),t(Ie,k7),t(Ie,Qn),t(Qn,b7),t(Q,y7),t(Q,Yt),t(Yt,Gn),t(Gn,S7),t(Yt,P7),t(Yt,Kn),t(Kn,Wn),t(Wn,$7),t(Q,A7),t(Q,gt),t(gt,Vn),t(Vn,h7),t(gt,x7),t(gt,ke),t(ke,Zn),t(Zn,w7),t(ke,M7),t(ke,Xn),t(Xn,H7),t(ke,U7),t(ke,Yn),t(Yn,C7),f(e,jv,o),f(e,Yl,o),t(Yl,j7),t(Yl,B7),t(Yl,N7),f(e,Bv,o),f(e,G,o),t(G,gn),t(gn,F7),t(G,z7),t(G,eu),t(eu,O7),t(G,T7),t(G,lu),t(lu,q7),t(G,J7),t(G,tu),t(tu,Q7),f(e,Nv,o),f(e,gl,o),t(gl,G7),t(gl,K7),t(gl,W7),f(e,Fv,o),f(e,ue,o),t(ue,iu),t(iu,V7),t(ue,Z7),t(ue,ru),t(ru,X7),t(ue,Y7),t(ue,au),t(au,g7),f(e,zv,o),f(e,et,o),t(et,eL),t(et,lL),t(et,tL),f(e,Ov,o),f(e,ta,o),t(ta,ou),t(ou,iL),f(e,Tv,o),f(e,qv,o),f(e,Jv,o),f(e,Qv,o),f(e,lt,o),t(lt,tt),t(tt,fu),t(lt,rL),f(e,Gv,o),f(e,Kv,o),f(e,Wv,o),f(e,ia,o),t(ia,aL),f(e,Vv,o),f(e,ra,o),t(ra,pu),t(pu,oL),f(e,Zv,o),f(e,aa,o),t(aa,fL),f(e,Xv,o),f(e,oa,o),t(oa,su),t(su,pL),f(e,Yv,o),f(e,fa,o),t(fa,sL),f(e,gv,o),f(e,pa,o),t(pa,nu),t(nu,nL),f(e,em,o),f(e,sa,o),t(sa,uL),lm=!0},p(e,[o]){const uu={};o&1&&(uu.$$scope={dirty:o,ctx:e}),Fe.$set(uu)},i(e){lm||(_(bt.$$.fragment,e),_(yt.$$.fragment,e),_(St.$$.fragment,e),_(Fe.$$.fragment,e),_(Pt.$$.fragment,e),_(At.$$.fragment,e),_(wt.$$.fragment,e),_(Mt.$$.fragment,e),_(Ut.$$.fragment,e),_(Ct.$$.fragment,e),_(jt.$$.fragment,e),_(Bt.$$.fragment,e),_(Nt.$$.fragment,e),_(zt.$$.fragment,e),_(Ot.$$.fragment,e),_(qt.$$.fragment,e),_(Jt.$$.fragment,e),_(Qt.$$.fragment,e),_(Gt.$$.fragment,e),_(Kt.$$.fragment,e),_(Wt.$$.fragment,e),lm=!0)},o(e){c(bt.$$.fragment,e),c(yt.$$.fragment,e),c(St.$$.fragment,e),c(Fe.$$.fragment,e),c(Pt.$$.fragment,e),c(At.$$.fragment,e),c(wt.$$.fragment,e),c(Mt.$$.fragment,e),c(Ut.$$.fragment,e),c(Ct.$$.fragment,e),c(jt.$$.fragment,e),c(Bt.$$.fragment,e),c(Nt.$$.fragment,e),c(zt.$$.fragment,e),c(Ot.$$.fragment,e),c(qt.$$.fragment,e),c(Jt.$$.fragment,e),c(Qt.$$.fragment,e),c(Gt.$$.fragment,e),c(Kt.$$.fragment,e),c(Wt.$$.fragment,e),lm=!1},d(e){e&&l(y),e&&l(mu),e&&l(ei),e&&l(Eu),e&&l(k),e&&l(_u),e&&l(cu),e&&l(du),e&&l(Ru),e&&l(be),e&&l(Lu),e&&l(Iu),e&&l(ku),e&&l(li),e&&l(bu),e&&l(W),e&&l(yu),e&&l(ti),e&&l(Su),e&&l(w),e&&l(Pu),e&&l(ii),e&&l($u),e&&l(V),e&&l(Au),e&&l(ri),e&&l(hu),e&&l(Se),e&&l(xu),e&&l(ai),e&&l(wu),e&&l(M),e&&l(Mu),e&&l(oi),e&&l(Hu),e&&l(Pe),e&&l(Uu),e&&l(fi),e&&l(Cu),e&&l($e),e&&l(ju),e&&l(pi),e&&l(Bu),e&&l(Ae),e&&l(Nu),e&&l(Fu),e&&l(zu),e&&l(Ou),e&&l(he),e&&l(Tu),e&&l(qu),e&&l(Ju),e&&l(we),e&&l(Qu),e&&l(si),e&&l(Gu),e&&l(Z),e&&l(Ku),e&&l(ni),e&&l(Wu),e&&l(He),e&&l(Vu),e&&l(ui),e&&l(Zu),e&&l(X),e&&l(Xu),e&&l(Ue),e&&l(Yu),e&&l(Di),e&&l(gu),e&&l(vi),e&&l(e1),e&&l(mi),e&&l(l1),e&&l(Y),e&&l(t1),e&&l(_i),e&&l(i1),e&&l(H),e&&l(r1),e&&l(je),e&&l(a1),e&&l(ci),e&&l(o1),e&&l(di),d(bt),e&&l(f1),e&&l(Ri),e&&l(p1),d(yt,e),e&&l(s1),e&&l(Li),e&&l(n1),d(St,e),e&&l(u1),e&&l(ce),e&&l(D1),e&&l(Ne),d(Fe),e&&l(v1),e&&l(Ii),e&&l(m1),d(Pt,e),e&&l(E1),e&&l(U),e&&l(_1),e&&l(Oe),e&&l(c1),d(At,e),e&&l(d1),e&&l(bi),e&&l(R1),e&&l(R),e&&l(L1),e&&l(yi),e&&l(I1),e&&l(qe),e&&l(k1),e&&l(Je),e&&l(b1),e&&l(Pi),e&&l(y1),e&&l($i),e&&l(S1),e&&l(Ai),e&&l(P1),e&&l(g),e&&l($1),e&&l(A1),e&&l(h1),e&&l(x1),e&&l(Ge),e&&l(w1),e&&l(M1),e&&l(H1),e&&l(xi),e&&l(U1),e&&l(wi),e&&l(C1),e&&l(Mi),e&&l(j1),e&&l(ee),e&&l(B1),e&&l(Hi),e&&l(N1),e&&l(We),e&&l(F1),e&&l(Ui),e&&l(z1),e&&l(Ve),e&&l(O1),e&&l(Ze),e&&l(T1),d(wt,e),e&&l(q1),e&&l(Ye),e&&l(J1),e&&l(Ci),e&&l(Q1),e&&l(ji),e&&l(G1),e&&l(Bi),e&&l(K1),e&&l(Ni),e&&l(W1),e&&l(ge),e&&l(V1),e&&l(Fi),e&&l(Z1),e&&l(ll),e&&l(X1),d(Mt,e),e&&l(Y1),e&&l(zi),e&&l(g1),e&&l(C),e&&l(eD),e&&l(tl),e&&l(lD),e&&l(Ti),e&&l(tD),e&&l(qi),e&&l(iD),e&&l(rl),e&&l(rD),e&&l(Ji),e&&l(aD),d(Ut,e),e&&l(oD),e&&l(I),e&&l(fD),e&&l(Qi),e&&l(pD),e&&l(P),d(Ct),e&&l(sD),e&&l(nD),e&&l(uD),e&&l(DD),e&&l(al),e&&l(vD),e&&l(mD),e&&l(ED),e&&l(Ki),e&&l(_D),e&&l(j),e&&l(cD),e&&l(Wi),e&&l(dD),e&&l(B),d(jt),e&&l(RD),d(Bt,e),e&&l(LD),e&&l(le),e&&l(ID),e&&l(Xi),e&&l(kD),e&&l(fl),e&&l(bD),e&&l(Yi),e&&l(yD),e&&l(gi),e&&l(SD),e&&l(N),e&&l(PD),e&&l(er),e&&l($D),e&&l(pl),e&&l(AD),e&&l(lr),e&&l(hD),e&&l(sl),e&&l(xD),e&&l(tr),e&&l(wD),e&&l(ir),e&&l(MD),e&&l(rr),e&&l(HD),e&&l($),e&&l(UD),e&&l(CD),e&&l(jD),e&&l(BD),e&&l(nl),e&&l(ND),e&&l(FD),e&&l(zD),e&&l(ar),e&&l(OD),e&&l(Dl),e&&l(TD),e&&l(or),e&&l(qD),e&&l(vl),e&&l(JD),e&&l(ml),e&&l(QD),d(Nt,e),e&&l(GD),e&&l(fr),e&&l(KD),e&&l(A),e&&l(WD),e&&l(pr),e&&l(VD),e&&l(te),e&&l(ZD),e&&l(_l),e&&l(XD),e&&l(nr),e&&l(YD),e&&l(cl),e&&l(gD),e&&l(dl),e&&l(e2),e&&l(ur),e&&l(l2),e&&l(Dr),e&&l(t2),e&&l(vr),e&&l(i2),e&&l(F),e&&l(r2),e&&l(mr),e&&l(a2),e&&l(Ll),e&&l(o2),d(zt,e),e&&l(f2),e&&l(_r),e&&l(p2),e&&l(Il),e&&l(s2),e&&l(cr),e&&l(n2),e&&l(ie),e&&l(u2),e&&l(Ir),e&&l(D2),e&&l(z),e&&l(v2),e&&l(bl),e&&l(m2),e&&l(kr),e&&l(E2),e&&l(br),e&&l(_2),e&&l(yr),e&&l(c2),e&&l(re),e&&l(d2),e&&l(Sr),e&&l(R2),e&&l(Sl),e&&l(L2),e&&l(Pr),e&&l(I2),e&&l(Pl),e&&l(k2),e&&l(b2),e&&l(y2),e&&l(S2),e&&l($l),e&&l(P2),e&&l($2),e&&l(A2),e&&l($r),e&&l(h2),e&&l(O),e&&l(x2),e&&l(hl),e&&l(w2),d(Ot,e),e&&l(M2),e&&l(ae),e&&l(H2),e&&l(wr),e&&l(U2),e&&l(oe),e&&l(C2),e&&l(Mr),e&&l(j2),e&&l(Hr),e&&l(B2),e&&l(fe),e&&l(N2),d(qt,e),e&&l(F2),e&&l(wl),e&&l(z2),e&&l(Ml),e&&l(O2),d(Jt,e),e&&l(T2),e&&l(Ul),e&&l(q2),e&&l(Cl),e&&l(J2),d(Qt,e),e&&l(Q2),e&&l(pe),e&&l(G2),e&&l(Ur),e&&l(K2),e&&l(se),e&&l(W2),e&&l(Bl),e&&l(V2),d(Gt,e),e&&l(Z2),e&&l(Fl),e&&l(X2),e&&l(Cr),e&&l(Y2),e&&l(jr),e&&l(g2),d(Kt,e),e&&l(ev),e&&l(Nr),e&&l(lv),e&&l(Fr),e&&l(tv),e&&l(Or),e&&l(iv),e&&l(Tr),e&&l(rv),e&&l(Ol),e&&l(av),d(Wt,e),e&&l(ov),e&&l(ne),e&&l(fv),e&&l(pv),e&&l(sv),e&&l(nv),e&&l(ql),e&&l(uv),e&&l(Dv),e&&l(vv),e&&l(Qr),e&&l(mv),e&&l(Ql),e&&l(Ev),e&&l(Gr),e&&l(_v),e&&l(Kl),e&&l(cv),e&&l(Kr),e&&l(dv),e&&l(T),e&&l(Rv),e&&l(Vr),e&&l(Lv),e&&l(q),e&&l(Iv),e&&l(Zr),e&&l(kv),e&&l(J),e&&l(bv),e&&l(Xr),e&&l(yv),e&&l(Wl),e&&l(Sv),e&&l(Yr),e&&l(Pv),e&&l(gr),e&&l($v),e&&l(ea),e&&l(Av),e&&l(hv),e&&l(xv),e&&l(wv),e&&l(Zl),e&&l(Mv),e&&l(Hv),e&&l(Uv),e&&l(la),e&&l(Cv),e&&l(Q),e&&l(jv),e&&l(Yl),e&&l(Bv),e&&l(G),e&&l(Nv),e&&l(gl),e&&l(Fv),e&&l(ue),e&&l(zv),e&&l(et),e&&l(Ov),e&&l(ta),e&&l(Tv),e&&l(qv),e&&l(Jv),e&&l(Qv),e&&l(lt),e&&l(Gv),e&&l(Kv),e&&l(Wv),e&&l(ia),e&&l(Vv),e&&l(ra),e&&l(Zv),e&&l(aa),e&&l(Xv),e&&l(oa),e&&l(Yv),e&&l(fa),e&&l(gv),e&&l(pa),e&&l(em),e&&l(sa)}}}const CS={title:"Spark 논문(RDD) 정리",date:"2023-09-06T00:00:00.000Z",excerpt:"Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing",categories:["Apache Spark","논문정리"],coverImage:"/post_img/Distributed Computing/Spark/RDD/cover.png",coverWidth:16,coverHeight:9,indexed:!0,exposed:!0};class jS extends PS{constructor(y){super(),$S(this,y,null,wS,AS,{})}}export{jS as default,CS as metadata};
