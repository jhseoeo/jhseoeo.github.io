import{S as _h,i as mh,s as Eh,k as i,q as f,a as n,y as dh,l as r,m as a,h as e,r as s,c as u,z as Rh,n as D,U as v,b as p,E as t,A as Lh,g as Ih,d as bh,B as kh}from"./index.d78780bf.js";import{H as yh}from"./Highlight.1019e7a6.js";function Sh(R_){let d;return{c(){d=f("이때 lines라는 RDD를 메모리로 불러오는 게 아님! count라는 action이 처음 수행된 *errors*를 메모리로 불러옴! (Lazy Execution)")},l(R){d=s(R,"이때 lines라는 RDD를 메모리로 불러오는 게 아님! count라는 action이 처음 수행된 *errors*를 메모리로 불러옴! (Lazy Execution)")},m(R,Ht){p(R,d,Ht)},d(R){R&&e(d)}}}function Ph(R_){let d,R,Ht,L_,Fu,$t,I_,Gu,m,Xa,Ya,b_,k_,ga,lo,y_,S_,Ut,eo,P_,h_,wt,to,A_,M_,io,x_,H_,ro,ao,U_,w_,oo,po,C_,B_,fo,so,j_,zu,Ou,Tu,qu,yl,Sl,no,N_,Ju,Qu,Ku,Wt,F_,$u,q,uo,G_,z_,Do,O_,T_,vo,q_,Wu,Vt,J_,Vu,P,co,Q_,K_,_o,$_,W_,mo,V_,Z_,Eo,X_,Zu,Zt,Y_,Xu,J,Ro,g_,lm,Lo,em,tm,Io,im,Yu,Xt,rm,gu,Pl,bo,am,om,ko,pm,l1,Yt,fm,e1,h,yo,sm,nm,So,um,Dm,Po,vm,cm,ho,_m,t1,gt,mm,i1,hl,Ao,Em,dm,Mo,Rm,r1,li,Lm,a1,Al,xo,Im,bm,Ho,km,o1,ei,ym,p1,Ml,Uo,Sm,Pm,wo,hm,f1,s1,n1,u1,xl,Hl,Co,Am,D1,v1,c1,Ul,wl,Bo,Mm,_1,ti,xm,m1,Q,jo,Hm,Um,No,wm,Cm,Fo,Bm,E1,ii,jm,d1,Cl,Go,Nm,Fm,zo,Gm,R1,ri,zm,L1,K,Oo,Om,Tm,To,qm,Jm,qo,Qm,I1,Bl,jl,Jo,Km,b1,ai,$m,k1,oi,Qo,Wm,y1,pi,Vm,S1,$,Ko,Zm,Xm,fi,Ym,Dl,$o,gm,lE,Wo,eE,tE,Vo,iE,rE,Zo,aE,P1,si,oE,h1,A,Xo,pE,fE,Yo,sE,nE,go,uE,DE,lp,vE,A1,Nl,Fl,ep,cE,M1,ni,_E,x1,ui,vl,mE,EE,dE,Di,PI,cl,tp,RE,LE,ip,IE,bE,Ct,kE,rp,yE,SE,H1,_l,PE,hE,AE,vi,hI,U1,ml,ME,xE,HE,ci,AI,w1,El,ap,UE,wE,op,CE,BE,C1,Gl,pp,zl,jE,fp,NE,B1,_i,FE,j1,mi,Ei,MI,N1,M,di,GE,dl,Bt,zE,sp,OE,TE,qE,np,JE,QE,up,KE,$E,Dp,WE,VE,Ol,vp,ZE,XE,cp,YE,gE,l3,_p,e3,F1,Tl,ql,mp,t3,G1,Ri,Li,xI,z1,Ii,i3,O1,c,Ep,r3,a3,dp,o3,p3,Rp,f3,s3,Lp,n3,u3,Ip,D3,v3,bp,c3,_3,kp,m3,E3,yp,d3,T1,bi,R3,q1,Jl,Sp,Pp,hp,L3,I3,ki,jt,Ap,b3,k3,Mp,xp,y3,J1,Ql,Kl,Hp,S3,Q1,yi,P3,K1,Si,Up,h3,$1,Pi,A3,W1,W,hi,M3,Nt,wp,x3,H3,Cp,U3,w3,Bp,C3,B3,jp,j3,V1,Z1,X1,Y1,$l,Wl,Np,N3,g1,lD,eD,Ai,F3,tD,Mi,Fp,G3,iD,xi,z3,rD,V,Gp,O3,T3,zp,q3,J3,Op,Q3,aD,Hi,K3,oD,Vl,Tp,$3,W3,qp,V3,pD,Ui,Z3,fD,Zl,Jp,X3,Y3,Qp,g3,sD,Xl,Yl,Kp,ld,nD,gl,wi,HI,ed,td,uD,le,$p,id,rd,Wp,ad,DD,Ci,od,vD,Bi,Vp,pd,cD,ji,fd,_D,Ni,Zp,sd,mD,ee,te,Xp,nd,ED,Fi,ud,dD,ie,Yp,Dd,vd,gp,cd,RD,re,Gi,UI,_d,zi,wI,LD,Oi,md,ID,x,lf,Ed,dd,Ti,Rd,ef,Ld,Id,Ft,bd,tf,kd,yd,Sd,rf,Pd,bD,ae,oe,af,hd,kD,qi,of,Ad,yD,Ji,Md,SD,pe,pf,xd,Hd,ff,Ud,PD,y,wd,Cd,Bd,Qi,CI,jd,Ki,BI,Nd,Fd,hD,_,S,Gd,sf,zd,Od,nf,Td,qd,uf,Jd,Qd,Df,Kd,$d,Wd,vf,Vd,Zd,cf,Xd,Yd,_f,gd,l4,mf,e4,t4,Ef,i4,r4,df,a4,AD,$i,o4,MD,L,Rf,p4,f4,Lf,s4,n4,If,u4,D4,fe,v4,c4,_4,Wi,jI,m4,bf,E4,xD,HD,UD,wD,se,ne,kf,d4,CD,BD,jD,Vi,R4,ND,H,yf,L4,I4,Sf,b4,k4,Pf,y4,S4,hf,P4,FD,Zi,h4,GD,U,Af,A4,M4,Mf,x4,H4,xf,U4,w4,Xi,C4,Rl,ue,B4,j4,N4,Yi,NI,F4,Hf,G4,z4,Uf,O4,zD,Gt,gi,FI,T4,OD,Z,wf,q4,J4,Cf,Q4,K4,Bf,$4,TD,lr,W4,qD,De,jf,Nf,V4,Z4,Ff,Gf,X4,JD,er,Y4,QD,tr,g4,KD,w,zf,l5,e5,Of,t5,i5,Tf,r5,a5,qf,o5,$D,ir,p5,WD,ve,Jf,f5,s5,Qf,n5,VD,rr,u5,ZD,ce,Kf,D5,v5,$f,c5,XD,ar,_5,YD,or,Wf,m5,gD,pr,E5,l2,I,Vf,d5,R5,Zf,L5,I5,Xf,b5,k5,Yf,y5,S5,gf,P5,e2,t2,i2,r2,_e,me,ls,h5,a2,o2,p2,fr,A5,f2,Ee,es,M5,x5,ts,H5,s2,sr,U5,n2,de,is,w5,C5,rs,B5,u2,Re,Le,as,j5,D2,X,nr,GI,N5,F5,G5,z5,v2,ur,O5,c2,b,os,T5,q5,ps,J5,Q5,fs,K5,$5,ss,W5,V5,ns,Z5,_2,Dr,X5,m2,Y,us,Y5,g5,Ds,lR,eR,vs,tR,E2,Ie,cs,iR,rR,vr,aR,_s,ms,oR,d2,cr,pR,R2,be,Es,fR,sR,ds,nR,L2,ke,ye,Rs,uR,I2,_r,DR,b2,mr,Ls,vR,k2,Er,cR,y2,C,Is,_R,mR,bs,ER,dR,ks,RR,LR,ys,IR,S2,dr,bR,P2,Se,Ss,kR,yR,Rr,SR,zt,Ps,PR,hR,hs,AR,h2,Pe,Lr,zI,MR,xR,A2,Ir,HR,M2,he,Ae,As,UR,x2,br,wR,H2,g,kr,CR,Ms,xs,BR,jR,yr,NR,Hs,Us,FR,GR,Sr,zR,ws,Cs,OR,U2,Pr,TR,w2,B,Bs,qR,JR,js,QR,KR,Ns,$R,WR,Fs,VR,C2,Me,xe,Gs,ZR,B2,hr,XR,j2,Ar,zs,YR,N2,Mr,gR,F2,ll,Os,l6,e6,Ts,t6,i6,qs,r6,G2,xr,a6,z2,He,Js,o6,p6,Qs,f6,O2,Hr,s6,T2,Ue,Ks,n6,u6,$s,D6,q2,J2,Q2,K2,we,Ce,Ws,v6,$2,W2,V2,Ur,c6,Z2,j,wr,_6,Vs,Zs,m6,E6,Cr,d6,Xs,Ys,R6,L6,gs,I6,b6,ln,k6,X2,Be,je,en,y6,Y2,Ne,Br,OI,S6,jr,TI,g2,el,tn,P6,h6,rn,A6,M6,Nr,x6,Ot,an,H6,U6,on,w6,lv,Fr,C6,ev,tl,pn,B6,j6,fn,N6,F6,sn,G6,tv,Gr,z6,iv,zr,O6,rv,il,nn,T6,q6,un,J6,Q6,Dn,K6,av,Fe,Or,qI,$6,W6,ov,Ge,vn,V6,Z6,cn,X6,pv,ze,Oe,_n,Y6,fv,Te,Tr,JI,g6,l7,sv,qe,mn,e7,t7,En,i7,nv,Je,Qe,dn,r7,uv,Ke,qr,QI,a7,o7,Dv,rl,Rn,p7,f7,Ln,s7,n7,In,u7,vv,Jr,D7,cv,al,bn,v7,c7,kn,_7,m7,yn,E7,_v,$e,We,Sn,d7,mv,Ve,Qr,KI,R7,L7,Ev,Ze,Xe,Pn,I7,dv,Kr,b7,Rv,$r,Wr,k7,hn,An,y7,Lv,Vr,Zr,$I,Iv,Xr,S7,bv,Yr,gr,P7,Mn,xn,h7,kv,la,A7,yv,ea,ta,M7,Ll,Hn,x7,H7,Un,U7,w7,wn,C7,Sv,Ye,ge,Cn,B7,Pv,lt,ia,WI,j7,N7,hv,ol,Bn,F7,G7,jn,z7,O7,ra,T7,Nn,Fn,q7,Av,Mv,xv,Hv,et,tt,Gn,J7,Uv,wv,Cv,aa,Q7,Bv,it,rt,zn,K7,jv,oa,$7,Nv,at,On,W7,V7,Tn,Z7,Fv,pa,X7,Gv,N,qn,Y7,g7,Jn,lL,eL,Qn,tL,iL,fa,rL,Kn,$n,aL,zv,sa,oL,Ov,F,Wn,pL,fL,Vn,sL,nL,Zn,uL,DL,Xn,vL,Tv,na,cL,qv,G,Yn,_L,mL,gn,EL,dL,lu,RL,LL,eu,IL,Jv,ua,bL,Qv,ot,pt,tu,kL,Kv,Da,yL,$v,va,iu,SL,Wv,ca,PL,Vv,Zv,Xv,Yv,ft,st,ru,hL,gv,lc,ec,_a,AL,tc,z,Tt,au,ML,xL,qt,ou,HL,UL,pu,wL,CL,Jt,fu,BL,jL,Il,su,NL,FL,nu,GL,zL,uu,OL,TL,Qt,Du,qL,JL,vu,cu,QL,KL,Kt,_u,$L,WL,bl,mu,VL,ZL,Eu,XL,YL,du,gL,ic,nt,l0,e0,t0,rc,O,Ru,i0,r0,Lu,a0,o0,Iu,p0,f0,bu,s0,ac,ut,n0,u0,D0,oc,pl,ku,v0,c0,yu,_0,m0,Su,E0,pc,Dt,d0,R0,L0,fc,ma,Pu,I0,sc,nc,uc,Dc,vt,ct,hu,b0,vc,cc,_c,Ea,k0,mc,da,Au,y0,Ec,Ra,S0,dc,La,Mu,P0,Rc,Ia,h0,Lc,ba,xu,A0,Ic,ka,M0,bc;return zl=new yh({props:{$$slots:{default:[Sh]},$$scope:{ctx:R_}}}),{c(){d=i("h2"),R=i("a"),Ht=i("span"),L_=f("Abstraction"),Fu=n(),$t=i("p"),I_=f("RDD(Resilient Distributed Datasets)"),Gu=n(),m=i("ul"),Xa=i("li"),Ya=i("p"),b_=f("Resilient : 메모리 내부에서 데이터가 손실 시 유실된 파티션을 재연산해 복구할 수 있다."),k_=n(),ga=i("li"),lo=i("p"),y_=f("Distributed : 스파크 클러스터를 통하여 메모리에 분산되어 저장된다."),S_=n(),Ut=i("li"),eo=i("p"),P_=f("Data : 파일, 정보 등등"),h_=n(),wt=i("ul"),to=i("li"),A_=f("분산 메모리 abstraction"),M_=n(),io=i("li"),x_=f("fault-tolerant하게 in-memory computation 가능해짐"),H_=n(),ro=i("li"),ao=i("p"),U_=f("iterative한 작업이나 interactive data mining 작업의 경우 in-memory로 하면 성능 향상"),w_=n(),oo=i("li"),po=i("p"),C_=f("shared memory의 제약된 형태로 fine-grained보단 course-grained 사용함"),B_=n(),fo=i("li"),so=i("p"),j_=f("Spark에서는 이 RDD를 사용하여 다양한 형태의 user application이나 computation에서 적용 가능"),zu=n(),Ou=i("br"),Tu=i("br"),qu=n(),yl=i("h2"),Sl=i("a"),no=i("span"),N_=f("Introduce"),Ju=n(),Qu=i("hr"),Ku=n(),Wt=i("p"),F_=f("MapReduce나 Dryad 등 데이터 분석 도구 특징"),$u=n(),q=i("ul"),uo=i("li"),G_=f("fault tolerant나 work distribution에 대한 걱정 없이 High level operator를 통해 분산 환경에서 parallel computation 허용함"),z_=n(),Do=i("li"),O_=f("즉, 얘네들은 분산된 resource에 접근하는 abstraction임"),T_=n(),vo=i("li"),q_=f("근데 분산된 메모리를 활용하기 위한 abstraction은 부족함"),Wu=n(),Vt=i("p"),J_=f("data reuse 측면"),Vu=n(),P=i("ul"),co=i("li"),Q_=f("iterative한 작업(머신 러닝, 그래프 알고리즘 등)이나 interactive data mining 작업을 할 때, computation 사이에서 데이터를 reuse하는 유일한 방법은 intermediate data를 external stable storage에 저장하는 것임. (이런 애들은 reuse 자주 함)"),K_=n(),_o=i("li"),$_=f("data replication, disk I/O, serialization 등 execution time 큰 것들로 인해 overhead 발생함"),W_=n(),mo=i("li"),V_=f("intermediate data를 메모리에 저장해서 reuse하는, Pregel과 HaLoop이라는 애들이 나오긴 했음. 근데 얘네들은 오직 특정한 형태의 computation pattern만 지원함"),Z_=n(),Eo=i("li"),X_=f("general하게 reuse할 수 있는 abstraction은 없음"),Zu=n(),Zt=i("p"),Y_=f("RDD는 다양한 application에서 data reuse를 가능하게 함"),Xu=n(),J=i("ul"),Ro=i("li"),g_=f("intermediate data를 메모리에 저장할 수 있는 fault tolerant, parallel 데이터 구조"),lm=n(),Lo=i("li"),em=f("최적화되게끔 partitioning을 제어하거나 다양한 operator를 사용해서 데이터를 조작할 수 있음."),tm=n(),Io=i("li"),im=f("adhoc query를 돌릴 수도 있다."),Yu=n(),Xt=i("p"),rm=f("기존에 존재하는 클러스터 단위의 in-memory storage abstraction(distributed shared memory, key-value store, database, Piccolo)는 mutable state를 fine grade로 나누었음(ex. cells in table)"),gu=n(),Pl=i("ul"),bo=i("li"),am=f("이런 방식에서 fault-tolerance를 제공하려면 machine들 사이에서 1. replication을 저장하거나, 2. log update를 해야 함."),om=n(),ko=i("li"),pm=f("이러한 방식은 상당한 양의 data-intensive workload가 발생하며, 데이터들이 cluster network를 통해 복사됨. cluster network의 bandwidth는 RAM보다 훨씬 별로라서, overhead가 발생함"),l1=n(),Yt=i("p"),fm=f("반면 RDD에서는 이런 시스템과는 달리, 많은 데이터 항목에 동일하게 operation을 적용 가능한 course-grained 기반의 정보 교환(map, filter, join 등)을 함"),e1=n(),h=i("ul"),yo=i("li"),sm=f("실제 데이터가 아닌, dataset(lineage)을 만들 때 사용되는 transformation을 logging함으로써, fault tolerance 제공"),nm=n(),So=i("li"),um=f("lineage chain이 점점 커지면 데이터 자체를 checkpointing하는 게 유용할 때도 있음"),Dm=n(),Po=i("li"),vm=f("만약 RDD의 partition을 손실한다고 해도, RDD에서는 그 partition이 다른 RDD로부터 어떻게 생겨났는지에 대한 정보를 가지고 있음. 따라서 그 파티션을 recompute함"),cm=n(),ho=i("li"),_m=f("따라서 손실된 데이터는 (비싼 data replication을 하지 않고도) 빠르게 복구될 수 있음"),t1=n(),gt=i("p"),mm=f("coarse-grained transformation 기반의 인터페이스가 처음에는 너무 제약된 형태로 보일 순 있지만, RDD는 다양한 병렬 application에 적합함."),i1=n(),hl=i("ul"),Ao=i("li"),Em=f("이러한 application은 여러 data item에 동일한 operation을 적용하는 경향"),dm=n(),Mo=i("li"),Rm=f("실제로, RDD는 MapReduce, Dryad, SQL, pregel, HaLoop 뿐만 아니라, 이러한 시스템으로 하기 어려운 interactive data mining과 같이 새로운 application 등, 분리된 시스템으로 제안된 cluster programming model에 적용될 수 있음"),r1=n(),li=i("p"),Lm=f("Spark라는 시스템에 RDD 구현하였음"),a1=n(),Al=i("ul"),xo=i("li"),Im=f("UC 버클리를 비롯한 여러 회사에서 연구 및 production에 사용중"),bm=n(),Ho=i("li"),km=f("Spark는 language-intergrated programming interface를 제공함(언어 자체에 Query문이 포함된 LINQ처럼). 또한 Spark는 Scala interpreter를 통해서 크기가 큰 dataset에 query를 날릴 수 있음"),o1=n(),ei=i("p"),ym=f("Spark의 성능"),p1=n(),Ml=i("ul"),Uo=i("li"),Sm=f("iterative application에서 하둡보다 20배 빠르고, real-world data analytic report에서 40배 빠르고, 1TB dataset을 scan하는 데 5~7초가 걸린다."),Pm=n(),wo=i("li"),hm=f("RDD의 generality(범용성)을 증명하기 위해, Pregel과 HaLoop의 프로그래밍 모델을 Spark 위에서 구현하기도 했음. 이때 Pregel과 HaLoop이 사용하는 placement optimization을 적용하였고, 비교적 적은 라이브러리로 구현함."),f1=n(),s1=i("br"),n1=i("br"),u1=n(),xl=i("h2"),Hl=i("a"),Co=i("span"),Am=f("Resilient Distributed Datasets(RDD)"),D1=n(),v1=i("hr"),c1=n(),Ul=i("h3"),wl=i("a"),Bo=i("span"),Mm=f("RDD Abstraction"),_1=n(),ti=i("p"),xm=f("RDD는 Read-only이며, record들의 Partitioned Collection임."),m1=n(),Q=i("ul"),jo=i("li"),Hm=f("RDD는 stable storage의 데이터나, 다른 RDD에 대한 deterministic operation을 통해서만 생성될 수 있음."),Um=n(),No=i("li"),wm=f("deterministic : 예측한 그대로 동작. 어떤 특정한 입력이 들어오면 언제나 똑같은 과정을 거쳐서 언제나 똑같은 결과를 내놓는다."),Cm=n(),Fo=i("li"),Bm=f("이러한 operation을 RDD의 다른 operation과 구분하기 위해 transform이라 부름. transform의 예는 map, filter, join 등이 있음"),E1=n(),ii=i("p"),jm=f("RDD는 항상 materialized일 필요는 없음(구체적으로 모든 정보를 포함할 필요는 없음)."),d1=n(),Cl=i("ul"),Go=i("li"),Nm=f("대신 stable storage에 저장된 데이터의 partition을 계산하기 위해, 다른 dataset(lineage)으로부터 어떻게 만들어진 것인지에 대해 정보를 포함하고 있음"),Fm=n(),zo=i("li"),Gm=f("프로그램은 failure가 발생한 후 reconstruct할 수 없는 RDD를 참조할 수 없음"),R1=n(),ri=i("p"),zm=f("사용자는 RDD의 persistence(지속성)과 partitioning을 조절할 수 있음."),L1=n(),K=i("ul"),Oo=i("li"),Om=f("재사용할 RDD를 지정하고, 어떤 storage strategy를 사용할 것인지 결정 가능 (ex. in-memory storage)"),Tm=n(),To=i("li"),qm=f("또한 RDD element가 각 record의 key에 따라 machine별로 partition 되게끔 요청할 수 있음"),Jm=n(),qo=i("li"),Qm=f("이는 placement optimization할 때 유용"),I1=n(),Bl=i("h3"),jl=i("a"),Jo=i("span"),Km=f("Spark Programming Interface"),b1=n(),ai=i("p"),$m=f("Spark는 laguage-integrated API를 통해 RDD를 제공함"),k1=n(),oi=i("ul"),Qo=i("li"),Wm=f("DryadLINQ나 FlumeJava와 유사함. 여기서는 각각의 dataset이 object로 표현되고, method를 통해 transformation을 호출함"),y1=n(),pi=i("p"),Vm=f("개발자들은 stable storage로부터 (map이나 filter 등의)transformation을 함으로써, 한 개 이상의 RDD를 정의할 수 있음."),S1=n(),$=i("ul"),Ko=i("li"),Zm=f("이렇게 RDD를 얻으면, action을 취할 수 있음"),Xm=n(),fi=i("li"),Ym=f("action : 그 값을 applciation으로 반환하거나, storage system 밖으로 데이터를 빼내는 등으로 사용하는 것. action의 예는 다음과 같음"),Dl=i("ul"),$o=i("li"),gm=f("count : dataset 내의 element의 수"),lE=n(),Wo=i("li"),eE=f("collect : element 자체를 반환"),tE=n(),Vo=i("li"),iE=f("save : dataset을 storage system에 저장"),rE=n(),Zo=i("li"),aE=f("Spark는 RDD에서 처음 실행되는 action을 느리게 연산하여, transformation에 pipeline할 수 있음"),P1=n(),si=i("p"),oE=f("persist : 특정 RDD가 미래의 operation에서 reuse될 수 있게끔 지정하는 method"),h1=n(),A=i("ul"),Xo=i("li"),pE=f("Spark는 default로 persistent RDD를 메모리에 저장해둠"),fE=n(),Yo=i("li"),sE=f("하지만 RAM에 공간이 없으면 disk로 spill할 수 있음"),nE=n(),go=i("li"),uE=f("유저 또한 다른 persistence strategy를 요청할 수 있음. 예를 들면 persist라는 flag는 RDD를 disk에만 저장하거나, 다른 machine들에 replication을 저장함"),DE=n(),lp=i("li"),vE=f("유저는 RDD별로 persistence priority를 지정하여, 어떤 in-memory data가 disk로 먼저 spill되게끔 할 것인지 결정할 수 있음"),A1=n(),Nl=i("h4"),Fl=i("a"),ep=i("span"),cE=f("Example: Console Log Mining"),M1=n(),ni=i("p"),_E=f("웹 서비스가 장애를 겪고 있고, 오퍼레이터가 원인을 찾아내기 위해 테라바이트 단위의 로그를 HDFS로 분석해 본다고 가정해봅시다."),x1=n(),ui=i("ul"),vl=i("li"),mE=f("Spark를 쓰면 오페레이터는 log의 에러 메시지를 RAM으로 불러와서, interactively(대화식) query를 날릴 수 있다."),EE=i("br"),dE=n(),Di=i("img"),cl=i("ul"),tp=i("li"),RE=f("line 1 : HDFS 파일으로부터 RDD를 정의한다"),LE=n(),ip=i("li"),IE=f("line 2 : 1의 RDD에서 Filter된 RDD (ERROR로 시작하는 데이터) => scala 문법으로 가능!"),bE=n(),Ct=i("li"),kE=f("line 3 : "),rp=i("em"),yE=f("errors"),SE=f("라는 RDD가 메모리에 남아서, query 사이에서 공유될 수 있게 함"),H1=n(),_l=i("p"),PE=f("cluster에 수행될 작업이 없다면, RDD로 에러 메시지의 수를 세는 등, action을 할 수 있음."),hE=i("br"),AE=n(),vi=i("img"),U1=n(),ml=i("p"),ME=f("사용자는 이렇게 얻은 RDD에서 추가적인 transformation을 실행하고, 그렇게 또 얻은 RDD에서 결과를 얻을 수 있음"),xE=i("br"),HE=n(),ci=i("img"),w1=n(),El=i("p"),ap=i("em"),UE=f("errors"),wE=f("에 관련된 첫 번째 액션(위에선 count)이 실행되면, Spark는 "),op=i("em"),CE=f("errors"),BE=f("의 partition을 메모리에 불러옴. 그러면 다음의 매우 연산이 빨라짐"),C1=n(),Gl=i("ul"),pp=i("li"),dh(zl.$$.fragment),jE=n(),fp=i("li"),NE=f("에러 메시지는 데이터의 극히 일부분에 해당하는 것이기에 충분히 작음. 메모리에 올려도 괜찮음"),B1=n(),_i=i("p"),FE=f("이 모델이 fault tolerance를 달성하는 방법을 그림으로 나타낸 것"),j1=n(),mi=i("p"),Ei=i("img"),N1=n(),M=i("ul"),di=i("li"),GE=f("위 3개의 query에 대한, RDD의 lineage graph"),dl=i("ol"),Bt=i("li"),zE=f("lines라는 RDD에 대한 filter의 결과로, "),sp=i("em"),OE=f("errors"),TE=f("라는 RDD를 얻음"),qE=n(),np=i("li"),JE=f("1에서 filter하여 다음의 RDD, map 하여 다음의 RDD를 얻음"),QE=n(),up=i("li"),KE=f("2에서 collect()"),$E=n(),Dp=i("li"),WE=f("Spark의 스케쥴러는 2의 map, filter 변환을 파이프라인화함"),VE=n(),Ol=i("li"),vp=i("em"),ZE=f("errors"),XE=f("라는 RDD의 데이터가 캐싱되어 있는 partition을 가진 node한테 연산하라고 던짐 (아까 "),cp=i("em"),YE=f("errors"),gE=f("는 count() 했었죠? 메모리에 올라가 있음)"),l3=n(),_p=i("li"),e3=f("만약 partition을 손실할 경우, Spark는 해당되는 line 파티션에만 filter를 적용하여 재구성함"),F1=n(),Tl=i("h3"),ql=i("a"),mp=i("span"),t3=f("Advantages of the RDD Model"),G1=n(),Ri=i("p"),Li=i("img"),z1=n(),Ii=i("p"),i3=f("RDD와 Distributed Shared Memory(DSM)를 비교했을 때 장점이 나옴."),O1=n(),c=i("ul"),Ep=i("li"),r3=f("DSM은 global address space의 임의의 공간에서 read/write를 수행"),a3=n(),dp=i("li"),o3=f("전통적인 shared memory system 뿐 아니라, Piccolo나 분산 데이터베이스 등 shared state를 fine-grained로 write하는 application도 DHT 사용함"),p3=n(),Rp=i("li"),f3=f("DSM은 일반적인 방식이지만, 하지만 이런 방식은 commodity cluster에서 효율적이고 fault-tolerant한 방식으로 구현하기 어려움"),s3=n(),Lp=i("li"),n3=f("DSM은 각 메모리의 위치별 read / write를 허용하지만(이게 fine-grained의 정의임. 그리고 RDD도 read 연산은 fine-grained로 가능함), 반면 RDD는 Course-grained인 transformation을 통해서만 생성(write)될 수 있음"),u3=n(),Ip=i("li"),D3=f("이는 RDD를 사용하는 application이 bulk write만 하게끔 제약하지만, 보다 효율적인 fault-tolerance를 제공함"),v3=n(),bp=i("li"),c3=f("RDD는 checkpointing의 overhead가 없는 대신, lineage를 통해 회복이 가능. (물론 lineage chain이 너무 길 경우 체크포인트를 쓰기도 함. 나중에 다룰 예정)"),_3=n(),kp=i("li"),m3=f(`또한 RDD에서는 failure 발생 시 오직 손실된 partition만 복구하며, 이는 전체 프로그램을 rollback할 필요 없이 다른 node에서 병렬적으로 실행 가능함.
RDD의 두 번째 장점은, straggler가 있으면 그 태스크의 백업 복사본을 실행할 수 있다는 것(MapReduce처럼)`),E3=n(),yp=i("li"),d3=f("DSM에서는 Backup Task를 만드는 것이 어려움. 두 task가 동일한 메모리 영역을 액세스하여, 설의 업데이트를 방해하는 등 문제가 생길 수 있기 때문임."),T1=n(),bi=i("p"),R3=f("마지막으로, RDD는 두 가지 이점을 제공함"),q1=n(),Jl=i("ul"),Sp=i("li"),Pp=i("ol"),hp=i("li"),L3=f("bulk 연산에서 data locality에 따라 runtime schedule 가능 => 성능 향상"),I3=n(),ki=i("li"),jt=i("ol"),Ap=i("li"),b3=f("스캔 기반 작업에만 사용된다면, 저장할 공간이 없을 때 성능 저하가 graceful하게 일어남."),k3=n(),Mp=i("ul"),xp=i("li"),y3=f("RAM에 맞지 않는 partition은 disk에 저장되며, 현재의 data-parallel system과 유사한 성능을 냄."),J1=n(),Ql=i("h3"),Kl=i("a"),Hp=i("span"),S3=f("Application Not Suitable for RDDs"),Q1=n(),yi=i("p"),P3=f("RDD는 same operation을 전체 dataset에 적용하는 batch application에 적합함"),K1=n(),Si=i("ul"),Up=i("li"),h3=f("RDD는 각 단계의 transformation을 lineage graph의 한 단계로 기억하며, 많은 양의 데이터를 기록할 필요 없이 손실된 partition을 복구할 수 있음."),$1=n(),Pi=i("p"),A3=f("반면 부적합한 application도 존재함"),W1=n(),W=i("ul"),hi=i("li"),M3=f("asynchronous하게 fine-grained shared state를 update하는 application"),Nt=i("ul"),wp=i("li"),x3=f("web server의 storage system"),H3=n(),Cp=i("li"),U3=f("점진적인 web crawler"),w3=n(),Bp=i("li"),C3=f("이러한 Application의 경우, 전통적인 log update, data checkpoint를 생성하는, database를 사용하는 것이 좋음"),B3=n(),jp=i("li"),j3=f("Spark의 목표는 batch analytic을 위한 프로그래밍 모델을 제공하는 것"),V1=n(),Z1=i("br"),X1=i("br"),Y1=n(),$l=i("h2"),Wl=i("a"),Np=i("span"),N3=f("Spark Programming Interfaces"),g1=n(),lD=i("hr"),eD=n(),Ai=i("p"),F3=f("Spark는 language-integrated API를 통해 RDD abstraction을 제공함"),tD=n(),Mi=i("ul"),Fp=i("li"),G3=f("함수형 + 정적 타이핑 언어인 Scala를 선택하였는데, 간결하기 때문에 interactive하게 사용하기 용이함"),iD=n(),xi=i("p"),z3=f("Spark를 쓰는 개발자는 driver program을 작성해야 하는데, 얘가 클러스터의 worker들에 접속함."),rD=n(),V=i("ul"),Gp=i("li"),O3=f("Driver는 한 개 이상의 RDD를 정의하고, action을 호출함."),T3=n(),zp=i("li"),q3=f("Driver는 RDD Lineage를 추적함"),J3=n(),Op=i("li"),Q3=f("worker는 여러 연산을 통해 RDD Partition을 RAM에 저장할 수 있는 long-lived process임"),aD=n(),Hi=i("p"),K3=f("map과 같은 RDD Operation에는 closure(function literal)를 넘겨줘야 함"),oD=n(),Vl=i("ul"),Tp=i("li"),$3=f("이때 closure는 Java object로 표현되며, Serialize하여 네트워크를 통해 closure를 전송할 수 있음"),W3=n(),qp=i("li"),V3=f("또한, 이 closure에 묶여 있는 변수는 Object의 field값으로 설정됨"),pD=n(),Ui=i("p"),Z3=f("RDD 자체는 원소의 타입을 파라미터로 넘길 수 있는 statically typed objected이다."),fD=n(),Zl=i("ul"),Jp=i("li"),X3=f("RDD[Int]는 Int의 RDD이다."),Y3=n(),Qp=i("li"),g3=f("Scala는 Type Interface를 지원하니, 타입을 생략해도 된다."),sD=n(),Xl=i("h3"),Yl=i("a"),Kp=i("span"),ld=f("RDD Operations in Spark"),nD=n(),gl=i("p"),wi=i("img"),ed=i("br"),td=f(`
위 표는 Spark에서 사용 가능한 Transformation과 Action의 목록임.`),uD=n(),le=i("ul"),$p=i("li"),id=f("대괄호 안에 타입 파라미터를 표시하여, 각 연산의 특징을 제시하였음."),rd=n(),Wp=i("li"),ad=f("transformation은 lazy operation인 반면, action은 프로그램에 값을 반환하거나 외부 스토리지에 값을 write하기 위해 연산을 시작함."),DD=n(),Ci=i("p"),od=f(`join 등의 연산은 key-value pair 형태의 RDD에서만 가능함.
또한 함수 이름은 스칼라나 다른 함수형 언어의 API와 매칭이 가능하게끔 선정하였음`),vD=n(),Bi=i("ul"),Vp=i("li"),pd=f("map : 1-1 mapping / flatMap : MapReduce의 map과 유사함. 각 input value를 한 개 이상의 output과 mapping"),cD=n(),ji=i("p"),fd=f(`사용자는 RDD가 지속되게끔 요청할 수 있음. (persist)
RDD의 partition order를 얻을 수도 있음.`),_D=n(),Ni=i("ul"),Zp=i("li"),sd=f(`Partitioner Class가 partition order를 나타냄. 이걸 가지고 다른 dataset을 partition할 수도 있음.
groupByKey, reduceByKey, sort 등의 연산은 자동으로 hash partition 또는 range partition된 RDD를 생성한다.`),mD=n(),ee=i("h3"),te=i("a"),Xp=i("span"),nd=f("Example: Logistic Regression"),ED=n(),Fi=i("p"),ud=f("기계 학습 알고리즘의 경우, iterative한 경우가 많다."),dD=n(),ie=i("ul"),Yp=i("li"),Dd=f("gradient descent 등 반복 최적화 절차를 수행하기 때문"),vd=n(),gp=i("li"),cd=f("따라서 데이터를 메모리에 저장한다면 험청 빨라질 것임"),RD=n(),re=i("p"),Gi=i("img"),_d=n(),zi=i("img"),LD=n(),Oi=i("p"),md=f("위 코드는 logistic regression 예제인데, 제가 머신러닝 이런거 안해봐서 뭔지 잘 모름 ㅈㅅ; 흐름만 봄"),ID=n(),x=i("ul"),lf=i("li"),Ed=f("text file에서 map"),dd=n(),Ti=i("li"),Rd=f("parsePoint 함수 넘겨서 텍스트 파일의 각 라인으로부터 좌표상의 위치 얻음 => "),ef=i("em"),Ld=f("points"),Id=n(),Ft=i("li"),bd=f("반복적으로 "),tf=i("em"),kd=f("points"),yd=f("에서 map 및 reduce하여 결과(w 벡터)를 얻을 수 있음"),Sd=n(),rf=i("li"),Pd=f("메모리에 올려놓고 반복하기 때문에 20배까지 속도가 빨라짐"),bD=n(),ae=i("h3"),oe=i("a"),af=i("span"),hd=f("Example: PageRank"),kD=n(),qi=i("ul"),of=i("li"),Ad=f("RDD의 partitioning을 사용하여, 성능을 향상시킬 수 있는 것을 보여줌"),yD=n(),Ji=i("p"),Md=f(`더 복잡한 data sharing pattern임.
PageRank 알고리즘은 다른 문서에서 각 문서로 link되는 회수를 합산하여, 문서의 rank를 반복적으로 업데이트한다.`),SD=n(),pe=i("ul"),pf=i("li"),xd=f("각 iteration마다 각 문서는 r/n의 기여도를 이웃들에게 보낸다. (r : rank, n : 이웃의 수)"),Hd=n(),ff=i("li"),Ud=f("그 후 순위를 α/N + (1 − α)∑ci 로 계산 (∑ci : 받은 기여도의 총합, N : 총 문서 수)"),PD=n(),y=i("p"),wd=f("PageRank를 Spark로 나타내면 다음과 같음"),Cd=i("br"),Bd=n(),Qi=i("img"),jd=n(),Ki=i("img"),Nd=i("br"),Fd=f(`
좌측의 프로그램을 돌리면 우측의 그림과 같은 RDD Lineage 그래프를 얻을 수 있음`),hD=n(),_=i("ul"),S=i("li"),Gd=f("각 iteration마다, 이전 iteration의 "),sf=i("em"),zd=f("contribs"),Od=f("와 "),nf=i("em"),Td=f("ranks"),qd=f(", 그리고 정적인 "),uf=i("em"),Jd=f("links"),Qd=f("라는 dataset으로부터, 새로운 "),Df=i("em"),Kd=f("ranks"),$d=f("라는 dataset을 만듦."),Wd=n(),vf=i("li"),Vd=f("이 그래프의 흥미로운 특징은, 반복의 회수만큼 graph가 늘어난다는 것이다."),Zd=n(),cf=i("li"),Xd=f("이 작업은 많은 iteration이 동반되므로, fault recovery를 효율적으로 하려면 특정 버전의 ranks를 replication을 만들어서 저장해야 할 수도 있음"),Yd=n(),_f=i("li"),gd=f("사용자는 RELIABLE 플래그를 줘서 persist 메소드를 호출하면 그렇게 할 수 있음"),l4=n(),mf=i("li"),e4=f("하지만 links라는 dataset은 replication을 만들 필요가 없음. 그냥 input file에서 map 다시 돌리면 해당 partition을 다시 얻는 게 더 효율적이기 때문"),t4=n(),Ef=i("li"),i4=f("이 dataset은 보통 ranks보다 훨씬 크기가 큼. 각 문서에는 많은 링크가 있지만 순위는 한 개뿐이기 때문"),r4=n(),df=i("li"),a4=f("따라서 lineage를 사용하여 복구하는 게, 프로그램의 전체 in-memory state의 checkpoint를 만드는 것보다 시간을 절약할 수 있음"),AD=n(),$i=i("p"),o4=f("RDD의 partitioning을 제어함으로써, PageRank 알고리즘에서의 통신을 최적화할 수 있음"),MD=n(),L=i("ul"),Rf=i("li"),p4=f("만약 links를 기준으로 partitioning하게끔 명시한다면, ranks에 대해서도 동일한 방식으로 partitioning할 수 있음"),f4=n(),Lf=i("li"),s4=f("그렇게 되면 links와 ranks간의 join 연산이 통신을 필요로 하지 않게 됨(같은 머신 위에 필요한 데이터가 있음)"),n4=n(),If=i("li"),u4=f("Partitioner class를 작성하여, 도메인 이름에 따라 페이지를 묶을 수도 있음."),D4=n(),fe=i("li"),v4=f("아래와 같이, links를 정의할 때 PartitionBy()라는 method를 통해 진행"),c4=i("br"),_4=n(),Wi=i("img"),m4=n(),bf=i("li"),E4=f("RDD는 사용자가 이러한 목표(일관된 partitioning을 통한 최적화)를 직접 표현할 수 있게 함."),xD=n(),HD=i("br"),UD=i("br"),wD=n(),se=i("h2"),ne=i("a"),kf=i("span"),d4=f("Representing RDDs"),CD=n(),BD=i("hr"),jD=n(),Vi=i("p"),R4=f("RDD를 Abstraction으로 제공하기 위한 과제 중 하나는, 광범위한 transformation에서 lineage를 추적할 수 있는 표현을 선택하는 것임"),ND=n(),H=i("ul"),yf=i("li"),L4=f("RDD를 구현하는 시스템은 반드시 다양한 transformation 연산자들을 제공해야 하며, 사용자가 임의의 방식으로 transformation을 선택할 수 있게 해야 함."),I4=n(),Sf=i("li"),b4=f("이 논문에서는 graph-based의 표현을 제안함"),k4=n(),Pf=i("li"),y4=f("Spark에서는 이 표현을 사용함으로써, 각각의 스케줄러에 특별한 논리를 추가하지 않고 광범위한 transformation을 지원함"),S4=n(),hf=i("li"),P4=f("시스템 설계가 매우 단순화됨"),FD=n(),Zi=i("p"),h4=f("각각의 RDD는 아래와 같은 정보를 노출하는 공통적인 인터페이스로 나타낼 수 있음"),GD=n(),U=i("ol"),Af=i("li"),A4=f("partition의 집합 (dataset의 atomic pieces)"),M4=n(),Mf=i("li"),x4=f("Parent RDD에 대한 종속성(dependency) 집합"),H4=n(),xf=i("li"),U4=f("Parent RDD를 기반으로 dataset을 계산하는 함수"),w4=n(),Xi=i("li"),C4=f("partitioning scheme 및 데이터 배치에 대한 메타데이터"),Rl=i("ul"),ue=i("li"),B4=f("해당 인터페이스는 아래와 같은 테이블에서 보여줌"),j4=i("br"),N4=n(),Yi=i("img"),F4=n(),Hf=i("li"),G4=f("예를 들면, HDFS 파일을 표현하는 RDD는 파일의 각 블록마다 partition을 가지고 있고 어떤 machine의 블록에 올라가 있는지 정보를 알고 있음"),z4=n(),Uf=i("li"),O4=f("한편 이 RDD에 map을 한 결과물은 동일한 partition을 가지지만, 요소를 계산할 때 parent data에 map 함수를 적용한다."),zD=n(),Gt=i("p"),gi=i("img"),T4=f(`
RDD간의 종속성(Dependency)를 나타내는 인터페이스는 두 종류가 있음`),OD=n(),Z=i("ul"),wf=i("li"),q4=f("narrow dependency: 1개의 Parent RDD에 1개의 Child RDD가 종속"),J4=n(),Cf=i("li"),Q4=f("wide dependency : 1개의 Parent RDD에 여러 개의 Child RDD가 종속될 수 있음"),K4=n(),Bf=i("li"),$4=f("예를 들어 map은 narrow dependency이고, join은 (parent가 hash-partitioned 되어있는 게 아니라면) wide dependency임."),TD=n(),lr=i("p"),W4=f("이렇게 narrow와 wide로 구분하는 게 유용한 이유가 두 가지 있음."),qD=n(),De=i("ol"),jf=i("li"),Nf=i("p"),V4=f(`narrow dependency는 모든 parent partition을 계산할 수 있는 하나의 cluster node에서 pipelined execution이 가능함.
=> 예를 들면 각 요소마다 filter 이후 map을 적용할 수 있음
=> 반면 wide dependency에서는, MapReduce처럼 Parent Patrtition의 모든 데이터가 Child들에 Shuffle되어야 한다.`),Z4=n(),Ff=i("li"),Gf=i("p"),X4=f(`node failure 이후 회복할 때는 narrow dependency에서 더 효율적임
=> 손실이 발생한 parent partition만 회복하면 되기 때문이며, 이는 다른 노드에서 병렬적으로 재연산이 가능
=> 반면 wide dependency의 lineage graph에서는, 특정 단일 노드에서 failure가 발생하면 해당 RDD의 조상으로부터 형성된 특정 파티션을 잃어버릴 수도 있으며, 이 경우 완전히 재실행해야 할 수도 있음.`),JD=n(),er=i("p"),Y4=f(`Spark에서, 이러한 RDD의 공통적인 인터페이스는 대부분의 transformation을 20줄 이내로 수행할 수 있게 하였음.
아래 내용은 여러 RDD 구현이 요약된 것임`),QD=n(),tr=i("p"),g4=f("HDFS Files"),KD=n(),w=i("ul"),zf=i("li"),l5=f("RDD가 HDFS의 파일인 경우, partitions()는 파일의 각 블록당 한 개의 partition이 반환된다."),e5=n(),Of=i("li"),t5=f("각 Partition 객체에 block offset이 포함되어 있다"),i5=n(),Tf=i("li"),r5=f("prefferedLocation()은 블록이 존재하는 노드를 반환한다."),a5=n(),qf=i("li"),o5=f("iterator()는 블록을 읽는다."),$D=n(),ir=i("p"),p5=f("map"),WD=n(),ve=i("ul"),Jf=i("li"),f5=f("임의의 RDD에서 map을 호출하면 MappedRDD 객체가 반환된다"),s5=n(),Qf=i("li"),n5=f("이 객체는 parent와 동일한 partition 및 preferred location을 가지지만, Iterator()는 parent의 record와 매핑하기 위해 전달된 함수를 적용한다."),VD=n(),rr=i("p"),u5=f("union"),ZD=n(),ce=i("ul"),Kf=i("li"),D5=f("두 개의 RDD에서 union을 호출하면, 각 부모의 partition이 합쳐진 partition을 가진 RDD가 반환됨"),v5=n(),$f=i("li"),c5=f("각각의 Child Partition은 parent에 대한 narrow dependency를 통해 계산됨"),XD=n(),ar=i("p"),_5=f("sample"),YD=n(),or=i("ul"),Wf=i("li"),m5=f("sample은 map과 비슷하지만, RDD가 parent record를 deterministically하게 샘플링하기 위해 각 partition마다 random number seed를 저장한다는 차이가 있음"),gD=n(),pr=i("p"),E5=f("join"),l2=n(),I=i("ul"),Vf=i("li"),d5=f("두 RDD를 join하는 연산은 세 가지 경우가 있음."),R5=n(),Zf=i("li"),L5=f("두 RDD가 동일 partition에 hash/range partition된 경우(partitioner가 같은 경우), 둘 다 narrow dependency"),I5=n(),Xf=i("li"),b5=f("둘 중 하나만 hash/range partition된 경우(partitioner를 가짐), narrow와 wide 혼합"),k5=n(),Yf=i("li"),y5=f("아니면, 둘 다 wide dependency임"),S5=n(),gf=i("li"),P5=f("어떤 경우이든 결과물인 RDD는 partitioner를 가지며, parent로부터 물려받거나 default hash partitioner를 가짐"),e2=n(),t2=i("br"),i2=i("br"),r2=n(),_e=i("h2"),me=i("a"),ls=i("span"),h5=f("Implementation"),a2=n(),o2=i("hr"),p2=n(),fr=i("p"),A5=f("Spark 시스템은 Mesos cluster manager 위에서 동작하며, Hadoop, MPI(Message Passing Interface) 등 다른 어플리케이션과 리소스를 공유할 수 있다."),f2=n(),Ee=i("ul"),es=i("li"),M5=f("각각의 Spark 프로그램은 driver(master)와 worker를 가진 별도의 Mesos Application으로 동작한다."),x5=n(),ts=i("li"),H5=f("애플리케이션 간의 자원 관리는 Mesos에 의해 처리된다."),s2=n(),sr=i("p"),U5=f("Spark는 HDFS, HBase 등 Hadoop의 입력 소스를 통해 데이터를 읽어올 수 있다."),n2=n(),de=i("ul"),is=i("li"),w5=f("기존의 Hadoop에서 사용하는 input plugin API를 사용한다."),C5=n(),rs=i("li"),B5=f("특별히 수정된 Scala 버전을 사용하지 않아도 된다."),u2=n(),Re=i("h3"),Le=i("a"),as=i("span"),j5=f("Job Scheduling"),D2=n(),X=i("p"),nr=i("img"),N5=i("br"),F5=f(`
그림에서 검정색은 이미 메모리에 올라가 있는 부분임.`),G5=i("br"),z5=f(`
stage 1의 결과물이 이미 RAM에 올라가 있으므로, stage 3의 RDD를 얻기 위해서는 stage 2, 3만 하면 됨`),v2=n(),ur=i("p"),O5=f("Spark scheduler는 4장에서 다루었던 RDD 표현을 사용한다. Spark의 scheduler는 Dryad의 scheduler와 비슷하지만, persistent RDD의 어떤 partition을 메모리에 올릴지도 고려한다."),c2=n(),b=i("ul"),os=i("li"),T5=f("위 그림처럼, 유저가 RDD에 대한 action을 수행할 때마다 scheduler는 실행할 stage의 DAG를 만들기 위해 RDD의 lineage graph를 검사한다."),q5=n(),ps=i("li"),J5=f("DAG : Directed Acyclic Graph. Cycle이 없는 Directed Graph"),Q5=n(),fs=i("li"),K5=f("각 stage는 narrow dependency로 구성할 수 있는, 여러 transform의 파이프라인으로 구성되어 있음"),$5=n(),ss=i("li"),W5=f("각 stage를 구분하는 것은 wide dependency에 필요한 shuffle 연산 또는 parent RDD의 계산을 단순화할 수 있는 이미 계산된 partition이다."),V5=n(),ns=i("li"),Z5=f("Scheduler는 대상 RDD가 계산될 때까지, 각 stage의 missing partition을 연산하는 작업을 생성한다."),_2=n(),Dr=i("p"),X5=f("Spark의 scheduler는 delay scheduling을 사용하여, data locality에 따라 machine에 작업 할당"),m2=n(),Y=i("ul"),us=i("li"),Y5=f("만약 task가 어느 노드의 메모리에서 사용 가능한 partition을 처리해야 할 경우, 해당 노드로 보낸다."),g5=n(),Ds=i("li"),lR=f(`또는 task가 HDFS처럼 preferred location이 존재하는 RDD의 partition을 처리하는 경우, 해당 파티션으로 보냄
Wide Dependency(shuffle)의 경우, 오류 복구를 단순화하기 위해 parent partition을 보유한 노드에 있는 intermediate record를 materialize함.`),eR=n(),vs=i("li"),tR=f("MapReduce가 map output을 materialize하는 것과 유사"),E2=n(),Ie=i("ol"),cs=i("li"),iR=f("만약 task가 failure하면, 해당 stage의 parent가 살아있는 한 다른 node에서 작업을 다시 실행함."),rR=n(),vr=i("li"),aR=f("만약 특정 stage 자체를 사용할 수 없는 경우(예를 들면 shuffle 중 map side의 출력값이 손실된 경우), 병렬적으로 missing partition을 계산하기 위해 task를 다시 전송한다."),_s=i("ul"),ms=i("li"),oR=f("RDD linage graph를 replicating하는 것은 간단하지만, scheduler 실패는 아직 핸들링하기 어려움"),d2=n(),cr=i("p"),pR=f("Spark의 모든 연산은 driver 프로그램에서 action이 호출되면 그에 따라 실행됨"),R2=n(),be=i("ul"),Es=i("li"),fR=f("하지만 map과 같은 cluster의 작업이 조회 작업을 호출하도록 하여, hash-partition된 RDD의 요소에 key값을 통해 random access할 수 있게 하는 실험도 하고 있음"),sR=n(),ds=i("li"),nR=f("이 경우, task는 scheduler에게 필요한 partition이 missing 상태일 경우 이를 계산하게끔 지시해야 함."),L2=n(),ke=i("h3"),ye=i("a"),Rs=i("span"),uR=f("Interpreter Integration"),I2=n(),_r=i("p"),DR=f("Scala는 Python이나 Ruby처럼 interactive shell을 제공함"),b2=n(),mr=i("ul"),Ls=i("li"),vR=f("데이터를 in-memory로 처리하여 latency가 낮기 때문에, 사용자는 Spark Interpreter를 통해 interactive하게 많은 양의 데이터에 query를 날릴 수 있음"),k2=n(),Er=i("p"),cR=f("Scala interpreter는 사용가 입력한 클래스가 있는 라인을 컴파일하여 JVM에 로드하고, 그 위에서 함수를 호출함."),y2=n(),C=i("ul"),Is=i("li"),_R=f("이러한 클래스는 그 라인에서 선언된 변수나 함수를 포함하며, initialize method로 그 라인을 실행하는 singleton object를 포함함."),mR=n(),bs=i("li"),ER=f("singleton object : class의 instance가 오직 1개만 생성됨"),dR=n(),ks=i("li"),RR=f("예를 들면, 만약 유저가 var x = 5를 입력하고 그 다음 println(x)를 입력했다고 가정"),LR=n(),ys=i("li"),IR=f("인터프리터는 x를 포함하는 Line1이라는 클래스를 만들고, println(Line1.getInstance().x)로 컴파일"),S2=n(),dr=i("p"),bR=f("Spark interpreter에서는 두 가지의 변화를 줬음"),P2=n(),Se=i("ol"),Ss=i("li"),kR=f("Class Shipping: worker 노드가 각 라인에 선언된 클래스의 바이트 코드를 읽어올 수 있게끔, interpreter는 이런 클래스를 HTTP로 전송함."),yR=n(),Rr=i("li"),SR=f("수정된 코드 생성: 일반적으로 코드의 각 라인마다 생성된 Singleton Object는 해당 클래스의 static method를 통해 접근함."),zt=i("ul"),Ps=i("li"),PR=f("위 예제(Line1.getInstance().x)처럼 이전 라인에서 정의된 변수를 참조하는 closure를 serialize할 때, Java는 object graph를 추적하여 x를 감싸는 Line1 인스턴스를 전달하지 않음. 따라서 worker 노드는 x를 받지 않을 것임."),hR=n(),hs=i("li"),AR=f("code generation logic을 수정하여, 참조를 하려고 할 시 각 라인의 object의 instance를 직접 참조하게끔 변경하였음"),h2=n(),Pe=i("p"),Lr=i("img"),MR=i("br"),xR=f(`
위 그림은 사용자가 입력한 라인을 interpreter가 어떻게 해석하는지 보여줌`),A2=n(),Ir=i("p"),HR=f("Spark interpreter를 쓰면 HDFS에 저장된 dataset을 탐색하거나, trace를 추적(아마 lineage graph?)하는데 유용하다는 것을 발견하였음."),M2=n(),he=i("h3"),Ae=i("a"),As=i("span"),UR=f("Memory Management"),x2=n(),br=i("p"),wR=f("Spark는 persistent RDD를 저장하기 위한 세 가지 옵션을 제공한다."),H2=n(),g=i("ol"),kr=i("li"),CR=f("in-memory storage - deserialized Java object"),Ms=i("ul"),xs=i("li"),BR=f("JVM이 RDD 요소를 native하게 접근할 수 있기 때문에 가장 빠름"),jR=n(),yr=i("li"),NR=f("in-memory storage – serialized data"),Hs=i("ul"),Us=i("li"),FR=f("Java의 object graph보다 메모리 측면에서는 효율적이지만, 성능은 감소"),GR=n(),Sr=i("li"),zR=f("on-disk storage"),ws=i("ul"),Cs=i("li"),OR=f("RDD가 너무 커서 RAM에 저장하기엔 너무 크지만 사용할 때마다 재계산하기에는 비용이 너무 많이 드는 RDD에 유용함"),U2=n(),Pr=i("p"),TR=f("사용 가능한 메모리는 제한적이므로, RDD 레벨에서 LRU 제거 정책을 사용함."),w2=n(),B=i("ul"),Bs=i("li"),qR=f("새로운 RDD Partition이 계산될 때 이를 저장할 공간이 충분치 않다면, 가장 예전에 access된 RDD를 쫓아냄."),JR=n(),js=i("li"),QR=f("예외적으로, 새로운 partition이 있는 RDD와 동일한 RDD는 쫓아내지 않는데, cycling partition이 일어나지 않게끔 하기 위함"),KR=n(),Ns=i("li"),$R=f("대부분의 작업은 RDD 전체에서 수행되기 때문에, 이는 굉장히 중요함. 이미 메모리에 있는 파티션이 미래에 필요할 가능성이 높음."),WR=n(),Fs=i("li"),VR=f("메모리 관리 정책의 기본값인 이 방식도 잘 동작하지만, 사용자는 각 RDD에 persistence priority를 부여하여 제어할 수도 있음."),C2=n(),Me=i("h3"),xe=i("a"),Gs=i("span"),ZR=f("Support for Checkpointing"),B2=n(),hr=i("p"),XR=f("RDD가 failure한 이후 lineage를 통해 복구할 수 있지만, lineage chain이 너무 길면 복구 과정에서 시간이 너무 오래 걸릴 수 있음"),j2=n(),Ar=i("ul"),zs=i("li"),YR=f("RDD를 stable storage에 checkpointing하면 유용함"),N2=n(),Mr=i("p"),gR=f("일반적으로 Checkpoint는 wide dependency를 포함하는, 긴 lineage graph의 RDD에 대해 유용함"),F2=n(),ll=i("ul"),Os=i("li"),l6=f("만약 이 경우 클러스터 안의 노드의 falilure는 각각의 parent RDD로부터 온 데이터 조각의 손실로 이어질 수 있음. 이 경우 모든 데이터를 다시 계산해야 함"),e6=n(),Ts=i("li"),t6=f("반면 narrow dependency의 경우에는, Checkpointing이 불필요함."),i6=n(),qs=i("li"),r6=f("노드가 실패하여 lost partition을 계산하려면 전체 RDD를 복제하는 비용의 극히 일부만으로 다른 노드에서 병렬적으로 재계산할 수 있기 때문"),G2=n(),xr=i("p"),a6=f("Spark는 (persist() method의 REPLICATE flag 등) checkpointing API를 제공함."),z2=n(),He=i("ul"),Js=i("li"),o6=f("다만 어떤 데이터를 checkpointing할지는 유저가 결정"),p6=n(),Qs=i("li"),f6=f("시스템 복구 시간을 최소화할 수 있도록 자동으로 checkpointing하는 방법을 연구 중에 있음"),O2=n(),Hr=i("p"),s6=f("RDD의 read-only라는 특성 덕에 일반적인 shared memory보다 checkpointing하기 쉬움."),T2=n(),Ue=i("ul"),Ks=i("li"),n6=f("data consistency를 고려할 필요가 없음"),u6=n(),$s=i("li"),D6=f("checkpointing을 background에서 진행하면서, 작동중인 프로그램을 멈추거나 특별한 분산 스냅샷 스키마를 사용할 필요가 없음. (동시에 가능)"),q2=n(),J2=i("br"),Q2=i("br"),K2=n(),we=i("h2"),Ce=i("a"),Ws=i("span"),v6=f("Evaluation"),$2=n(),W2=i("hr"),V2=n(),Ur=i("p"),c6=f("EC2에 올려서 Spark와 RDD, 및 이를 사용하는 User Application의 성능을 검사하였음"),Z2=n(),j=i("ol"),wr=i("li"),_6=f("스파크는 반복적인 기계 학습 및 그래프 애플리케이션에서 하둡을 최대 20배 능가함"),Vs=i("ul"),Zs=i("li"),m6=f("데이터를 자바 객체로 메모리에 저장함으로써 입출력 및 역직렬화 비용을 피할 수 있기 때문에 속도가 향상된다."),E6=n(),Cr=i("li"),d6=f("사용자가 작성한 애플리케이션에 올라간 Spark는 성능과 확장성이 뛰어나다."),Xs=i("ul"),Ys=i("li"),R6=f("analytics report 할 때 하둡보다 40배 빨랐음"),L6=n(),gs=i("li"),I6=f("노드에 장애가 발생하면 스파크는 손실된 RDD 파티션만 재구성하여 신속하게 복구할 수 있다."),b6=n(),ln=i("li"),k6=f("스파크는 1TB 데이터 세트를 5-7초의 지연시간(latency)으로 대화식(interactively)으로 쿼리하는 데 사용할 수 있다"),X2=n(),Be=i("h3"),je=i("a"),en=i("span"),y6=f("Iterative Machine Learning Applications"),Y2=n(),Ne=i("p"),Br=i("img"),S6=n(),jr=i("img"),g2=n(),el=i("ul"),tn=i("li"),P6=f("Logistic Regression: I/O 및 serialization sensitive"),h6=n(),rn=i("li"),A6=f("K-Means: compute-intensive"),M6=n(),Nr=i("li"),x6=f("HadoopBinMem"),Ot=i("ul"),an=i("li"),H6=f("input data를 binary format으로 바꾸는 hadoop 버전"),U6=n(),on=i("li"),w6=f("데이터를 in-memory HDFS 인스턴스에 저장"),lv=n(),Fr=i("p"),C6=f("그림 7의 First iteration: HadoopBM > Hadoop > Spark"),ev=n(),tl=i("ul"),pn=i("li"),B6=f("HadoopBM : 데이터를 binary로 바꾸는 추가적인 작업 및 in-memory HDFS를 replicate하는 overhead로 인해 가장 느림"),j6=n(),fn=i("li"),N6=f("Hadoop : heartbeat를 보내기 위한 Signaling overhead로 인해 Spark보다 느림"),F6=n(),sn=i("li"),G6=f("Spark: 이후의 Iteration부터는 RDD로 인해 데이터가 reuse되어 빨라짐"),tv=n(),Gr=i("p"),z6=f("그림 8: 그냥 machine 수 달리해서 재 본거임. 역시 spark가 제일 빠름"),iv=n(),zr=i("p"),O6=f("하둡이 느린 이유"),rv=n(),il=i("ol"),nn=i("li"),T6=f(`하둡의 소프트웨어 스택의 오버헤드
=> 하둡은 job을 수행할 때 job 설정, task 시작, 정리 등의 overhead 등으로 인해, 최소 25초의 오버헤드가 발생`),q6=n(),un=i("li"),J6=f(`데이터를 서빙할 때 HDFS의 오버헤드
=> HDFS는 여러 개의 메모리 복사본을 각 블록에 전송하며, 각 블록에 체크섬을 수행하기 때문에 오버헤드 발생`),Q6=n(),Dn=i("li"),K6=f("binary record를 Java object로 변경하기 위한 deserialization 비용"),av=n(),Fe=i("p"),Or=i("img"),$6=i("br"),W6=f(`
Text – binary 시간 차이 : parsing에 소요되는 시간`),ov=n(),Ge=i("ul"),vn=i("li"),V6=f("Hadoop은 binary data를 Java object로 변환하는데 시간이 필요함"),Z6=n(),cn=i("li"),X6=f("Spark는 RDD 요소를 메모리에 Java object로 바로 저장하므로, 오버헤드를 회피함"),pv=n(),ze=i("h3"),Oe=i("a"),_n=i("span"),Y6=f("PageRank"),fv=n(),Te=i("p"),Tr=i("img"),g6=i("br"),l7=f(`
PageRank에서도 Spark가 빠르게 나옴`),sv=n(),qe=i("ul"),mn=i("li"),e7=f("Controlled Partitioning을 해주면, data access가 일관되게 일어나기 때문에 속도를 향상시킬 수 있다"),t7=n(),En=i("li"),i7=f("또한 Pregel에서 PageRank를 돌려도, Pregel은 추가적인 연산을 하기 때문에 Spark의 버전보다 4초정도 더 길게 나옴."),nv=n(),Je=i("h3"),Qe=i("a"),dn=i("span"),r7=f("Fault Recovery"),uv=n(),Ke=i("p"),qr=i("img"),a7=i("br"),o7=f(`
K-means를 돌릴 때 failure가 발생한 경우 recovery에 얼마나 시간이 걸리는지 보여줌`),Dv=n(),rl=i("ul"),Rn=i("li"),p7=f("6번째 iteration에서 machine 하나 죽여서, 그 machine에서 돌아가는 task가 실패"),f7=n(),Ln=i("li"),s7=f("다른 machone에서 task를 다시 실행"),n7=n(),In=i("li"),u7=f("해당 task의 input data와 RDD lineage를 다시 읽고, RDD Partition을 재구성"),vv=n(),Jr=i("p"),D7=f("checkpoint 기반의 장애 복구 메커니즘은 체크포인트 빈도에 따라 작업을 여러번 반복해야 할수도 있음"),cv=n(),al=i("ul"),bn=i("li"),v7=f("또한 시스템은 네트워크를 통해 대용량의 working set을 replicate해야 함"),c7=n(),kn=i("li"),_7=f("이를 RAM에 복제하면 Spark의 두 배 메모리를 쓰는 거고, DISK에 복제하면 대용량의 데이터를 쓰는 것을 기다려야 함"),m7=n(),yn=i("li"),E7=f("Spark의 RDD lineage graph는 크기가 10kb 미만"),_v=n(),$e=i("h3"),We=i("a"),Sn=i("span"),d7=f("Behavior with Insufficient Memory"),mv=n(),Ve=i("p"),Qr=i("img"),R7=i("br"),L7=f(`
성능이 감소되긴 하지만 Graceful하게(어느정도 하락폭을 예측할 수 있게) 감소됨`),Ev=n(),Ze=i("h3"),Xe=i("a"),Pn=i("span"),I7=f("User Applications Built with Spark"),dv=n(),Kr=i("p"),b7=f("In-memory Analytics:"),Rv=n(),$r=i("ul"),Wr=i("li"),k7=f("영상 배포하는 Conviva Inc라는 회사는 analytic report를 만들기 위해 하둡을 쓰다가 Spark를 사용"),hn=i("ul"),An=i("li"),y7=f("40배 빨라짐"),Lv=n(),Vr=i("p"),Zr=i("img"),Iv=n(),Xr=i("p"),S7=f("Traffic Modeling:"),bv=n(),Yr=i("ul"),gr=i("li"),P7=f("산발적으로 수집된 자동차 GPS 측정치에서 교통 현황을 추정하기 위한 학습 알고리즘을 병렬적으로 구성함."),Mn=i("ul"),xn=i("li"),h7=f("두 개의 map과 reduceByKey를 반복적으로 적용하여 모델을 학습시켰고, 성능이 선형적으로 확장됨 (분산처리가 잘 되고 있음)"),kv=n(),la=i("p"),A7=f("Twitter Spam Classification:"),yv=n(),ea=i("ul"),ta=i("li"),M7=f("트위터의 스팸 메시지에서 link를 검증하기 위해 Spark 사용"),Ll=i("ul"),Hn=i("li"),x7=f("앞서 봤던 logistic regression를 사용하였고, URL이 가리키는 페이지 정보를 수집함."),H7=n(),Un=i("li"),U7=f("성능이 linear하게 늘어나지는 않았음 (communication cost가 iteration보다 높아지기 때문)"),w7=n(),wn=i("li"),C7=f("아마 네트워크에 접속해서 페이지 정보를 읽어와야 하기 때문인 듯"),Sv=n(),Ye=i("h3"),ge=i("a"),Cn=i("span"),B7=f("Interactive Data Mining"),Pv=n(),lt=i("p"),ia=i("img"),j7=i("br"),N7=f(`
Spark는 거대한 dataset에 대화식 query를 날릴 수 있음`),hv=n(),ol=i("ul"),Bn=i("li"),F7=f("(1) => 전체 페이지에 query하여 조회수 확인"),G7=n(),jn=i("li"),z7=f("(2) => 제목이 주어진 단어와 같은 페이지만 조회수 확인"),O7=n(),ra=i("li"),T7=f("(3) => 제목이 부분적으로 일치하는 페이지만 조회수 확인"),Nn=i("ul"),Fn=i("li"),q7=f("response time이 on-disk에서 하는 것보다 훨씬 빠름 (on-disk는 170초 걸렸다고 함)"),Av=n(),Mv=i("br"),xv=i("br"),Hv=n(),et=i("h2"),tt=i("a"),Gn=i("span"),J7=f("Discussions"),Uv=n(),wv=i("hr"),Cv=n(),aa=i("p"),Q7=f("RDD는 immutable하고 coarse-grained transformation을 하므로, 제한된 interface만을 제공하는 것처럼 보이지만, 다양한 application에 적합함"),Bv=n(),it=i("h3"),rt=i("a"),zn=i("span"),K7=f("Expressing Existing Programming Models"),jv=n(),oa=i("p"),$7=f("RDD는 지금까지 제안되어 온 다양한 클러스터 프로그래밍 모델을 “효율적으로” 표현할 수 있음"),Nv=n(),at=i("ul"),On=i("li"),W7=f("효율적이라는 말은, 단순히 이러한 모델로 작성한 프로그램과 동일한 output을 얻을 수 있을 뿐 아니라, 최적화까지 가능함."),V7=n(),Tn=i("li"),Z7=f("데이터를 memory에 보관하고, communication을 minimize하기 위해 잘 partitioning하고, failure를 효율적으로 recovery함"),Fv=n(),pa=i("p"),X7=f("RDD로 표현 가능한 모델"),Gv=n(),N=i("ul"),qn=i("li"),Y7=f("MapReduce: flatMap, GroupByKey, reduceByKey가 각각 Mapper, Reducer, Combiner에 해당"),g7=n(),Jn=i("li"),lL=f("DryadLINQ: Spark로도 할 수 있음"),eL=n(),Qn=i("li"),tL=f("SQL: SQL query를 날려서 data-parallel operation을 수행할 수 있음"),iL=n(),fa=i("li"),rL=f("Pregel: Google Pregel은 iterative graph application에 특화된 모델임"),Kn=i("ul"),$n=i("li"),aL=f("RDD를 사용하면 Pregel이 하는 것처럼 vertex state를 메모리에 유지하고, Partitioning을 제어하고, 통신을 최소화하고, 장애 시 부분적인 복구를 수행할 수 있다."),zv=n(),sa=i("p"),oL=f("Iterative MapReduce"),Ov=n(),F=i("ul"),Wn=i("li"),pL=f("HaLoop 및 Twister 등 MapReduce를 Iterative하게 돌리기 위한 시스템이 있음"),fL=n(),Vn=i("li"),sL=f(`얘네의 핵심은 partitioning 및 메모리에 올려놓고 reuse하는 것인데, 이것도 Spark 200줄로 표현이 가능했음
Batched Stream Processing`),nL=n(),Zn=i("li"),uL=f("새로운 데이터를 받아서 주기적으로 결과를 업데이트하는 점진적인 시스템"),DL=n(),Xn=i("li"),vL=f("Intermediate state를 RDD로 두면 처리 속도가 향상됨."),Tv=n(),na=i("p"),cL=f("RDD가 이렇게 다양한 프로그래밍 모델을 표현할 수 있는 이유는, RDD의 제약조건이 다수의 병렬 어플리케이션에서 큰 의미가 없기 때문임."),qv=n(),G=i("ul"),Yn=i("li"),_L=f("RDD는 오직 transformation을 거쳐서 생성될 수 있음"),mL=n(),gn=i("li"),EL=f("근데 대부분의 병렬 프로그램이 표현을 쉽게 하려고 원래 동일한 연산을 record에 적용하고 있음."),dL=n(),lu=i("li"),RL=f("동일한 dataset의 버전을 나타내기 위해 여러 개의 RDD를 생성할 수 있기 때문에, RDD의 immutability는 장애물이 아님."),LL=n(),eu=i("li"),IL=f("실제로, 대부분의 MapReduce 애플리케이션은 HDFS 등 파일 업데이트를 허용하지 않는 파일 시스템에서 실행됨."),Jv=n(),ua=i("p"),bL=f("이전 프레임워크들은 데이터 공유를 위한 abstraction이 부족했기 때문에 이런 범용성을 가지지 못한 것 같음"),Qv=n(),ot=i("h3"),pt=i("a"),tu=i("span"),kL=f("Leveraging RDDs for Debugging"),Kv=n(),Da=i("p"),yL=f("DD는 fault tolerance를 위해 deterministical하게 다시 계산할 수 있게끔 설계되었지만, 이러한 특성 덕분에 디버깅도 잘함"),$v=n(),va=i("ul"),iu=i("li"),SL=f("작업 중 RDD의 lineage를 기록함으로써, RDD를 나중에 재구성하여 사용자가 대화식으로 query할 수 있고, RDD 종속된 파티션을 다시 계산하여 단일 프로세스 디버거에서 job의 모든 task를 다시 실행할 수 있음"),Wv=n(),ca=i("p"),PL=f("여러 노드에서 이벤트 순서를 캡쳐해야 하는 기존의 general distributed system에서의 replay debugger와는 달리, 이 방식은 RDD lineage graph만을 기록하기 때문에 recording overhead가 거의 없음."),Vv=n(),Zv=i("br"),Xv=i("br"),Yv=n(),ft=i("h2"),st=i("a"),ru=i("span"),hL=f("Related Work"),gv=n(),lc=i("hr"),ec=n(),_a=i("p"),AL=f("Cluster Programming Models:"),tc=n(),z=i("ol"),Tt=i("li"),au=i("p"),ML=f("data flow model"),xL=n(),qt=i("ul"),ou=i("li"),HL=f("MapReduce, Dryad, Ciel 등은 데이터 프로세싱을 위한 다양한 Operator 제공"),UL=n(),pu=i("li"),wL=f("반면 RDD는 data replication, I/O 및 serization의 높은 비용을 피하기 위해 stable storage보다 더 효율적인 abstraction을 제공함."),CL=n(),Jt=i("li"),fu=i("p"),BL=f("High level programming interface for data flow system"),jL=n(),Il=i("ul"),su=i("li"),NL=f("DryadLINQ, FlumeJava는 사용자가 map, join 등의 연산자로 parallel collection에 접근할 수 있는 language-integrated API를 제공"),FL=n(),nu=i("li"),GL=f("하지만 이러한 시스템들은 query의 결과를 다른 query로 pipeline하기 어려움"),zL=n(),uu=i("li"),OL=f("Spark는 이것이 가능하기 때문에, 다양한 Application에서 활용할 수 있음"),TL=n(),Qt=i("li"),Du=i("p"),qL=f("Pregel, HaLoop, Twister 등은 generic abstraction을 제공하지 않아서 정해진 용도 이외의 용도로 사용하기 어려움."),JL=n(),vu=i("ul"),cu=i("li"),QL=f("RDD는 distributed storage abstraction을 제공하여, interactive data mining 등 위의 시스템이 하기 어려운 것도 가능함"),KL=n(),Kt=i("li"),_u=i("p"),$L=f("Piccolo나 RAMCloud 등의 Distributed Shared Memory 기반의 시스템은 사용자가 in-memory computation을 수행할 수 있게끔, shared mutable state를 노출시킴."),WL=n(),bl=i("ul"),mu=i("li"),VL=f("RDD는 두 가지 측면에서 이러한 시스템과 다름"),ZL=n(),Eu=i("li"),XL=f("RDD는 map, sort, join 등 high level interface를 제공하는 반면, 위의 애들은 table cell에 대한 read/update밖에 지원하지 않음"),YL=n(),du=i("li"),gL=f("RDD는 Lineage based라서, 위 애들보다 checkpoint 및 rollback이 덜 무거움"),ic=n(),nt=i("p"),l0=f("Caching System:"),e0=i("br"),t0=f(`
Nectar는 DryadLINQ 작업에서 intermediate data를 재사용할 수 있음.`),rc=n(),O=i("ul"),Ru=i("li"),i0=f("RDD에서도 이러한 능력을 본땄음"),r0=n(),Lu=i("li"),a0=f("근데 Nectar는 in-memory caching을 제공하지 않고, 사용자가 원하는 dataset을 persist 및 partitioning control하게끔 하는 기능이 없음."),o0=n(),Iu=i("li"),p0=f("CIel 및 FlumeJava는 in-memory로 caching을 지원하지 않고, 원하는 데이터를 caching할 수 없음"),f0=n(),bu=i("li"),s0=f("분산 파일 시스템에 대한 인메모리 캐시도 제시되었지만, RDD처럼 중간 결과를 sharing하는 것보다는 약간 모자람"),ac=n(),ut=i("p"),n0=f("Lineage:"),u0=i("br"),D0=f(`
Lineage를 capture하는 것은 오랜 연구 주제였음.`),oc=n(),pl=i("ul"),ku=i("li"),v0=f("RDD는 fine-grained lineage를 capture하는 데 비용이 적게 드는 병렬 프로그래밍 모델을 제공하여, 장애 복구에 사용할 수 있도록 함."),c0=n(),yu=i("li"),_0=f("이러한 lineage based의 회복 매커니즘은 MapReduce나 Dryad의 메커니즘하고 비슷하지만, 얘네들은 job이 끝나면 lineage를 잃어버리므로, 컴퓨팅 간에 데이터를 공유하려면 replicated storage를 사용해야 함"),m0=n(),Su=i("li"),E0=f("반면 RDD는 disk I/O나 replication 없이 lineage를 써서, 데이터가 메모리에 지속되게 하여 효율적으로 데이터를 공유할 수 있음."),pc=n(),Dt=i("p"),d0=f("Relational Database:"),R0=i("br"),L0=f(`
RDMS는 fine-grained이며 모든 record에 대한 read/write 접근을 허용함. 또한 fault tolerance, logging operation, consistency를 유지해야 함`),fc=n(),ma=i("ul"),Pu=i("li"),I0=f("반면 RDS는 coarse-grained이므로 이런거 할 필요가 없음"),sc=n(),nc=i("br"),uc=i("br"),Dc=n(),vt=i("h2"),ct=i("a"),hu=i("span"),b0=f("Conclusion"),vc=n(),cc=i("hr"),_c=n(),Ea=i("p"),k0=f("RDD : cluster application에서 데이터를 sharing하는 abstraction"),mc=n(),da=i("ul"),Au=i("li"),y0=f("효율적인, general-purpose, fault-tolerance를 제공"),Ec=n(),Ra=i("p"),S0=f("RDD는 다양한 종류의 병렬 application을 표현할 수 있음"),dc=n(),La=i("ul"),Mu=i("li"),P0=f("iterative computation을 위해 제안된 많은 특화된 프로그래밍 모델과, 이러한 모델이 캡처하지 못하는 새로운 응용 프로그램 등 다양한 병렬 애플리케이션을 표현할 수 있음."),Rc=n(),Ia=i("p"),h0=f("fault tolerance를 위해 data replicating을 선택하는 기존 cluster의 storage abstraction과는 달리, RDD는 coarse-grained transformation 기반의 API를 제공"),Lc=n(),ba=i("ul"),xu=i("li"),A0=f("lineage를 통해 효율적으로 recover 가능"),Ic=n(),ka=i("p"),M0=f(`RDD가 구현된 시스템인 Spark의 성능은 interactive application에서 Hadoop보다 20배 뛰어남.
또한 100기가바이트 대의 데이터에 대화형 쿼리를 날릴 수도 있다.`),this.h()},l(l){d=r(l,"H2",{id:!0});var o=a(d);R=r(o,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Hu=a(R);Ht=r(Hu,"SPAN",{class:!0}),a(Ht).forEach(e),Hu.forEach(e),L_=s(o,"Abstraction"),o.forEach(e),Fu=u(l),$t=r(l,"P",{});var VI=a($t);I_=s(VI,"RDD(Resilient Distributed Datasets)"),VI.forEach(e),Gu=u(l),m=r(l,"UL",{});var T=a(m);Xa=r(T,"LI",{});var ZI=a(Xa);Ya=r(ZI,"P",{});var XI=a(Ya);b_=s(XI,"Resilient : 메모리 내부에서 데이터가 손실 시 유실된 파티션을 재연산해 복구할 수 있다."),XI.forEach(e),ZI.forEach(e),k_=u(T),ga=r(T,"LI",{});var YI=a(ga);lo=r(YI,"P",{});var gI=a(lo);y_=s(gI,"Distributed : 스파크 클러스터를 통하여 메모리에 분산되어 저장된다."),gI.forEach(e),YI.forEach(e),S_=u(T),Ut=r(T,"LI",{});var kc=a(Ut);eo=r(kc,"P",{});var l8=a(eo);P_=s(l8,"Data : 파일, 정보 등등"),l8.forEach(e),h_=u(kc),wt=r(kc,"UL",{});var yc=a(wt);to=r(yc,"LI",{});var e8=a(to);A_=s(e8,"분산 메모리 abstraction"),e8.forEach(e),M_=u(yc),io=r(yc,"LI",{});var t8=a(io);x_=s(t8,"fault-tolerant하게 in-memory computation 가능해짐"),t8.forEach(e),yc.forEach(e),kc.forEach(e),H_=u(T),ro=r(T,"LI",{});var i8=a(ro);ao=r(i8,"P",{});var r8=a(ao);U_=s(r8,"iterative한 작업이나 interactive data mining 작업의 경우 in-memory로 하면 성능 향상"),r8.forEach(e),i8.forEach(e),w_=u(T),oo=r(T,"LI",{});var a8=a(oo);po=r(a8,"P",{});var o8=a(po);C_=s(o8,"shared memory의 제약된 형태로 fine-grained보단 course-grained 사용함"),o8.forEach(e),a8.forEach(e),B_=u(T),fo=r(T,"LI",{});var p8=a(fo);so=r(p8,"P",{});var f8=a(so);j_=s(f8,"Spark에서는 이 RDD를 사용하여 다양한 형태의 user application이나 computation에서 적용 가능"),f8.forEach(e),p8.forEach(e),T.forEach(e),zu=u(l),Ou=r(l,"BR",{}),Tu=r(l,"BR",{}),qu=u(l),yl=r(l,"H2",{id:!0});var x0=a(yl);Sl=r(x0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var s8=a(Sl);no=r(s8,"SPAN",{class:!0}),a(no).forEach(e),s8.forEach(e),N_=s(x0,"Introduce"),x0.forEach(e),Ju=u(l),Qu=r(l,"HR",{}),Ku=u(l),Wt=r(l,"P",{});var n8=a(Wt);F_=s(n8,"MapReduce나 Dryad 등 데이터 분석 도구 특징"),n8.forEach(e),$u=u(l),q=r(l,"UL",{});var ya=a(q);uo=r(ya,"LI",{});var u8=a(uo);G_=s(u8,"fault tolerant나 work distribution에 대한 걱정 없이 High level operator를 통해 분산 환경에서 parallel computation 허용함"),u8.forEach(e),z_=u(ya),Do=r(ya,"LI",{});var D8=a(Do);O_=s(D8,"즉, 얘네들은 분산된 resource에 접근하는 abstraction임"),D8.forEach(e),T_=u(ya),vo=r(ya,"LI",{});var v8=a(vo);q_=s(v8,"근데 분산된 메모리를 활용하기 위한 abstraction은 부족함"),v8.forEach(e),ya.forEach(e),Wu=u(l),Vt=r(l,"P",{});var c8=a(Vt);J_=s(c8,"data reuse 측면"),c8.forEach(e),Vu=u(l),P=r(l,"UL",{});var _t=a(P);co=r(_t,"LI",{});var _8=a(co);Q_=s(_8,"iterative한 작업(머신 러닝, 그래프 알고리즘 등)이나 interactive data mining 작업을 할 때, computation 사이에서 데이터를 reuse하는 유일한 방법은 intermediate data를 external stable storage에 저장하는 것임. (이런 애들은 reuse 자주 함)"),_8.forEach(e),K_=u(_t),_o=r(_t,"LI",{});var m8=a(_o);$_=s(m8,"data replication, disk I/O, serialization 등 execution time 큰 것들로 인해 overhead 발생함"),m8.forEach(e),W_=u(_t),mo=r(_t,"LI",{});var E8=a(mo);V_=s(E8,"intermediate data를 메모리에 저장해서 reuse하는, Pregel과 HaLoop이라는 애들이 나오긴 했음. 근데 얘네들은 오직 특정한 형태의 computation pattern만 지원함"),E8.forEach(e),Z_=u(_t),Eo=r(_t,"LI",{});var d8=a(Eo);X_=s(d8,"general하게 reuse할 수 있는 abstraction은 없음"),d8.forEach(e),_t.forEach(e),Zu=u(l),Zt=r(l,"P",{});var R8=a(Zt);Y_=s(R8,"RDD는 다양한 application에서 data reuse를 가능하게 함"),R8.forEach(e),Xu=u(l),J=r(l,"UL",{});var Sa=a(J);Ro=r(Sa,"LI",{});var L8=a(Ro);g_=s(L8,"intermediate data를 메모리에 저장할 수 있는 fault tolerant, parallel 데이터 구조"),L8.forEach(e),lm=u(Sa),Lo=r(Sa,"LI",{});var I8=a(Lo);em=s(I8,"최적화되게끔 partitioning을 제어하거나 다양한 operator를 사용해서 데이터를 조작할 수 있음."),I8.forEach(e),tm=u(Sa),Io=r(Sa,"LI",{});var b8=a(Io);im=s(b8,"adhoc query를 돌릴 수도 있다."),b8.forEach(e),Sa.forEach(e),Yu=u(l),Xt=r(l,"P",{});var k8=a(Xt);rm=s(k8,"기존에 존재하는 클러스터 단위의 in-memory storage abstraction(distributed shared memory, key-value store, database, Piccolo)는 mutable state를 fine grade로 나누었음(ex. cells in table)"),k8.forEach(e),gu=u(l),Pl=r(l,"UL",{});var Sc=a(Pl);bo=r(Sc,"LI",{});var y8=a(bo);am=s(y8,"이런 방식에서 fault-tolerance를 제공하려면 machine들 사이에서 1. replication을 저장하거나, 2. log update를 해야 함."),y8.forEach(e),om=u(Sc),ko=r(Sc,"LI",{});var S8=a(ko);pm=s(S8,"이러한 방식은 상당한 양의 data-intensive workload가 발생하며, 데이터들이 cluster network를 통해 복사됨. cluster network의 bandwidth는 RAM보다 훨씬 별로라서, overhead가 발생함"),S8.forEach(e),Sc.forEach(e),l1=u(l),Yt=r(l,"P",{});var P8=a(Yt);fm=s(P8,"반면 RDD에서는 이런 시스템과는 달리, 많은 데이터 항목에 동일하게 operation을 적용 가능한 course-grained 기반의 정보 교환(map, filter, join 등)을 함"),P8.forEach(e),e1=u(l),h=r(l,"UL",{});var mt=a(h);yo=r(mt,"LI",{});var h8=a(yo);sm=s(h8,"실제 데이터가 아닌, dataset(lineage)을 만들 때 사용되는 transformation을 logging함으로써, fault tolerance 제공"),h8.forEach(e),nm=u(mt),So=r(mt,"LI",{});var A8=a(So);um=s(A8,"lineage chain이 점점 커지면 데이터 자체를 checkpointing하는 게 유용할 때도 있음"),A8.forEach(e),Dm=u(mt),Po=r(mt,"LI",{});var M8=a(Po);vm=s(M8,"만약 RDD의 partition을 손실한다고 해도, RDD에서는 그 partition이 다른 RDD로부터 어떻게 생겨났는지에 대한 정보를 가지고 있음. 따라서 그 파티션을 recompute함"),M8.forEach(e),cm=u(mt),ho=r(mt,"LI",{});var x8=a(ho);_m=s(x8,"따라서 손실된 데이터는 (비싼 data replication을 하지 않고도) 빠르게 복구될 수 있음"),x8.forEach(e),mt.forEach(e),t1=u(l),gt=r(l,"P",{});var H8=a(gt);mm=s(H8,"coarse-grained transformation 기반의 인터페이스가 처음에는 너무 제약된 형태로 보일 순 있지만, RDD는 다양한 병렬 application에 적합함."),H8.forEach(e),i1=u(l),hl=r(l,"UL",{});var Pc=a(hl);Ao=r(Pc,"LI",{});var U8=a(Ao);Em=s(U8,"이러한 application은 여러 data item에 동일한 operation을 적용하는 경향"),U8.forEach(e),dm=u(Pc),Mo=r(Pc,"LI",{});var w8=a(Mo);Rm=s(w8,"실제로, RDD는 MapReduce, Dryad, SQL, pregel, HaLoop 뿐만 아니라, 이러한 시스템으로 하기 어려운 interactive data mining과 같이 새로운 application 등, 분리된 시스템으로 제안된 cluster programming model에 적용될 수 있음"),w8.forEach(e),Pc.forEach(e),r1=u(l),li=r(l,"P",{});var C8=a(li);Lm=s(C8,"Spark라는 시스템에 RDD 구현하였음"),C8.forEach(e),a1=u(l),Al=r(l,"UL",{});var hc=a(Al);xo=r(hc,"LI",{});var B8=a(xo);Im=s(B8,"UC 버클리를 비롯한 여러 회사에서 연구 및 production에 사용중"),B8.forEach(e),bm=u(hc),Ho=r(hc,"LI",{});var j8=a(Ho);km=s(j8,"Spark는 language-intergrated programming interface를 제공함(언어 자체에 Query문이 포함된 LINQ처럼). 또한 Spark는 Scala interpreter를 통해서 크기가 큰 dataset에 query를 날릴 수 있음"),j8.forEach(e),hc.forEach(e),o1=u(l),ei=r(l,"P",{});var N8=a(ei);ym=s(N8,"Spark의 성능"),N8.forEach(e),p1=u(l),Ml=r(l,"UL",{});var Ac=a(Ml);Uo=r(Ac,"LI",{});var F8=a(Uo);Sm=s(F8,"iterative application에서 하둡보다 20배 빠르고, real-world data analytic report에서 40배 빠르고, 1TB dataset을 scan하는 데 5~7초가 걸린다."),F8.forEach(e),Pm=u(Ac),wo=r(Ac,"LI",{});var G8=a(wo);hm=s(G8,"RDD의 generality(범용성)을 증명하기 위해, Pregel과 HaLoop의 프로그래밍 모델을 Spark 위에서 구현하기도 했음. 이때 Pregel과 HaLoop이 사용하는 placement optimization을 적용하였고, 비교적 적은 라이브러리로 구현함."),G8.forEach(e),Ac.forEach(e),f1=u(l),s1=r(l,"BR",{}),n1=r(l,"BR",{}),u1=u(l),xl=r(l,"H2",{id:!0});var H0=a(xl);Hl=r(H0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var z8=a(Hl);Co=r(z8,"SPAN",{class:!0}),a(Co).forEach(e),z8.forEach(e),Am=s(H0,"Resilient Distributed Datasets(RDD)"),H0.forEach(e),D1=u(l),v1=r(l,"HR",{}),c1=u(l),Ul=r(l,"H3",{id:!0});var U0=a(Ul);wl=r(U0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var O8=a(wl);Bo=r(O8,"SPAN",{class:!0}),a(Bo).forEach(e),O8.forEach(e),Mm=s(U0,"RDD Abstraction"),U0.forEach(e),_1=u(l),ti=r(l,"P",{});var T8=a(ti);xm=s(T8,"RDD는 Read-only이며, record들의 Partitioned Collection임."),T8.forEach(e),m1=u(l),Q=r(l,"UL",{});var Pa=a(Q);jo=r(Pa,"LI",{});var q8=a(jo);Hm=s(q8,"RDD는 stable storage의 데이터나, 다른 RDD에 대한 deterministic operation을 통해서만 생성될 수 있음."),q8.forEach(e),Um=u(Pa),No=r(Pa,"LI",{});var J8=a(No);wm=s(J8,"deterministic : 예측한 그대로 동작. 어떤 특정한 입력이 들어오면 언제나 똑같은 과정을 거쳐서 언제나 똑같은 결과를 내놓는다."),J8.forEach(e),Cm=u(Pa),Fo=r(Pa,"LI",{});var Q8=a(Fo);Bm=s(Q8,"이러한 operation을 RDD의 다른 operation과 구분하기 위해 transform이라 부름. transform의 예는 map, filter, join 등이 있음"),Q8.forEach(e),Pa.forEach(e),E1=u(l),ii=r(l,"P",{});var K8=a(ii);jm=s(K8,"RDD는 항상 materialized일 필요는 없음(구체적으로 모든 정보를 포함할 필요는 없음)."),K8.forEach(e),d1=u(l),Cl=r(l,"UL",{});var Mc=a(Cl);Go=r(Mc,"LI",{});var $8=a(Go);Nm=s($8,"대신 stable storage에 저장된 데이터의 partition을 계산하기 위해, 다른 dataset(lineage)으로부터 어떻게 만들어진 것인지에 대해 정보를 포함하고 있음"),$8.forEach(e),Fm=u(Mc),zo=r(Mc,"LI",{});var W8=a(zo);Gm=s(W8,"프로그램은 failure가 발생한 후 reconstruct할 수 없는 RDD를 참조할 수 없음"),W8.forEach(e),Mc.forEach(e),R1=u(l),ri=r(l,"P",{});var V8=a(ri);zm=s(V8,"사용자는 RDD의 persistence(지속성)과 partitioning을 조절할 수 있음."),V8.forEach(e),L1=u(l),K=r(l,"UL",{});var ha=a(K);Oo=r(ha,"LI",{});var Z8=a(Oo);Om=s(Z8,"재사용할 RDD를 지정하고, 어떤 storage strategy를 사용할 것인지 결정 가능 (ex. in-memory storage)"),Z8.forEach(e),Tm=u(ha),To=r(ha,"LI",{});var X8=a(To);qm=s(X8,"또한 RDD element가 각 record의 key에 따라 machine별로 partition 되게끔 요청할 수 있음"),X8.forEach(e),Jm=u(ha),qo=r(ha,"LI",{});var Y8=a(qo);Qm=s(Y8,"이는 placement optimization할 때 유용"),Y8.forEach(e),ha.forEach(e),I1=u(l),Bl=r(l,"H3",{id:!0});var w0=a(Bl);jl=r(w0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var g8=a(jl);Jo=r(g8,"SPAN",{class:!0}),a(Jo).forEach(e),g8.forEach(e),Km=s(w0,"Spark Programming Interface"),w0.forEach(e),b1=u(l),ai=r(l,"P",{});var l9=a(ai);$m=s(l9,"Spark는 laguage-integrated API를 통해 RDD를 제공함"),l9.forEach(e),k1=u(l),oi=r(l,"UL",{});var e9=a(oi);Qo=r(e9,"LI",{});var t9=a(Qo);Wm=s(t9,"DryadLINQ나 FlumeJava와 유사함. 여기서는 각각의 dataset이 object로 표현되고, method를 통해 transformation을 호출함"),t9.forEach(e),e9.forEach(e),y1=u(l),pi=r(l,"P",{});var i9=a(pi);Vm=s(i9,"개발자들은 stable storage로부터 (map이나 filter 등의)transformation을 함으로써, 한 개 이상의 RDD를 정의할 수 있음."),i9.forEach(e),S1=u(l),$=r(l,"UL",{});var Aa=a($);Ko=r(Aa,"LI",{});var r9=a(Ko);Zm=s(r9,"이렇게 RDD를 얻으면, action을 취할 수 있음"),r9.forEach(e),Xm=u(Aa),fi=r(Aa,"LI",{});var C0=a(fi);Ym=s(C0,"action : 그 값을 applciation으로 반환하거나, storage system 밖으로 데이터를 빼내는 등으로 사용하는 것. action의 예는 다음과 같음"),Dl=r(C0,"UL",{});var Ma=a(Dl);$o=r(Ma,"LI",{});var a9=a($o);gm=s(a9,"count : dataset 내의 element의 수"),a9.forEach(e),lE=u(Ma),Wo=r(Ma,"LI",{});var o9=a(Wo);eE=s(o9,"collect : element 자체를 반환"),o9.forEach(e),tE=u(Ma),Vo=r(Ma,"LI",{});var p9=a(Vo);iE=s(p9,"save : dataset을 storage system에 저장"),p9.forEach(e),Ma.forEach(e),C0.forEach(e),rE=u(Aa),Zo=r(Aa,"LI",{});var f9=a(Zo);aE=s(f9,"Spark는 RDD에서 처음 실행되는 action을 느리게 연산하여, transformation에 pipeline할 수 있음"),f9.forEach(e),Aa.forEach(e),P1=u(l),si=r(l,"P",{});var s9=a(si);oE=s(s9,"persist : 특정 RDD가 미래의 operation에서 reuse될 수 있게끔 지정하는 method"),s9.forEach(e),h1=u(l),A=r(l,"UL",{});var Et=a(A);Xo=r(Et,"LI",{});var n9=a(Xo);pE=s(n9,"Spark는 default로 persistent RDD를 메모리에 저장해둠"),n9.forEach(e),fE=u(Et),Yo=r(Et,"LI",{});var u9=a(Yo);sE=s(u9,"하지만 RAM에 공간이 없으면 disk로 spill할 수 있음"),u9.forEach(e),nE=u(Et),go=r(Et,"LI",{});var D9=a(go);uE=s(D9,"유저 또한 다른 persistence strategy를 요청할 수 있음. 예를 들면 persist라는 flag는 RDD를 disk에만 저장하거나, 다른 machine들에 replication을 저장함"),D9.forEach(e),DE=u(Et),lp=r(Et,"LI",{});var v9=a(lp);vE=s(v9,"유저는 RDD별로 persistence priority를 지정하여, 어떤 in-memory data가 disk로 먼저 spill되게끔 할 것인지 결정할 수 있음"),v9.forEach(e),Et.forEach(e),A1=u(l),Nl=r(l,"H4",{id:!0});var B0=a(Nl);Fl=r(B0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var c9=a(Fl);ep=r(c9,"SPAN",{class:!0}),a(ep).forEach(e),c9.forEach(e),cE=s(B0,"Example: Console Log Mining"),B0.forEach(e),M1=u(l),ni=r(l,"P",{});var _9=a(ni);_E=s(_9,"웹 서비스가 장애를 겪고 있고, 오퍼레이터가 원인을 찾아내기 위해 테라바이트 단위의 로그를 HDFS로 분석해 본다고 가정해봅시다."),_9.forEach(e),x1=u(l),ui=r(l,"UL",{});var m9=a(ui);vl=r(m9,"LI",{});var xa=a(vl);mE=s(xa,"Spark를 쓰면 오페레이터는 log의 에러 메시지를 RAM으로 불러와서, interactively(대화식) query를 날릴 수 있다."),EE=r(xa,"BR",{}),dE=u(xa),Di=r(xa,"IMG",{src:!0,alt:!0}),cl=r(xa,"UL",{});var Ha=a(cl);tp=r(Ha,"LI",{});var E9=a(tp);RE=s(E9,"line 1 : HDFS 파일으로부터 RDD를 정의한다"),E9.forEach(e),LE=u(Ha),ip=r(Ha,"LI",{});var d9=a(ip);IE=s(d9,"line 2 : 1의 RDD에서 Filter된 RDD (ERROR로 시작하는 데이터) => scala 문법으로 가능!"),d9.forEach(e),bE=u(Ha),Ct=r(Ha,"LI",{});var xc=a(Ct);kE=s(xc,"line 3 : "),rp=r(xc,"EM",{});var R9=a(rp);yE=s(R9,"errors"),R9.forEach(e),SE=s(xc,"라는 RDD가 메모리에 남아서, query 사이에서 공유될 수 있게 함"),xc.forEach(e),Ha.forEach(e),xa.forEach(e),m9.forEach(e),H1=u(l),_l=r(l,"P",{});var Uu=a(_l);PE=s(Uu,"cluster에 수행될 작업이 없다면, RDD로 에러 메시지의 수를 세는 등, action을 할 수 있음."),hE=r(Uu,"BR",{}),AE=u(Uu),vi=r(Uu,"IMG",{src:!0,alt:!0}),Uu.forEach(e),U1=u(l),ml=r(l,"P",{});var wu=a(ml);ME=s(wu,"사용자는 이렇게 얻은 RDD에서 추가적인 transformation을 실행하고, 그렇게 또 얻은 RDD에서 결과를 얻을 수 있음"),xE=r(wu,"BR",{}),HE=u(wu),ci=r(wu,"IMG",{src:!0,alt:!0}),wu.forEach(e),w1=u(l),El=r(l,"P",{});var Cu=a(El);ap=r(Cu,"EM",{});var L9=a(ap);UE=s(L9,"errors"),L9.forEach(e),wE=s(Cu,"에 관련된 첫 번째 액션(위에선 count)이 실행되면, Spark는 "),op=r(Cu,"EM",{});var I9=a(op);CE=s(I9,"errors"),I9.forEach(e),BE=s(Cu,"의 partition을 메모리에 불러옴. 그러면 다음의 매우 연산이 빨라짐"),Cu.forEach(e),C1=u(l),Gl=r(l,"UL",{});var Hc=a(Gl);pp=r(Hc,"LI",{});var b9=a(pp);Rh(zl.$$.fragment,b9),b9.forEach(e),jE=u(Hc),fp=r(Hc,"LI",{});var k9=a(fp);NE=s(k9,"에러 메시지는 데이터의 극히 일부분에 해당하는 것이기에 충분히 작음. 메모리에 올려도 괜찮음"),k9.forEach(e),Hc.forEach(e),B1=u(l),_i=r(l,"P",{});var y9=a(_i);FE=s(y9,"이 모델이 fault tolerance를 달성하는 방법을 그림으로 나타낸 것"),y9.forEach(e),j1=u(l),mi=r(l,"P",{});var S9=a(mi);Ei=r(S9,"IMG",{src:!0,alt:!0}),S9.forEach(e),N1=u(l),M=r(l,"UL",{});var dt=a(M);di=r(dt,"LI",{});var j0=a(di);GE=s(j0,"위 3개의 query에 대한, RDD의 lineage graph"),dl=r(j0,"OL",{});var Ua=a(dl);Bt=r(Ua,"LI",{});var Uc=a(Bt);zE=s(Uc,"lines라는 RDD에 대한 filter의 결과로, "),sp=r(Uc,"EM",{});var P9=a(sp);OE=s(P9,"errors"),P9.forEach(e),TE=s(Uc,"라는 RDD를 얻음"),Uc.forEach(e),qE=u(Ua),np=r(Ua,"LI",{});var h9=a(np);JE=s(h9,"1에서 filter하여 다음의 RDD, map 하여 다음의 RDD를 얻음"),h9.forEach(e),QE=u(Ua),up=r(Ua,"LI",{});var A9=a(up);KE=s(A9,"2에서 collect()"),A9.forEach(e),Ua.forEach(e),j0.forEach(e),$E=u(dt),Dp=r(dt,"LI",{});var M9=a(Dp);WE=s(M9,"Spark의 스케쥴러는 2의 map, filter 변환을 파이프라인화함"),M9.forEach(e),VE=u(dt),Ol=r(dt,"LI",{});var Bu=a(Ol);vp=r(Bu,"EM",{});var x9=a(vp);ZE=s(x9,"errors"),x9.forEach(e),XE=s(Bu,"라는 RDD의 데이터가 캐싱되어 있는 partition을 가진 node한테 연산하라고 던짐 (아까 "),cp=r(Bu,"EM",{});var H9=a(cp);YE=s(H9,"errors"),H9.forEach(e),gE=s(Bu,"는 count() 했었죠? 메모리에 올라가 있음)"),Bu.forEach(e),l3=u(dt),_p=r(dt,"LI",{});var U9=a(_p);e3=s(U9,"만약 partition을 손실할 경우, Spark는 해당되는 line 파티션에만 filter를 적용하여 재구성함"),U9.forEach(e),dt.forEach(e),F1=u(l),Tl=r(l,"H3",{id:!0});var N0=a(Tl);ql=r(N0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var w9=a(ql);mp=r(w9,"SPAN",{class:!0}),a(mp).forEach(e),w9.forEach(e),t3=s(N0,"Advantages of the RDD Model"),N0.forEach(e),G1=u(l),Ri=r(l,"P",{});var C9=a(Ri);Li=r(C9,"IMG",{src:!0,alt:!0}),C9.forEach(e),z1=u(l),Ii=r(l,"P",{});var B9=a(Ii);i3=s(B9,"RDD와 Distributed Shared Memory(DSM)를 비교했을 때 장점이 나옴."),B9.forEach(e),O1=u(l),c=r(l,"UL",{});var E=a(c);Ep=r(E,"LI",{});var j9=a(Ep);r3=s(j9,"DSM은 global address space의 임의의 공간에서 read/write를 수행"),j9.forEach(e),a3=u(E),dp=r(E,"LI",{});var N9=a(dp);o3=s(N9,"전통적인 shared memory system 뿐 아니라, Piccolo나 분산 데이터베이스 등 shared state를 fine-grained로 write하는 application도 DHT 사용함"),N9.forEach(e),p3=u(E),Rp=r(E,"LI",{});var F9=a(Rp);f3=s(F9,"DSM은 일반적인 방식이지만, 하지만 이런 방식은 commodity cluster에서 효율적이고 fault-tolerant한 방식으로 구현하기 어려움"),F9.forEach(e),s3=u(E),Lp=r(E,"LI",{});var G9=a(Lp);n3=s(G9,"DSM은 각 메모리의 위치별 read / write를 허용하지만(이게 fine-grained의 정의임. 그리고 RDD도 read 연산은 fine-grained로 가능함), 반면 RDD는 Course-grained인 transformation을 통해서만 생성(write)될 수 있음"),G9.forEach(e),u3=u(E),Ip=r(E,"LI",{});var z9=a(Ip);D3=s(z9,"이는 RDD를 사용하는 application이 bulk write만 하게끔 제약하지만, 보다 효율적인 fault-tolerance를 제공함"),z9.forEach(e),v3=u(E),bp=r(E,"LI",{});var O9=a(bp);c3=s(O9,"RDD는 checkpointing의 overhead가 없는 대신, lineage를 통해 회복이 가능. (물론 lineage chain이 너무 길 경우 체크포인트를 쓰기도 함. 나중에 다룰 예정)"),O9.forEach(e),_3=u(E),kp=r(E,"LI",{});var T9=a(kp);m3=s(T9,`또한 RDD에서는 failure 발생 시 오직 손실된 partition만 복구하며, 이는 전체 프로그램을 rollback할 필요 없이 다른 node에서 병렬적으로 실행 가능함.
RDD의 두 번째 장점은, straggler가 있으면 그 태스크의 백업 복사본을 실행할 수 있다는 것(MapReduce처럼)`),T9.forEach(e),E3=u(E),yp=r(E,"LI",{});var q9=a(yp);d3=s(q9,"DSM에서는 Backup Task를 만드는 것이 어려움. 두 task가 동일한 메모리 영역을 액세스하여, 설의 업데이트를 방해하는 등 문제가 생길 수 있기 때문임."),q9.forEach(e),E.forEach(e),T1=u(l),bi=r(l,"P",{});var J9=a(bi);R3=s(J9,"마지막으로, RDD는 두 가지 이점을 제공함"),J9.forEach(e),q1=u(l),Jl=r(l,"UL",{});var wc=a(Jl);Sp=r(wc,"LI",{});var Q9=a(Sp);Pp=r(Q9,"OL",{});var K9=a(Pp);hp=r(K9,"LI",{});var $9=a(hp);L3=s($9,"bulk 연산에서 data locality에 따라 runtime schedule 가능 => 성능 향상"),$9.forEach(e),K9.forEach(e),Q9.forEach(e),I3=u(wc),ki=r(wc,"LI",{});var F0=a(ki);jt=r(F0,"OL",{start:!0});var G0=a(jt);Ap=r(G0,"LI",{});var W9=a(Ap);b3=s(W9,"스캔 기반 작업에만 사용된다면, 저장할 공간이 없을 때 성능 저하가 graceful하게 일어남."),W9.forEach(e),k3=u(G0),G0.forEach(e),Mp=r(F0,"UL",{});var V9=a(Mp);xp=r(V9,"LI",{});var Z9=a(xp);y3=s(Z9,"RAM에 맞지 않는 partition은 disk에 저장되며, 현재의 data-parallel system과 유사한 성능을 냄."),Z9.forEach(e),V9.forEach(e),F0.forEach(e),wc.forEach(e),J1=u(l),Ql=r(l,"H3",{id:!0});var z0=a(Ql);Kl=r(z0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var X9=a(Kl);Hp=r(X9,"SPAN",{class:!0}),a(Hp).forEach(e),X9.forEach(e),S3=s(z0,"Application Not Suitable for RDDs"),z0.forEach(e),Q1=u(l),yi=r(l,"P",{});var Y9=a(yi);P3=s(Y9,"RDD는 same operation을 전체 dataset에 적용하는 batch application에 적합함"),Y9.forEach(e),K1=u(l),Si=r(l,"UL",{});var g9=a(Si);Up=r(g9,"LI",{});var lb=a(Up);h3=s(lb,"RDD는 각 단계의 transformation을 lineage graph의 한 단계로 기억하며, 많은 양의 데이터를 기록할 필요 없이 손실된 partition을 복구할 수 있음."),lb.forEach(e),g9.forEach(e),$1=u(l),Pi=r(l,"P",{});var eb=a(Pi);A3=s(eb,"반면 부적합한 application도 존재함"),eb.forEach(e),W1=u(l),W=r(l,"UL",{});var wa=a(W);hi=r(wa,"LI",{});var O0=a(hi);M3=s(O0,"asynchronous하게 fine-grained shared state를 update하는 application"),Nt=r(O0,"UL",{});var Cc=a(Nt);wp=r(Cc,"LI",{});var tb=a(wp);x3=s(tb,"web server의 storage system"),tb.forEach(e),H3=u(Cc),Cp=r(Cc,"LI",{});var ib=a(Cp);U3=s(ib,"점진적인 web crawler"),ib.forEach(e),Cc.forEach(e),O0.forEach(e),w3=u(wa),Bp=r(wa,"LI",{});var rb=a(Bp);C3=s(rb,"이러한 Application의 경우, 전통적인 log update, data checkpoint를 생성하는, database를 사용하는 것이 좋음"),rb.forEach(e),B3=u(wa),jp=r(wa,"LI",{});var ab=a(jp);j3=s(ab,"Spark의 목표는 batch analytic을 위한 프로그래밍 모델을 제공하는 것"),ab.forEach(e),wa.forEach(e),V1=u(l),Z1=r(l,"BR",{}),X1=r(l,"BR",{}),Y1=u(l),$l=r(l,"H2",{id:!0});var T0=a($l);Wl=r(T0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ob=a(Wl);Np=r(ob,"SPAN",{class:!0}),a(Np).forEach(e),ob.forEach(e),N3=s(T0,"Spark Programming Interfaces"),T0.forEach(e),g1=u(l),lD=r(l,"HR",{}),eD=u(l),Ai=r(l,"P",{});var pb=a(Ai);F3=s(pb,"Spark는 language-integrated API를 통해 RDD abstraction을 제공함"),pb.forEach(e),tD=u(l),Mi=r(l,"UL",{});var fb=a(Mi);Fp=r(fb,"LI",{});var sb=a(Fp);G3=s(sb,"함수형 + 정적 타이핑 언어인 Scala를 선택하였는데, 간결하기 때문에 interactive하게 사용하기 용이함"),sb.forEach(e),fb.forEach(e),iD=u(l),xi=r(l,"P",{});var nb=a(xi);z3=s(nb,"Spark를 쓰는 개발자는 driver program을 작성해야 하는데, 얘가 클러스터의 worker들에 접속함."),nb.forEach(e),rD=u(l),V=r(l,"UL",{});var Ca=a(V);Gp=r(Ca,"LI",{});var ub=a(Gp);O3=s(ub,"Driver는 한 개 이상의 RDD를 정의하고, action을 호출함."),ub.forEach(e),T3=u(Ca),zp=r(Ca,"LI",{});var Db=a(zp);q3=s(Db,"Driver는 RDD Lineage를 추적함"),Db.forEach(e),J3=u(Ca),Op=r(Ca,"LI",{});var vb=a(Op);Q3=s(vb,"worker는 여러 연산을 통해 RDD Partition을 RAM에 저장할 수 있는 long-lived process임"),vb.forEach(e),Ca.forEach(e),aD=u(l),Hi=r(l,"P",{});var cb=a(Hi);K3=s(cb,"map과 같은 RDD Operation에는 closure(function literal)를 넘겨줘야 함"),cb.forEach(e),oD=u(l),Vl=r(l,"UL",{});var Bc=a(Vl);Tp=r(Bc,"LI",{});var _b=a(Tp);$3=s(_b,"이때 closure는 Java object로 표현되며, Serialize하여 네트워크를 통해 closure를 전송할 수 있음"),_b.forEach(e),W3=u(Bc),qp=r(Bc,"LI",{});var mb=a(qp);V3=s(mb,"또한, 이 closure에 묶여 있는 변수는 Object의 field값으로 설정됨"),mb.forEach(e),Bc.forEach(e),pD=u(l),Ui=r(l,"P",{});var Eb=a(Ui);Z3=s(Eb,"RDD 자체는 원소의 타입을 파라미터로 넘길 수 있는 statically typed objected이다."),Eb.forEach(e),fD=u(l),Zl=r(l,"UL",{});var jc=a(Zl);Jp=r(jc,"LI",{});var db=a(Jp);X3=s(db,"RDD[Int]는 Int의 RDD이다."),db.forEach(e),Y3=u(jc),Qp=r(jc,"LI",{});var Rb=a(Qp);g3=s(Rb,"Scala는 Type Interface를 지원하니, 타입을 생략해도 된다."),Rb.forEach(e),jc.forEach(e),sD=u(l),Xl=r(l,"H3",{id:!0});var q0=a(Xl);Yl=r(q0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Lb=a(Yl);Kp=r(Lb,"SPAN",{class:!0}),a(Kp).forEach(e),Lb.forEach(e),ld=s(q0,"RDD Operations in Spark"),q0.forEach(e),nD=u(l),gl=r(l,"P",{});var Nc=a(gl);wi=r(Nc,"IMG",{src:!0,alt:!0}),ed=r(Nc,"BR",{}),td=s(Nc,`
위 표는 Spark에서 사용 가능한 Transformation과 Action의 목록임.`),Nc.forEach(e),uD=u(l),le=r(l,"UL",{});var Fc=a(le);$p=r(Fc,"LI",{});var Ib=a($p);id=s(Ib,"대괄호 안에 타입 파라미터를 표시하여, 각 연산의 특징을 제시하였음."),Ib.forEach(e),rd=u(Fc),Wp=r(Fc,"LI",{});var bb=a(Wp);ad=s(bb,"transformation은 lazy operation인 반면, action은 프로그램에 값을 반환하거나 외부 스토리지에 값을 write하기 위해 연산을 시작함."),bb.forEach(e),Fc.forEach(e),DD=u(l),Ci=r(l,"P",{});var kb=a(Ci);od=s(kb,`join 등의 연산은 key-value pair 형태의 RDD에서만 가능함.
또한 함수 이름은 스칼라나 다른 함수형 언어의 API와 매칭이 가능하게끔 선정하였음`),kb.forEach(e),vD=u(l),Bi=r(l,"UL",{});var yb=a(Bi);Vp=r(yb,"LI",{});var Sb=a(Vp);pd=s(Sb,"map : 1-1 mapping / flatMap : MapReduce의 map과 유사함. 각 input value를 한 개 이상의 output과 mapping"),Sb.forEach(e),yb.forEach(e),cD=u(l),ji=r(l,"P",{});var Pb=a(ji);fd=s(Pb,`사용자는 RDD가 지속되게끔 요청할 수 있음. (persist)
RDD의 partition order를 얻을 수도 있음.`),Pb.forEach(e),_D=u(l),Ni=r(l,"UL",{});var hb=a(Ni);Zp=r(hb,"LI",{});var Ab=a(Zp);sd=s(Ab,`Partitioner Class가 partition order를 나타냄. 이걸 가지고 다른 dataset을 partition할 수도 있음.
groupByKey, reduceByKey, sort 등의 연산은 자동으로 hash partition 또는 range partition된 RDD를 생성한다.`),Ab.forEach(e),hb.forEach(e),mD=u(l),ee=r(l,"H3",{id:!0});var J0=a(ee);te=r(J0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Mb=a(te);Xp=r(Mb,"SPAN",{class:!0}),a(Xp).forEach(e),Mb.forEach(e),nd=s(J0,"Example: Logistic Regression"),J0.forEach(e),ED=u(l),Fi=r(l,"P",{});var xb=a(Fi);ud=s(xb,"기계 학습 알고리즘의 경우, iterative한 경우가 많다."),xb.forEach(e),dD=u(l),ie=r(l,"UL",{});var Gc=a(ie);Yp=r(Gc,"LI",{});var Hb=a(Yp);Dd=s(Hb,"gradient descent 등 반복 최적화 절차를 수행하기 때문"),Hb.forEach(e),vd=u(Gc),gp=r(Gc,"LI",{});var Ub=a(gp);cd=s(Ub,"따라서 데이터를 메모리에 저장한다면 험청 빨라질 것임"),Ub.forEach(e),Gc.forEach(e),RD=u(l),re=r(l,"P",{});var zc=a(re);Gi=r(zc,"IMG",{src:!0,alt:!0}),_d=u(zc),zi=r(zc,"IMG",{src:!0,alt:!0}),zc.forEach(e),LD=u(l),Oi=r(l,"P",{});var wb=a(Oi);md=s(wb,"위 코드는 logistic regression 예제인데, 제가 머신러닝 이런거 안해봐서 뭔지 잘 모름 ㅈㅅ; 흐름만 봄"),wb.forEach(e),ID=u(l),x=r(l,"UL",{});var Rt=a(x);lf=r(Rt,"LI",{});var Cb=a(lf);Ed=s(Cb,"text file에서 map"),Cb.forEach(e),dd=u(Rt),Ti=r(Rt,"LI",{});var Q0=a(Ti);Rd=s(Q0,"parsePoint 함수 넘겨서 텍스트 파일의 각 라인으로부터 좌표상의 위치 얻음 => "),ef=r(Q0,"EM",{});var Bb=a(ef);Ld=s(Bb,"points"),Bb.forEach(e),Q0.forEach(e),Id=u(Rt),Ft=r(Rt,"LI",{});var Oc=a(Ft);bd=s(Oc,"반복적으로 "),tf=r(Oc,"EM",{});var jb=a(tf);kd=s(jb,"points"),jb.forEach(e),yd=s(Oc,"에서 map 및 reduce하여 결과(w 벡터)를 얻을 수 있음"),Oc.forEach(e),Sd=u(Rt),rf=r(Rt,"LI",{});var Nb=a(rf);Pd=s(Nb,"메모리에 올려놓고 반복하기 때문에 20배까지 속도가 빨라짐"),Nb.forEach(e),Rt.forEach(e),bD=u(l),ae=r(l,"H3",{id:!0});var K0=a(ae);oe=r(K0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Fb=a(oe);af=r(Fb,"SPAN",{class:!0}),a(af).forEach(e),Fb.forEach(e),hd=s(K0,"Example: PageRank"),K0.forEach(e),kD=u(l),qi=r(l,"UL",{});var Gb=a(qi);of=r(Gb,"LI",{});var zb=a(of);Ad=s(zb,"RDD의 partitioning을 사용하여, 성능을 향상시킬 수 있는 것을 보여줌"),zb.forEach(e),Gb.forEach(e),yD=u(l),Ji=r(l,"P",{});var Ob=a(Ji);Md=s(Ob,`더 복잡한 data sharing pattern임.
PageRank 알고리즘은 다른 문서에서 각 문서로 link되는 회수를 합산하여, 문서의 rank를 반복적으로 업데이트한다.`),Ob.forEach(e),SD=u(l),pe=r(l,"UL",{});var Tc=a(pe);pf=r(Tc,"LI",{});var Tb=a(pf);xd=s(Tb,"각 iteration마다 각 문서는 r/n의 기여도를 이웃들에게 보낸다. (r : rank, n : 이웃의 수)"),Tb.forEach(e),Hd=u(Tc),ff=r(Tc,"LI",{});var qb=a(ff);Ud=s(qb,"그 후 순위를 α/N + (1 − α)∑ci 로 계산 (∑ci : 받은 기여도의 총합, N : 총 문서 수)"),qb.forEach(e),Tc.forEach(e),PD=u(l),y=r(l,"P",{});var kl=a(y);wd=s(kl,"PageRank를 Spark로 나타내면 다음과 같음"),Cd=r(kl,"BR",{}),Bd=u(kl),Qi=r(kl,"IMG",{src:!0,alt:!0}),jd=u(kl),Ki=r(kl,"IMG",{src:!0,alt:!0}),Nd=r(kl,"BR",{}),Fd=s(kl,`
좌측의 프로그램을 돌리면 우측의 그림과 같은 RDD Lineage 그래프를 얻을 수 있음`),kl.forEach(e),hD=u(l),_=r(l,"UL",{});var k=a(_);S=r(k,"LI",{});var fl=a(S);Gd=s(fl,"각 iteration마다, 이전 iteration의 "),sf=r(fl,"EM",{});var Jb=a(sf);zd=s(Jb,"contribs"),Jb.forEach(e),Od=s(fl,"와 "),nf=r(fl,"EM",{});var Qb=a(nf);Td=s(Qb,"ranks"),Qb.forEach(e),qd=s(fl,", 그리고 정적인 "),uf=r(fl,"EM",{});var Kb=a(uf);Jd=s(Kb,"links"),Kb.forEach(e),Qd=s(fl,"라는 dataset으로부터, 새로운 "),Df=r(fl,"EM",{});var $b=a(Df);Kd=s($b,"ranks"),$b.forEach(e),$d=s(fl,"라는 dataset을 만듦."),fl.forEach(e),Wd=u(k),vf=r(k,"LI",{});var Wb=a(vf);Vd=s(Wb,"이 그래프의 흥미로운 특징은, 반복의 회수만큼 graph가 늘어난다는 것이다."),Wb.forEach(e),Zd=u(k),cf=r(k,"LI",{});var Vb=a(cf);Xd=s(Vb,"이 작업은 많은 iteration이 동반되므로, fault recovery를 효율적으로 하려면 특정 버전의 ranks를 replication을 만들어서 저장해야 할 수도 있음"),Vb.forEach(e),Yd=u(k),_f=r(k,"LI",{});var Zb=a(_f);gd=s(Zb,"사용자는 RELIABLE 플래그를 줘서 persist 메소드를 호출하면 그렇게 할 수 있음"),Zb.forEach(e),l4=u(k),mf=r(k,"LI",{});var Xb=a(mf);e4=s(Xb,"하지만 links라는 dataset은 replication을 만들 필요가 없음. 그냥 input file에서 map 다시 돌리면 해당 partition을 다시 얻는 게 더 효율적이기 때문"),Xb.forEach(e),t4=u(k),Ef=r(k,"LI",{});var Yb=a(Ef);i4=s(Yb,"이 dataset은 보통 ranks보다 훨씬 크기가 큼. 각 문서에는 많은 링크가 있지만 순위는 한 개뿐이기 때문"),Yb.forEach(e),r4=u(k),df=r(k,"LI",{});var gb=a(df);a4=s(gb,"따라서 lineage를 사용하여 복구하는 게, 프로그램의 전체 in-memory state의 checkpoint를 만드는 것보다 시간을 절약할 수 있음"),gb.forEach(e),k.forEach(e),AD=u(l),$i=r(l,"P",{});var lk=a($i);o4=s(lk,"RDD의 partitioning을 제어함으로써, PageRank 알고리즘에서의 통신을 최적화할 수 있음"),lk.forEach(e),MD=u(l),L=r(l,"UL",{});var sl=a(L);Rf=r(sl,"LI",{});var ek=a(Rf);p4=s(ek,"만약 links를 기준으로 partitioning하게끔 명시한다면, ranks에 대해서도 동일한 방식으로 partitioning할 수 있음"),ek.forEach(e),f4=u(sl),Lf=r(sl,"LI",{});var tk=a(Lf);s4=s(tk,"그렇게 되면 links와 ranks간의 join 연산이 통신을 필요로 하지 않게 됨(같은 머신 위에 필요한 데이터가 있음)"),tk.forEach(e),n4=u(sl),If=r(sl,"LI",{});var ik=a(If);u4=s(ik,"Partitioner class를 작성하여, 도메인 이름에 따라 페이지를 묶을 수도 있음."),ik.forEach(e),D4=u(sl),fe=r(sl,"LI",{});var ju=a(fe);v4=s(ju,"아래와 같이, links를 정의할 때 PartitionBy()라는 method를 통해 진행"),c4=r(ju,"BR",{}),_4=u(ju),Wi=r(ju,"IMG",{src:!0,alt:!0}),ju.forEach(e),m4=u(sl),bf=r(sl,"LI",{});var rk=a(bf);E4=s(rk,"RDD는 사용자가 이러한 목표(일관된 partitioning을 통한 최적화)를 직접 표현할 수 있게 함."),rk.forEach(e),sl.forEach(e),xD=u(l),HD=r(l,"BR",{}),UD=r(l,"BR",{}),wD=u(l),se=r(l,"H2",{id:!0});var $0=a(se);ne=r($0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ak=a(ne);kf=r(ak,"SPAN",{class:!0}),a(kf).forEach(e),ak.forEach(e),d4=s($0,"Representing RDDs"),$0.forEach(e),CD=u(l),BD=r(l,"HR",{}),jD=u(l),Vi=r(l,"P",{});var ok=a(Vi);R4=s(ok,"RDD를 Abstraction으로 제공하기 위한 과제 중 하나는, 광범위한 transformation에서 lineage를 추적할 수 있는 표현을 선택하는 것임"),ok.forEach(e),ND=u(l),H=r(l,"UL",{});var Lt=a(H);yf=r(Lt,"LI",{});var pk=a(yf);L4=s(pk,"RDD를 구현하는 시스템은 반드시 다양한 transformation 연산자들을 제공해야 하며, 사용자가 임의의 방식으로 transformation을 선택할 수 있게 해야 함."),pk.forEach(e),I4=u(Lt),Sf=r(Lt,"LI",{});var fk=a(Sf);b4=s(fk,"이 논문에서는 graph-based의 표현을 제안함"),fk.forEach(e),k4=u(Lt),Pf=r(Lt,"LI",{});var sk=a(Pf);y4=s(sk,"Spark에서는 이 표현을 사용함으로써, 각각의 스케줄러에 특별한 논리를 추가하지 않고 광범위한 transformation을 지원함"),sk.forEach(e),S4=u(Lt),hf=r(Lt,"LI",{});var nk=a(hf);P4=s(nk,"시스템 설계가 매우 단순화됨"),nk.forEach(e),Lt.forEach(e),FD=u(l),Zi=r(l,"P",{});var uk=a(Zi);h4=s(uk,"각각의 RDD는 아래와 같은 정보를 노출하는 공통적인 인터페이스로 나타낼 수 있음"),uk.forEach(e),GD=u(l),U=r(l,"OL",{});var It=a(U);Af=r(It,"LI",{});var Dk=a(Af);A4=s(Dk,"partition의 집합 (dataset의 atomic pieces)"),Dk.forEach(e),M4=u(It),Mf=r(It,"LI",{});var vk=a(Mf);x4=s(vk,"Parent RDD에 대한 종속성(dependency) 집합"),vk.forEach(e),H4=u(It),xf=r(It,"LI",{});var ck=a(xf);U4=s(ck,"Parent RDD를 기반으로 dataset을 계산하는 함수"),ck.forEach(e),w4=u(It),Xi=r(It,"LI",{});var W0=a(Xi);C4=s(W0,"partitioning scheme 및 데이터 배치에 대한 메타데이터"),Rl=r(W0,"UL",{});var Ba=a(Rl);ue=r(Ba,"LI",{});var Nu=a(ue);B4=s(Nu,"해당 인터페이스는 아래와 같은 테이블에서 보여줌"),j4=r(Nu,"BR",{}),N4=u(Nu),Yi=r(Nu,"IMG",{src:!0,alt:!0}),Nu.forEach(e),F4=u(Ba),Hf=r(Ba,"LI",{});var _k=a(Hf);G4=s(_k,"예를 들면, HDFS 파일을 표현하는 RDD는 파일의 각 블록마다 partition을 가지고 있고 어떤 machine의 블록에 올라가 있는지 정보를 알고 있음"),_k.forEach(e),z4=u(Ba),Uf=r(Ba,"LI",{});var mk=a(Uf);O4=s(mk,"한편 이 RDD에 map을 한 결과물은 동일한 partition을 가지지만, 요소를 계산할 때 parent data에 map 함수를 적용한다."),mk.forEach(e),Ba.forEach(e),W0.forEach(e),It.forEach(e),zD=u(l),Gt=r(l,"P",{});var V0=a(Gt);gi=r(V0,"IMG",{src:!0,alt:!0}),T4=s(V0,`
RDD간의 종속성(Dependency)를 나타내는 인터페이스는 두 종류가 있음`),V0.forEach(e),OD=u(l),Z=r(l,"UL",{});var ja=a(Z);wf=r(ja,"LI",{});var Ek=a(wf);q4=s(Ek,"narrow dependency: 1개의 Parent RDD에 1개의 Child RDD가 종속"),Ek.forEach(e),J4=u(ja),Cf=r(ja,"LI",{});var dk=a(Cf);Q4=s(dk,"wide dependency : 1개의 Parent RDD에 여러 개의 Child RDD가 종속될 수 있음"),dk.forEach(e),K4=u(ja),Bf=r(ja,"LI",{});var Rk=a(Bf);$4=s(Rk,"예를 들어 map은 narrow dependency이고, join은 (parent가 hash-partitioned 되어있는 게 아니라면) wide dependency임."),Rk.forEach(e),ja.forEach(e),TD=u(l),lr=r(l,"P",{});var Lk=a(lr);W4=s(Lk,"이렇게 narrow와 wide로 구분하는 게 유용한 이유가 두 가지 있음."),Lk.forEach(e),qD=u(l),De=r(l,"OL",{});var qc=a(De);jf=r(qc,"LI",{});var Ik=a(jf);Nf=r(Ik,"P",{});var bk=a(Nf);V4=s(bk,`narrow dependency는 모든 parent partition을 계산할 수 있는 하나의 cluster node에서 pipelined execution이 가능함.
=> 예를 들면 각 요소마다 filter 이후 map을 적용할 수 있음
=> 반면 wide dependency에서는, MapReduce처럼 Parent Patrtition의 모든 데이터가 Child들에 Shuffle되어야 한다.`),bk.forEach(e),Ik.forEach(e),Z4=u(qc),Ff=r(qc,"LI",{});var kk=a(Ff);Gf=r(kk,"P",{});var yk=a(Gf);X4=s(yk,`node failure 이후 회복할 때는 narrow dependency에서 더 효율적임
=> 손실이 발생한 parent partition만 회복하면 되기 때문이며, 이는 다른 노드에서 병렬적으로 재연산이 가능
=> 반면 wide dependency의 lineage graph에서는, 특정 단일 노드에서 failure가 발생하면 해당 RDD의 조상으로부터 형성된 특정 파티션을 잃어버릴 수도 있으며, 이 경우 완전히 재실행해야 할 수도 있음.`),yk.forEach(e),kk.forEach(e),qc.forEach(e),JD=u(l),er=r(l,"P",{});var Sk=a(er);Y4=s(Sk,`Spark에서, 이러한 RDD의 공통적인 인터페이스는 대부분의 transformation을 20줄 이내로 수행할 수 있게 하였음.
아래 내용은 여러 RDD 구현이 요약된 것임`),Sk.forEach(e),QD=u(l),tr=r(l,"P",{});var Pk=a(tr);g4=s(Pk,"HDFS Files"),Pk.forEach(e),KD=u(l),w=r(l,"UL",{});var bt=a(w);zf=r(bt,"LI",{});var hk=a(zf);l5=s(hk,"RDD가 HDFS의 파일인 경우, partitions()는 파일의 각 블록당 한 개의 partition이 반환된다."),hk.forEach(e),e5=u(bt),Of=r(bt,"LI",{});var Ak=a(Of);t5=s(Ak,"각 Partition 객체에 block offset이 포함되어 있다"),Ak.forEach(e),i5=u(bt),Tf=r(bt,"LI",{});var Mk=a(Tf);r5=s(Mk,"prefferedLocation()은 블록이 존재하는 노드를 반환한다."),Mk.forEach(e),a5=u(bt),qf=r(bt,"LI",{});var xk=a(qf);o5=s(xk,"iterator()는 블록을 읽는다."),xk.forEach(e),bt.forEach(e),$D=u(l),ir=r(l,"P",{});var Hk=a(ir);p5=s(Hk,"map"),Hk.forEach(e),WD=u(l),ve=r(l,"UL",{});var Jc=a(ve);Jf=r(Jc,"LI",{});var Uk=a(Jf);f5=s(Uk,"임의의 RDD에서 map을 호출하면 MappedRDD 객체가 반환된다"),Uk.forEach(e),s5=u(Jc),Qf=r(Jc,"LI",{});var wk=a(Qf);n5=s(wk,"이 객체는 parent와 동일한 partition 및 preferred location을 가지지만, Iterator()는 parent의 record와 매핑하기 위해 전달된 함수를 적용한다."),wk.forEach(e),Jc.forEach(e),VD=u(l),rr=r(l,"P",{});var Ck=a(rr);u5=s(Ck,"union"),Ck.forEach(e),ZD=u(l),ce=r(l,"UL",{});var Qc=a(ce);Kf=r(Qc,"LI",{});var Bk=a(Kf);D5=s(Bk,"두 개의 RDD에서 union을 호출하면, 각 부모의 partition이 합쳐진 partition을 가진 RDD가 반환됨"),Bk.forEach(e),v5=u(Qc),$f=r(Qc,"LI",{});var jk=a($f);c5=s(jk,"각각의 Child Partition은 parent에 대한 narrow dependency를 통해 계산됨"),jk.forEach(e),Qc.forEach(e),XD=u(l),ar=r(l,"P",{});var Nk=a(ar);_5=s(Nk,"sample"),Nk.forEach(e),YD=u(l),or=r(l,"UL",{});var Fk=a(or);Wf=r(Fk,"LI",{});var Gk=a(Wf);m5=s(Gk,"sample은 map과 비슷하지만, RDD가 parent record를 deterministically하게 샘플링하기 위해 각 partition마다 random number seed를 저장한다는 차이가 있음"),Gk.forEach(e),Fk.forEach(e),gD=u(l),pr=r(l,"P",{});var zk=a(pr);E5=s(zk,"join"),zk.forEach(e),l2=u(l),I=r(l,"UL",{});var nl=a(I);Vf=r(nl,"LI",{});var Ok=a(Vf);d5=s(Ok,"두 RDD를 join하는 연산은 세 가지 경우가 있음."),Ok.forEach(e),R5=u(nl),Zf=r(nl,"LI",{});var Tk=a(Zf);L5=s(Tk,"두 RDD가 동일 partition에 hash/range partition된 경우(partitioner가 같은 경우), 둘 다 narrow dependency"),Tk.forEach(e),I5=u(nl),Xf=r(nl,"LI",{});var qk=a(Xf);b5=s(qk,"둘 중 하나만 hash/range partition된 경우(partitioner를 가짐), narrow와 wide 혼합"),qk.forEach(e),k5=u(nl),Yf=r(nl,"LI",{});var Jk=a(Yf);y5=s(Jk,"아니면, 둘 다 wide dependency임"),Jk.forEach(e),S5=u(nl),gf=r(nl,"LI",{});var Qk=a(gf);P5=s(Qk,"어떤 경우이든 결과물인 RDD는 partitioner를 가지며, parent로부터 물려받거나 default hash partitioner를 가짐"),Qk.forEach(e),nl.forEach(e),e2=u(l),t2=r(l,"BR",{}),i2=r(l,"BR",{}),r2=u(l),_e=r(l,"H2",{id:!0});var Z0=a(_e);me=r(Z0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Kk=a(me);ls=r(Kk,"SPAN",{class:!0}),a(ls).forEach(e),Kk.forEach(e),h5=s(Z0,"Implementation"),Z0.forEach(e),a2=u(l),o2=r(l,"HR",{}),p2=u(l),fr=r(l,"P",{});var $k=a(fr);A5=s($k,"Spark 시스템은 Mesos cluster manager 위에서 동작하며, Hadoop, MPI(Message Passing Interface) 등 다른 어플리케이션과 리소스를 공유할 수 있다."),$k.forEach(e),f2=u(l),Ee=r(l,"UL",{});var Kc=a(Ee);es=r(Kc,"LI",{});var Wk=a(es);M5=s(Wk,"각각의 Spark 프로그램은 driver(master)와 worker를 가진 별도의 Mesos Application으로 동작한다."),Wk.forEach(e),x5=u(Kc),ts=r(Kc,"LI",{});var Vk=a(ts);H5=s(Vk,"애플리케이션 간의 자원 관리는 Mesos에 의해 처리된다."),Vk.forEach(e),Kc.forEach(e),s2=u(l),sr=r(l,"P",{});var Zk=a(sr);U5=s(Zk,"Spark는 HDFS, HBase 등 Hadoop의 입력 소스를 통해 데이터를 읽어올 수 있다."),Zk.forEach(e),n2=u(l),de=r(l,"UL",{});var $c=a(de);is=r($c,"LI",{});var Xk=a(is);w5=s(Xk,"기존의 Hadoop에서 사용하는 input plugin API를 사용한다."),Xk.forEach(e),C5=u($c),rs=r($c,"LI",{});var Yk=a(rs);B5=s(Yk,"특별히 수정된 Scala 버전을 사용하지 않아도 된다."),Yk.forEach(e),$c.forEach(e),u2=u(l),Re=r(l,"H3",{id:!0});var X0=a(Re);Le=r(X0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var gk=a(Le);as=r(gk,"SPAN",{class:!0}),a(as).forEach(e),gk.forEach(e),j5=s(X0,"Job Scheduling"),X0.forEach(e),D2=u(l),X=r(l,"P",{});var Na=a(X);nr=r(Na,"IMG",{src:!0,alt:!0}),N5=r(Na,"BR",{}),F5=s(Na,`
그림에서 검정색은 이미 메모리에 올라가 있는 부분임.`),G5=r(Na,"BR",{}),z5=s(Na,`
stage 1의 결과물이 이미 RAM에 올라가 있으므로, stage 3의 RDD를 얻기 위해서는 stage 2, 3만 하면 됨`),Na.forEach(e),v2=u(l),ur=r(l,"P",{});var ly=a(ur);O5=s(ly,"Spark scheduler는 4장에서 다루었던 RDD 표현을 사용한다. Spark의 scheduler는 Dryad의 scheduler와 비슷하지만, persistent RDD의 어떤 partition을 메모리에 올릴지도 고려한다."),ly.forEach(e),c2=u(l),b=r(l,"UL",{});var ul=a(b);os=r(ul,"LI",{});var ey=a(os);T5=s(ey,"위 그림처럼, 유저가 RDD에 대한 action을 수행할 때마다 scheduler는 실행할 stage의 DAG를 만들기 위해 RDD의 lineage graph를 검사한다."),ey.forEach(e),q5=u(ul),ps=r(ul,"LI",{});var ty=a(ps);J5=s(ty,"DAG : Directed Acyclic Graph. Cycle이 없는 Directed Graph"),ty.forEach(e),Q5=u(ul),fs=r(ul,"LI",{});var iy=a(fs);K5=s(iy,"각 stage는 narrow dependency로 구성할 수 있는, 여러 transform의 파이프라인으로 구성되어 있음"),iy.forEach(e),$5=u(ul),ss=r(ul,"LI",{});var ry=a(ss);W5=s(ry,"각 stage를 구분하는 것은 wide dependency에 필요한 shuffle 연산 또는 parent RDD의 계산을 단순화할 수 있는 이미 계산된 partition이다."),ry.forEach(e),V5=u(ul),ns=r(ul,"LI",{});var ay=a(ns);Z5=s(ay,"Scheduler는 대상 RDD가 계산될 때까지, 각 stage의 missing partition을 연산하는 작업을 생성한다."),ay.forEach(e),ul.forEach(e),_2=u(l),Dr=r(l,"P",{});var oy=a(Dr);X5=s(oy,"Spark의 scheduler는 delay scheduling을 사용하여, data locality에 따라 machine에 작업 할당"),oy.forEach(e),m2=u(l),Y=r(l,"UL",{});var Fa=a(Y);us=r(Fa,"LI",{});var py=a(us);Y5=s(py,"만약 task가 어느 노드의 메모리에서 사용 가능한 partition을 처리해야 할 경우, 해당 노드로 보낸다."),py.forEach(e),g5=u(Fa),Ds=r(Fa,"LI",{});var fy=a(Ds);lR=s(fy,`또는 task가 HDFS처럼 preferred location이 존재하는 RDD의 partition을 처리하는 경우, 해당 파티션으로 보냄
Wide Dependency(shuffle)의 경우, 오류 복구를 단순화하기 위해 parent partition을 보유한 노드에 있는 intermediate record를 materialize함.`),fy.forEach(e),eR=u(Fa),vs=r(Fa,"LI",{});var sy=a(vs);tR=s(sy,"MapReduce가 map output을 materialize하는 것과 유사"),sy.forEach(e),Fa.forEach(e),E2=u(l),Ie=r(l,"OL",{});var Wc=a(Ie);cs=r(Wc,"LI",{});var ny=a(cs);iR=s(ny,"만약 task가 failure하면, 해당 stage의 parent가 살아있는 한 다른 node에서 작업을 다시 실행함."),ny.forEach(e),rR=u(Wc),vr=r(Wc,"LI",{});var Y0=a(vr);aR=s(Y0,"만약 특정 stage 자체를 사용할 수 없는 경우(예를 들면 shuffle 중 map side의 출력값이 손실된 경우), 병렬적으로 missing partition을 계산하기 위해 task를 다시 전송한다."),_s=r(Y0,"UL",{});var uy=a(_s);ms=r(uy,"LI",{});var Dy=a(ms);oR=s(Dy,"RDD linage graph를 replicating하는 것은 간단하지만, scheduler 실패는 아직 핸들링하기 어려움"),Dy.forEach(e),uy.forEach(e),Y0.forEach(e),Wc.forEach(e),d2=u(l),cr=r(l,"P",{});var vy=a(cr);pR=s(vy,"Spark의 모든 연산은 driver 프로그램에서 action이 호출되면 그에 따라 실행됨"),vy.forEach(e),R2=u(l),be=r(l,"UL",{});var Vc=a(be);Es=r(Vc,"LI",{});var cy=a(Es);fR=s(cy,"하지만 map과 같은 cluster의 작업이 조회 작업을 호출하도록 하여, hash-partition된 RDD의 요소에 key값을 통해 random access할 수 있게 하는 실험도 하고 있음"),cy.forEach(e),sR=u(Vc),ds=r(Vc,"LI",{});var _y=a(ds);nR=s(_y,"이 경우, task는 scheduler에게 필요한 partition이 missing 상태일 경우 이를 계산하게끔 지시해야 함."),_y.forEach(e),Vc.forEach(e),L2=u(l),ke=r(l,"H3",{id:!0});var g0=a(ke);ye=r(g0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var my=a(ye);Rs=r(my,"SPAN",{class:!0}),a(Rs).forEach(e),my.forEach(e),uR=s(g0,"Interpreter Integration"),g0.forEach(e),I2=u(l),_r=r(l,"P",{});var Ey=a(_r);DR=s(Ey,"Scala는 Python이나 Ruby처럼 interactive shell을 제공함"),Ey.forEach(e),b2=u(l),mr=r(l,"UL",{});var dy=a(mr);Ls=r(dy,"LI",{});var Ry=a(Ls);vR=s(Ry,"데이터를 in-memory로 처리하여 latency가 낮기 때문에, 사용자는 Spark Interpreter를 통해 interactive하게 많은 양의 데이터에 query를 날릴 수 있음"),Ry.forEach(e),dy.forEach(e),k2=u(l),Er=r(l,"P",{});var Ly=a(Er);cR=s(Ly,"Scala interpreter는 사용가 입력한 클래스가 있는 라인을 컴파일하여 JVM에 로드하고, 그 위에서 함수를 호출함."),Ly.forEach(e),y2=u(l),C=r(l,"UL",{});var kt=a(C);Is=r(kt,"LI",{});var Iy=a(Is);_R=s(Iy,"이러한 클래스는 그 라인에서 선언된 변수나 함수를 포함하며, initialize method로 그 라인을 실행하는 singleton object를 포함함."),Iy.forEach(e),mR=u(kt),bs=r(kt,"LI",{});var by=a(bs);ER=s(by,"singleton object : class의 instance가 오직 1개만 생성됨"),by.forEach(e),dR=u(kt),ks=r(kt,"LI",{});var ky=a(ks);RR=s(ky,"예를 들면, 만약 유저가 var x = 5를 입력하고 그 다음 println(x)를 입력했다고 가정"),ky.forEach(e),LR=u(kt),ys=r(kt,"LI",{});var yy=a(ys);IR=s(yy,"인터프리터는 x를 포함하는 Line1이라는 클래스를 만들고, println(Line1.getInstance().x)로 컴파일"),yy.forEach(e),kt.forEach(e),S2=u(l),dr=r(l,"P",{});var Sy=a(dr);bR=s(Sy,"Spark interpreter에서는 두 가지의 변화를 줬음"),Sy.forEach(e),P2=u(l),Se=r(l,"OL",{});var Zc=a(Se);Ss=r(Zc,"LI",{});var Py=a(Ss);kR=s(Py,"Class Shipping: worker 노드가 각 라인에 선언된 클래스의 바이트 코드를 읽어올 수 있게끔, interpreter는 이런 클래스를 HTTP로 전송함."),Py.forEach(e),yR=u(Zc),Rr=r(Zc,"LI",{});var lI=a(Rr);SR=s(lI,"수정된 코드 생성: 일반적으로 코드의 각 라인마다 생성된 Singleton Object는 해당 클래스의 static method를 통해 접근함."),zt=r(lI,"UL",{});var Xc=a(zt);Ps=r(Xc,"LI",{});var hy=a(Ps);PR=s(hy,"위 예제(Line1.getInstance().x)처럼 이전 라인에서 정의된 변수를 참조하는 closure를 serialize할 때, Java는 object graph를 추적하여 x를 감싸는 Line1 인스턴스를 전달하지 않음. 따라서 worker 노드는 x를 받지 않을 것임."),hy.forEach(e),hR=u(Xc),hs=r(Xc,"LI",{});var Ay=a(hs);AR=s(Ay,"code generation logic을 수정하여, 참조를 하려고 할 시 각 라인의 object의 instance를 직접 참조하게끔 변경하였음"),Ay.forEach(e),Xc.forEach(e),lI.forEach(e),Zc.forEach(e),h2=u(l),Pe=r(l,"P",{});var Yc=a(Pe);Lr=r(Yc,"IMG",{src:!0,alt:!0}),MR=r(Yc,"BR",{}),xR=s(Yc,`
위 그림은 사용자가 입력한 라인을 interpreter가 어떻게 해석하는지 보여줌`),Yc.forEach(e),A2=u(l),Ir=r(l,"P",{});var My=a(Ir);HR=s(My,"Spark interpreter를 쓰면 HDFS에 저장된 dataset을 탐색하거나, trace를 추적(아마 lineage graph?)하는데 유용하다는 것을 발견하였음."),My.forEach(e),M2=u(l),he=r(l,"H3",{id:!0});var eI=a(he);Ae=r(eI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var xy=a(Ae);As=r(xy,"SPAN",{class:!0}),a(As).forEach(e),xy.forEach(e),UR=s(eI,"Memory Management"),eI.forEach(e),x2=u(l),br=r(l,"P",{});var Hy=a(br);wR=s(Hy,"Spark는 persistent RDD를 저장하기 위한 세 가지 옵션을 제공한다."),Hy.forEach(e),H2=u(l),g=r(l,"OL",{});var Ga=a(g);kr=r(Ga,"LI",{});var tI=a(kr);CR=s(tI,"in-memory storage - deserialized Java object"),Ms=r(tI,"UL",{});var Uy=a(Ms);xs=r(Uy,"LI",{});var wy=a(xs);BR=s(wy,"JVM이 RDD 요소를 native하게 접근할 수 있기 때문에 가장 빠름"),wy.forEach(e),Uy.forEach(e),tI.forEach(e),jR=u(Ga),yr=r(Ga,"LI",{});var iI=a(yr);NR=s(iI,"in-memory storage – serialized data"),Hs=r(iI,"UL",{});var Cy=a(Hs);Us=r(Cy,"LI",{});var By=a(Us);FR=s(By,"Java의 object graph보다 메모리 측면에서는 효율적이지만, 성능은 감소"),By.forEach(e),Cy.forEach(e),iI.forEach(e),GR=u(Ga),Sr=r(Ga,"LI",{});var rI=a(Sr);zR=s(rI,"on-disk storage"),ws=r(rI,"UL",{});var jy=a(ws);Cs=r(jy,"LI",{});var Ny=a(Cs);OR=s(Ny,"RDD가 너무 커서 RAM에 저장하기엔 너무 크지만 사용할 때마다 재계산하기에는 비용이 너무 많이 드는 RDD에 유용함"),Ny.forEach(e),jy.forEach(e),rI.forEach(e),Ga.forEach(e),U2=u(l),Pr=r(l,"P",{});var Fy=a(Pr);TR=s(Fy,"사용 가능한 메모리는 제한적이므로, RDD 레벨에서 LRU 제거 정책을 사용함."),Fy.forEach(e),w2=u(l),B=r(l,"UL",{});var yt=a(B);Bs=r(yt,"LI",{});var Gy=a(Bs);qR=s(Gy,"새로운 RDD Partition이 계산될 때 이를 저장할 공간이 충분치 않다면, 가장 예전에 access된 RDD를 쫓아냄."),Gy.forEach(e),JR=u(yt),js=r(yt,"LI",{});var zy=a(js);QR=s(zy,"예외적으로, 새로운 partition이 있는 RDD와 동일한 RDD는 쫓아내지 않는데, cycling partition이 일어나지 않게끔 하기 위함"),zy.forEach(e),KR=u(yt),Ns=r(yt,"LI",{});var Oy=a(Ns);$R=s(Oy,"대부분의 작업은 RDD 전체에서 수행되기 때문에, 이는 굉장히 중요함. 이미 메모리에 있는 파티션이 미래에 필요할 가능성이 높음."),Oy.forEach(e),WR=u(yt),Fs=r(yt,"LI",{});var Ty=a(Fs);VR=s(Ty,"메모리 관리 정책의 기본값인 이 방식도 잘 동작하지만, 사용자는 각 RDD에 persistence priority를 부여하여 제어할 수도 있음."),Ty.forEach(e),yt.forEach(e),C2=u(l),Me=r(l,"H3",{id:!0});var aI=a(Me);xe=r(aI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var qy=a(xe);Gs=r(qy,"SPAN",{class:!0}),a(Gs).forEach(e),qy.forEach(e),ZR=s(aI,"Support for Checkpointing"),aI.forEach(e),B2=u(l),hr=r(l,"P",{});var Jy=a(hr);XR=s(Jy,"RDD가 failure한 이후 lineage를 통해 복구할 수 있지만, lineage chain이 너무 길면 복구 과정에서 시간이 너무 오래 걸릴 수 있음"),Jy.forEach(e),j2=u(l),Ar=r(l,"UL",{});var Qy=a(Ar);zs=r(Qy,"LI",{});var Ky=a(zs);YR=s(Ky,"RDD를 stable storage에 checkpointing하면 유용함"),Ky.forEach(e),Qy.forEach(e),N2=u(l),Mr=r(l,"P",{});var $y=a(Mr);gR=s($y,"일반적으로 Checkpoint는 wide dependency를 포함하는, 긴 lineage graph의 RDD에 대해 유용함"),$y.forEach(e),F2=u(l),ll=r(l,"UL",{});var za=a(ll);Os=r(za,"LI",{});var Wy=a(Os);l6=s(Wy,"만약 이 경우 클러스터 안의 노드의 falilure는 각각의 parent RDD로부터 온 데이터 조각의 손실로 이어질 수 있음. 이 경우 모든 데이터를 다시 계산해야 함"),Wy.forEach(e),e6=u(za),Ts=r(za,"LI",{});var Vy=a(Ts);t6=s(Vy,"반면 narrow dependency의 경우에는, Checkpointing이 불필요함."),Vy.forEach(e),i6=u(za),qs=r(za,"LI",{});var Zy=a(qs);r6=s(Zy,"노드가 실패하여 lost partition을 계산하려면 전체 RDD를 복제하는 비용의 극히 일부만으로 다른 노드에서 병렬적으로 재계산할 수 있기 때문"),Zy.forEach(e),za.forEach(e),G2=u(l),xr=r(l,"P",{});var Xy=a(xr);a6=s(Xy,"Spark는 (persist() method의 REPLICATE flag 등) checkpointing API를 제공함."),Xy.forEach(e),z2=u(l),He=r(l,"UL",{});var gc=a(He);Js=r(gc,"LI",{});var Yy=a(Js);o6=s(Yy,"다만 어떤 데이터를 checkpointing할지는 유저가 결정"),Yy.forEach(e),p6=u(gc),Qs=r(gc,"LI",{});var gy=a(Qs);f6=s(gy,"시스템 복구 시간을 최소화할 수 있도록 자동으로 checkpointing하는 방법을 연구 중에 있음"),gy.forEach(e),gc.forEach(e),O2=u(l),Hr=r(l,"P",{});var lS=a(Hr);s6=s(lS,"RDD의 read-only라는 특성 덕에 일반적인 shared memory보다 checkpointing하기 쉬움."),lS.forEach(e),T2=u(l),Ue=r(l,"UL",{});var l_=a(Ue);Ks=r(l_,"LI",{});var eS=a(Ks);n6=s(eS,"data consistency를 고려할 필요가 없음"),eS.forEach(e),u6=u(l_),$s=r(l_,"LI",{});var tS=a($s);D6=s(tS,"checkpointing을 background에서 진행하면서, 작동중인 프로그램을 멈추거나 특별한 분산 스냅샷 스키마를 사용할 필요가 없음. (동시에 가능)"),tS.forEach(e),l_.forEach(e),q2=u(l),J2=r(l,"BR",{}),Q2=r(l,"BR",{}),K2=u(l),we=r(l,"H2",{id:!0});var oI=a(we);Ce=r(oI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var iS=a(Ce);Ws=r(iS,"SPAN",{class:!0}),a(Ws).forEach(e),iS.forEach(e),v6=s(oI,"Evaluation"),oI.forEach(e),$2=u(l),W2=r(l,"HR",{}),V2=u(l),Ur=r(l,"P",{});var rS=a(Ur);c6=s(rS,"EC2에 올려서 Spark와 RDD, 및 이를 사용하는 User Application의 성능을 검사하였음"),rS.forEach(e),Z2=u(l),j=r(l,"OL",{});var St=a(j);wr=r(St,"LI",{});var pI=a(wr);_6=s(pI,"스파크는 반복적인 기계 학습 및 그래프 애플리케이션에서 하둡을 최대 20배 능가함"),Vs=r(pI,"UL",{});var aS=a(Vs);Zs=r(aS,"LI",{});var oS=a(Zs);m6=s(oS,"데이터를 자바 객체로 메모리에 저장함으로써 입출력 및 역직렬화 비용을 피할 수 있기 때문에 속도가 향상된다."),oS.forEach(e),aS.forEach(e),pI.forEach(e),E6=u(St),Cr=r(St,"LI",{});var fI=a(Cr);d6=s(fI,"사용자가 작성한 애플리케이션에 올라간 Spark는 성능과 확장성이 뛰어나다."),Xs=r(fI,"UL",{});var pS=a(Xs);Ys=r(pS,"LI",{});var fS=a(Ys);R6=s(fS,"analytics report 할 때 하둡보다 40배 빨랐음"),fS.forEach(e),pS.forEach(e),fI.forEach(e),L6=u(St),gs=r(St,"LI",{});var sS=a(gs);I6=s(sS,"노드에 장애가 발생하면 스파크는 손실된 RDD 파티션만 재구성하여 신속하게 복구할 수 있다."),sS.forEach(e),b6=u(St),ln=r(St,"LI",{});var nS=a(ln);k6=s(nS,"스파크는 1TB 데이터 세트를 5-7초의 지연시간(latency)으로 대화식(interactively)으로 쿼리하는 데 사용할 수 있다"),nS.forEach(e),St.forEach(e),X2=u(l),Be=r(l,"H3",{id:!0});var sI=a(Be);je=r(sI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var uS=a(je);en=r(uS,"SPAN",{class:!0}),a(en).forEach(e),uS.forEach(e),y6=s(sI,"Iterative Machine Learning Applications"),sI.forEach(e),Y2=u(l),Ne=r(l,"P",{});var e_=a(Ne);Br=r(e_,"IMG",{src:!0,alt:!0}),S6=u(e_),jr=r(e_,"IMG",{src:!0,alt:!0}),e_.forEach(e),g2=u(l),el=r(l,"UL",{});var Oa=a(el);tn=r(Oa,"LI",{});var DS=a(tn);P6=s(DS,"Logistic Regression: I/O 및 serialization sensitive"),DS.forEach(e),h6=u(Oa),rn=r(Oa,"LI",{});var vS=a(rn);A6=s(vS,"K-Means: compute-intensive"),vS.forEach(e),M6=u(Oa),Nr=r(Oa,"LI",{});var nI=a(Nr);x6=s(nI,"HadoopBinMem"),Ot=r(nI,"UL",{});var t_=a(Ot);an=r(t_,"LI",{});var cS=a(an);H6=s(cS,"input data를 binary format으로 바꾸는 hadoop 버전"),cS.forEach(e),U6=u(t_),on=r(t_,"LI",{});var _S=a(on);w6=s(_S,"데이터를 in-memory HDFS 인스턴스에 저장"),_S.forEach(e),t_.forEach(e),nI.forEach(e),Oa.forEach(e),lv=u(l),Fr=r(l,"P",{});var mS=a(Fr);C6=s(mS,"그림 7의 First iteration: HadoopBM > Hadoop > Spark"),mS.forEach(e),ev=u(l),tl=r(l,"UL",{});var Ta=a(tl);pn=r(Ta,"LI",{});var ES=a(pn);B6=s(ES,"HadoopBM : 데이터를 binary로 바꾸는 추가적인 작업 및 in-memory HDFS를 replicate하는 overhead로 인해 가장 느림"),ES.forEach(e),j6=u(Ta),fn=r(Ta,"LI",{});var dS=a(fn);N6=s(dS,"Hadoop : heartbeat를 보내기 위한 Signaling overhead로 인해 Spark보다 느림"),dS.forEach(e),F6=u(Ta),sn=r(Ta,"LI",{});var RS=a(sn);G6=s(RS,"Spark: 이후의 Iteration부터는 RDD로 인해 데이터가 reuse되어 빨라짐"),RS.forEach(e),Ta.forEach(e),tv=u(l),Gr=r(l,"P",{});var LS=a(Gr);z6=s(LS,"그림 8: 그냥 machine 수 달리해서 재 본거임. 역시 spark가 제일 빠름"),LS.forEach(e),iv=u(l),zr=r(l,"P",{});var IS=a(zr);O6=s(IS,"하둡이 느린 이유"),IS.forEach(e),rv=u(l),il=r(l,"OL",{});var qa=a(il);nn=r(qa,"LI",{});var bS=a(nn);T6=s(bS,`하둡의 소프트웨어 스택의 오버헤드
=> 하둡은 job을 수행할 때 job 설정, task 시작, 정리 등의 overhead 등으로 인해, 최소 25초의 오버헤드가 발생`),bS.forEach(e),q6=u(qa),un=r(qa,"LI",{});var kS=a(un);J6=s(kS,`데이터를 서빙할 때 HDFS의 오버헤드
=> HDFS는 여러 개의 메모리 복사본을 각 블록에 전송하며, 각 블록에 체크섬을 수행하기 때문에 오버헤드 발생`),kS.forEach(e),Q6=u(qa),Dn=r(qa,"LI",{});var yS=a(Dn);K6=s(yS,"binary record를 Java object로 변경하기 위한 deserialization 비용"),yS.forEach(e),qa.forEach(e),av=u(l),Fe=r(l,"P",{});var i_=a(Fe);Or=r(i_,"IMG",{src:!0,alt:!0}),$6=r(i_,"BR",{}),W6=s(i_,`
Text – binary 시간 차이 : parsing에 소요되는 시간`),i_.forEach(e),ov=u(l),Ge=r(l,"UL",{});var r_=a(Ge);vn=r(r_,"LI",{});var SS=a(vn);V6=s(SS,"Hadoop은 binary data를 Java object로 변환하는데 시간이 필요함"),SS.forEach(e),Z6=u(r_),cn=r(r_,"LI",{});var PS=a(cn);X6=s(PS,"Spark는 RDD 요소를 메모리에 Java object로 바로 저장하므로, 오버헤드를 회피함"),PS.forEach(e),r_.forEach(e),pv=u(l),ze=r(l,"H3",{id:!0});var uI=a(ze);Oe=r(uI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var hS=a(Oe);_n=r(hS,"SPAN",{class:!0}),a(_n).forEach(e),hS.forEach(e),Y6=s(uI,"PageRank"),uI.forEach(e),fv=u(l),Te=r(l,"P",{});var a_=a(Te);Tr=r(a_,"IMG",{src:!0,alt:!0}),g6=r(a_,"BR",{}),l7=s(a_,`
PageRank에서도 Spark가 빠르게 나옴`),a_.forEach(e),sv=u(l),qe=r(l,"UL",{});var o_=a(qe);mn=r(o_,"LI",{});var AS=a(mn);e7=s(AS,"Controlled Partitioning을 해주면, data access가 일관되게 일어나기 때문에 속도를 향상시킬 수 있다"),AS.forEach(e),t7=u(o_),En=r(o_,"LI",{});var MS=a(En);i7=s(MS,"또한 Pregel에서 PageRank를 돌려도, Pregel은 추가적인 연산을 하기 때문에 Spark의 버전보다 4초정도 더 길게 나옴."),MS.forEach(e),o_.forEach(e),nv=u(l),Je=r(l,"H3",{id:!0});var DI=a(Je);Qe=r(DI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var xS=a(Qe);dn=r(xS,"SPAN",{class:!0}),a(dn).forEach(e),xS.forEach(e),r7=s(DI,"Fault Recovery"),DI.forEach(e),uv=u(l),Ke=r(l,"P",{});var p_=a(Ke);qr=r(p_,"IMG",{src:!0,alt:!0}),a7=r(p_,"BR",{}),o7=s(p_,`
K-means를 돌릴 때 failure가 발생한 경우 recovery에 얼마나 시간이 걸리는지 보여줌`),p_.forEach(e),Dv=u(l),rl=r(l,"UL",{});var Ja=a(rl);Rn=r(Ja,"LI",{});var HS=a(Rn);p7=s(HS,"6번째 iteration에서 machine 하나 죽여서, 그 machine에서 돌아가는 task가 실패"),HS.forEach(e),f7=u(Ja),Ln=r(Ja,"LI",{});var US=a(Ln);s7=s(US,"다른 machone에서 task를 다시 실행"),US.forEach(e),n7=u(Ja),In=r(Ja,"LI",{});var wS=a(In);u7=s(wS,"해당 task의 input data와 RDD lineage를 다시 읽고, RDD Partition을 재구성"),wS.forEach(e),Ja.forEach(e),vv=u(l),Jr=r(l,"P",{});var CS=a(Jr);D7=s(CS,"checkpoint 기반의 장애 복구 메커니즘은 체크포인트 빈도에 따라 작업을 여러번 반복해야 할수도 있음"),CS.forEach(e),cv=u(l),al=r(l,"UL",{});var Qa=a(al);bn=r(Qa,"LI",{});var BS=a(bn);v7=s(BS,"또한 시스템은 네트워크를 통해 대용량의 working set을 replicate해야 함"),BS.forEach(e),c7=u(Qa),kn=r(Qa,"LI",{});var jS=a(kn);_7=s(jS,"이를 RAM에 복제하면 Spark의 두 배 메모리를 쓰는 거고, DISK에 복제하면 대용량의 데이터를 쓰는 것을 기다려야 함"),jS.forEach(e),m7=u(Qa),yn=r(Qa,"LI",{});var NS=a(yn);E7=s(NS,"Spark의 RDD lineage graph는 크기가 10kb 미만"),NS.forEach(e),Qa.forEach(e),_v=u(l),$e=r(l,"H3",{id:!0});var vI=a($e);We=r(vI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var FS=a(We);Sn=r(FS,"SPAN",{class:!0}),a(Sn).forEach(e),FS.forEach(e),d7=s(vI,"Behavior with Insufficient Memory"),vI.forEach(e),mv=u(l),Ve=r(l,"P",{});var f_=a(Ve);Qr=r(f_,"IMG",{src:!0,alt:!0}),R7=r(f_,"BR",{}),L7=s(f_,`
성능이 감소되긴 하지만 Graceful하게(어느정도 하락폭을 예측할 수 있게) 감소됨`),f_.forEach(e),Ev=u(l),Ze=r(l,"H3",{id:!0});var cI=a(Ze);Xe=r(cI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var GS=a(Xe);Pn=r(GS,"SPAN",{class:!0}),a(Pn).forEach(e),GS.forEach(e),I7=s(cI,"User Applications Built with Spark"),cI.forEach(e),dv=u(l),Kr=r(l,"P",{});var zS=a(Kr);b7=s(zS,"In-memory Analytics:"),zS.forEach(e),Rv=u(l),$r=r(l,"UL",{});var OS=a($r);Wr=r(OS,"LI",{});var _I=a(Wr);k7=s(_I,"영상 배포하는 Conviva Inc라는 회사는 analytic report를 만들기 위해 하둡을 쓰다가 Spark를 사용"),hn=r(_I,"UL",{});var TS=a(hn);An=r(TS,"LI",{});var qS=a(An);y7=s(qS,"40배 빨라짐"),qS.forEach(e),TS.forEach(e),_I.forEach(e),OS.forEach(e),Lv=u(l),Vr=r(l,"P",{});var JS=a(Vr);Zr=r(JS,"IMG",{src:!0,alt:!0}),JS.forEach(e),Iv=u(l),Xr=r(l,"P",{});var QS=a(Xr);S7=s(QS,"Traffic Modeling:"),QS.forEach(e),bv=u(l),Yr=r(l,"UL",{});var KS=a(Yr);gr=r(KS,"LI",{});var mI=a(gr);P7=s(mI,"산발적으로 수집된 자동차 GPS 측정치에서 교통 현황을 추정하기 위한 학습 알고리즘을 병렬적으로 구성함."),Mn=r(mI,"UL",{});var $S=a(Mn);xn=r($S,"LI",{});var WS=a(xn);h7=s(WS,"두 개의 map과 reduceByKey를 반복적으로 적용하여 모델을 학습시켰고, 성능이 선형적으로 확장됨 (분산처리가 잘 되고 있음)"),WS.forEach(e),$S.forEach(e),mI.forEach(e),KS.forEach(e),kv=u(l),la=r(l,"P",{});var VS=a(la);A7=s(VS,"Twitter Spam Classification:"),VS.forEach(e),yv=u(l),ea=r(l,"UL",{});var ZS=a(ea);ta=r(ZS,"LI",{});var EI=a(ta);M7=s(EI,"트위터의 스팸 메시지에서 link를 검증하기 위해 Spark 사용"),Ll=r(EI,"UL",{});var Ka=a(Ll);Hn=r(Ka,"LI",{});var XS=a(Hn);x7=s(XS,"앞서 봤던 logistic regression를 사용하였고, URL이 가리키는 페이지 정보를 수집함."),XS.forEach(e),H7=u(Ka),Un=r(Ka,"LI",{});var YS=a(Un);U7=s(YS,"성능이 linear하게 늘어나지는 않았음 (communication cost가 iteration보다 높아지기 때문)"),YS.forEach(e),w7=u(Ka),wn=r(Ka,"LI",{});var gS=a(wn);C7=s(gS,"아마 네트워크에 접속해서 페이지 정보를 읽어와야 하기 때문인 듯"),gS.forEach(e),Ka.forEach(e),EI.forEach(e),ZS.forEach(e),Sv=u(l),Ye=r(l,"H3",{id:!0});var dI=a(Ye);ge=r(dI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var lP=a(ge);Cn=r(lP,"SPAN",{class:!0}),a(Cn).forEach(e),lP.forEach(e),B7=s(dI,"Interactive Data Mining"),dI.forEach(e),Pv=u(l),lt=r(l,"P",{});var s_=a(lt);ia=r(s_,"IMG",{src:!0,alt:!0}),j7=r(s_,"BR",{}),N7=s(s_,`
Spark는 거대한 dataset에 대화식 query를 날릴 수 있음`),s_.forEach(e),hv=u(l),ol=r(l,"UL",{});var $a=a(ol);Bn=r($a,"LI",{});var eP=a(Bn);F7=s(eP,"(1) => 전체 페이지에 query하여 조회수 확인"),eP.forEach(e),G7=u($a),jn=r($a,"LI",{});var tP=a(jn);z7=s(tP,"(2) => 제목이 주어진 단어와 같은 페이지만 조회수 확인"),tP.forEach(e),O7=u($a),ra=r($a,"LI",{});var RI=a(ra);T7=s(RI,"(3) => 제목이 부분적으로 일치하는 페이지만 조회수 확인"),Nn=r(RI,"UL",{});var iP=a(Nn);Fn=r(iP,"LI",{});var rP=a(Fn);q7=s(rP,"response time이 on-disk에서 하는 것보다 훨씬 빠름 (on-disk는 170초 걸렸다고 함)"),rP.forEach(e),iP.forEach(e),RI.forEach(e),$a.forEach(e),Av=u(l),Mv=r(l,"BR",{}),xv=r(l,"BR",{}),Hv=u(l),et=r(l,"H2",{id:!0});var LI=a(et);tt=r(LI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var aP=a(tt);Gn=r(aP,"SPAN",{class:!0}),a(Gn).forEach(e),aP.forEach(e),J7=s(LI,"Discussions"),LI.forEach(e),Uv=u(l),wv=r(l,"HR",{}),Cv=u(l),aa=r(l,"P",{});var oP=a(aa);Q7=s(oP,"RDD는 immutable하고 coarse-grained transformation을 하므로, 제한된 interface만을 제공하는 것처럼 보이지만, 다양한 application에 적합함"),oP.forEach(e),Bv=u(l),it=r(l,"H3",{id:!0});var II=a(it);rt=r(II,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var pP=a(rt);zn=r(pP,"SPAN",{class:!0}),a(zn).forEach(e),pP.forEach(e),K7=s(II,"Expressing Existing Programming Models"),II.forEach(e),jv=u(l),oa=r(l,"P",{});var fP=a(oa);$7=s(fP,"RDD는 지금까지 제안되어 온 다양한 클러스터 프로그래밍 모델을 “효율적으로” 표현할 수 있음"),fP.forEach(e),Nv=u(l),at=r(l,"UL",{});var n_=a(at);On=r(n_,"LI",{});var sP=a(On);W7=s(sP,"효율적이라는 말은, 단순히 이러한 모델로 작성한 프로그램과 동일한 output을 얻을 수 있을 뿐 아니라, 최적화까지 가능함."),sP.forEach(e),V7=u(n_),Tn=r(n_,"LI",{});var nP=a(Tn);Z7=s(nP,"데이터를 memory에 보관하고, communication을 minimize하기 위해 잘 partitioning하고, failure를 효율적으로 recovery함"),nP.forEach(e),n_.forEach(e),Fv=u(l),pa=r(l,"P",{});var uP=a(pa);X7=s(uP,"RDD로 표현 가능한 모델"),uP.forEach(e),Gv=u(l),N=r(l,"UL",{});var Pt=a(N);qn=r(Pt,"LI",{});var DP=a(qn);Y7=s(DP,"MapReduce: flatMap, GroupByKey, reduceByKey가 각각 Mapper, Reducer, Combiner에 해당"),DP.forEach(e),g7=u(Pt),Jn=r(Pt,"LI",{});var vP=a(Jn);lL=s(vP,"DryadLINQ: Spark로도 할 수 있음"),vP.forEach(e),eL=u(Pt),Qn=r(Pt,"LI",{});var cP=a(Qn);tL=s(cP,"SQL: SQL query를 날려서 data-parallel operation을 수행할 수 있음"),cP.forEach(e),iL=u(Pt),fa=r(Pt,"LI",{});var bI=a(fa);rL=s(bI,"Pregel: Google Pregel은 iterative graph application에 특화된 모델임"),Kn=r(bI,"UL",{});var _P=a(Kn);$n=r(_P,"LI",{});var mP=a($n);aL=s(mP,"RDD를 사용하면 Pregel이 하는 것처럼 vertex state를 메모리에 유지하고, Partitioning을 제어하고, 통신을 최소화하고, 장애 시 부분적인 복구를 수행할 수 있다."),mP.forEach(e),_P.forEach(e),bI.forEach(e),Pt.forEach(e),zv=u(l),sa=r(l,"P",{});var EP=a(sa);oL=s(EP,"Iterative MapReduce"),EP.forEach(e),Ov=u(l),F=r(l,"UL",{});var ht=a(F);Wn=r(ht,"LI",{});var dP=a(Wn);pL=s(dP,"HaLoop 및 Twister 등 MapReduce를 Iterative하게 돌리기 위한 시스템이 있음"),dP.forEach(e),fL=u(ht),Vn=r(ht,"LI",{});var RP=a(Vn);sL=s(RP,`얘네의 핵심은 partitioning 및 메모리에 올려놓고 reuse하는 것인데, 이것도 Spark 200줄로 표현이 가능했음
Batched Stream Processing`),RP.forEach(e),nL=u(ht),Zn=r(ht,"LI",{});var LP=a(Zn);uL=s(LP,"새로운 데이터를 받아서 주기적으로 결과를 업데이트하는 점진적인 시스템"),LP.forEach(e),DL=u(ht),Xn=r(ht,"LI",{});var IP=a(Xn);vL=s(IP,"Intermediate state를 RDD로 두면 처리 속도가 향상됨."),IP.forEach(e),ht.forEach(e),Tv=u(l),na=r(l,"P",{});var bP=a(na);cL=s(bP,"RDD가 이렇게 다양한 프로그래밍 모델을 표현할 수 있는 이유는, RDD의 제약조건이 다수의 병렬 어플리케이션에서 큰 의미가 없기 때문임."),bP.forEach(e),qv=u(l),G=r(l,"UL",{});var At=a(G);Yn=r(At,"LI",{});var kP=a(Yn);_L=s(kP,"RDD는 오직 transformation을 거쳐서 생성될 수 있음"),kP.forEach(e),mL=u(At),gn=r(At,"LI",{});var yP=a(gn);EL=s(yP,"근데 대부분의 병렬 프로그램이 표현을 쉽게 하려고 원래 동일한 연산을 record에 적용하고 있음."),yP.forEach(e),dL=u(At),lu=r(At,"LI",{});var SP=a(lu);RL=s(SP,"동일한 dataset의 버전을 나타내기 위해 여러 개의 RDD를 생성할 수 있기 때문에, RDD의 immutability는 장애물이 아님."),SP.forEach(e),LL=u(At),eu=r(At,"LI",{});var PP=a(eu);IL=s(PP,"실제로, 대부분의 MapReduce 애플리케이션은 HDFS 등 파일 업데이트를 허용하지 않는 파일 시스템에서 실행됨."),PP.forEach(e),At.forEach(e),Jv=u(l),ua=r(l,"P",{});var hP=a(ua);bL=s(hP,"이전 프레임워크들은 데이터 공유를 위한 abstraction이 부족했기 때문에 이런 범용성을 가지지 못한 것 같음"),hP.forEach(e),Qv=u(l),ot=r(l,"H3",{id:!0});var kI=a(ot);pt=r(kI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var AP=a(pt);tu=r(AP,"SPAN",{class:!0}),a(tu).forEach(e),AP.forEach(e),kL=s(kI,"Leveraging RDDs for Debugging"),kI.forEach(e),Kv=u(l),Da=r(l,"P",{});var MP=a(Da);yL=s(MP,"DD는 fault tolerance를 위해 deterministical하게 다시 계산할 수 있게끔 설계되었지만, 이러한 특성 덕분에 디버깅도 잘함"),MP.forEach(e),$v=u(l),va=r(l,"UL",{});var xP=a(va);iu=r(xP,"LI",{});var HP=a(iu);SL=s(HP,"작업 중 RDD의 lineage를 기록함으로써, RDD를 나중에 재구성하여 사용자가 대화식으로 query할 수 있고, RDD 종속된 파티션을 다시 계산하여 단일 프로세스 디버거에서 job의 모든 task를 다시 실행할 수 있음"),HP.forEach(e),xP.forEach(e),Wv=u(l),ca=r(l,"P",{});var UP=a(ca);PL=s(UP,"여러 노드에서 이벤트 순서를 캡쳐해야 하는 기존의 general distributed system에서의 replay debugger와는 달리, 이 방식은 RDD lineage graph만을 기록하기 때문에 recording overhead가 거의 없음."),UP.forEach(e),Vv=u(l),Zv=r(l,"BR",{}),Xv=r(l,"BR",{}),Yv=u(l),ft=r(l,"H2",{id:!0});var yI=a(ft);st=r(yI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var wP=a(st);ru=r(wP,"SPAN",{class:!0}),a(ru).forEach(e),wP.forEach(e),hL=s(yI,"Related Work"),yI.forEach(e),gv=u(l),lc=r(l,"HR",{}),ec=u(l),_a=r(l,"P",{});var CP=a(_a);AL=s(CP,"Cluster Programming Models:"),CP.forEach(e),tc=u(l),z=r(l,"OL",{});var Mt=a(z);Tt=r(Mt,"LI",{});var u_=a(Tt);au=r(u_,"P",{});var BP=a(au);ML=s(BP,"data flow model"),BP.forEach(e),xL=u(u_),qt=r(u_,"UL",{});var D_=a(qt);ou=r(D_,"LI",{});var jP=a(ou);HL=s(jP,"MapReduce, Dryad, Ciel 등은 데이터 프로세싱을 위한 다양한 Operator 제공"),jP.forEach(e),UL=u(D_),pu=r(D_,"LI",{});var NP=a(pu);wL=s(NP,"반면 RDD는 data replication, I/O 및 serization의 높은 비용을 피하기 위해 stable storage보다 더 효율적인 abstraction을 제공함."),NP.forEach(e),D_.forEach(e),u_.forEach(e),CL=u(Mt),Jt=r(Mt,"LI",{});var v_=a(Jt);fu=r(v_,"P",{});var FP=a(fu);BL=s(FP,"High level programming interface for data flow system"),FP.forEach(e),jL=u(v_),Il=r(v_,"UL",{});var Wa=a(Il);su=r(Wa,"LI",{});var GP=a(su);NL=s(GP,"DryadLINQ, FlumeJava는 사용자가 map, join 등의 연산자로 parallel collection에 접근할 수 있는 language-integrated API를 제공"),GP.forEach(e),FL=u(Wa),nu=r(Wa,"LI",{});var zP=a(nu);GL=s(zP,"하지만 이러한 시스템들은 query의 결과를 다른 query로 pipeline하기 어려움"),zP.forEach(e),zL=u(Wa),uu=r(Wa,"LI",{});var OP=a(uu);OL=s(OP,"Spark는 이것이 가능하기 때문에, 다양한 Application에서 활용할 수 있음"),OP.forEach(e),Wa.forEach(e),v_.forEach(e),TL=u(Mt),Qt=r(Mt,"LI",{});var c_=a(Qt);Du=r(c_,"P",{});var TP=a(Du);qL=s(TP,"Pregel, HaLoop, Twister 등은 generic abstraction을 제공하지 않아서 정해진 용도 이외의 용도로 사용하기 어려움."),TP.forEach(e),JL=u(c_),vu=r(c_,"UL",{});var qP=a(vu);cu=r(qP,"LI",{});var JP=a(cu);QL=s(JP,"RDD는 distributed storage abstraction을 제공하여, interactive data mining 등 위의 시스템이 하기 어려운 것도 가능함"),JP.forEach(e),qP.forEach(e),c_.forEach(e),KL=u(Mt),Kt=r(Mt,"LI",{});var __=a(Kt);_u=r(__,"P",{});var QP=a(_u);$L=s(QP,"Piccolo나 RAMCloud 등의 Distributed Shared Memory 기반의 시스템은 사용자가 in-memory computation을 수행할 수 있게끔, shared mutable state를 노출시킴."),QP.forEach(e),WL=u(__),bl=r(__,"UL",{});var Va=a(bl);mu=r(Va,"LI",{});var KP=a(mu);VL=s(KP,"RDD는 두 가지 측면에서 이러한 시스템과 다름"),KP.forEach(e),ZL=u(Va),Eu=r(Va,"LI",{});var $P=a(Eu);XL=s($P,"RDD는 map, sort, join 등 high level interface를 제공하는 반면, 위의 애들은 table cell에 대한 read/update밖에 지원하지 않음"),$P.forEach(e),YL=u(Va),du=r(Va,"LI",{});var WP=a(du);gL=s(WP,"RDD는 Lineage based라서, 위 애들보다 checkpoint 및 rollback이 덜 무거움"),WP.forEach(e),Va.forEach(e),__.forEach(e),Mt.forEach(e),ic=u(l),nt=r(l,"P",{});var m_=a(nt);l0=s(m_,"Caching System:"),e0=r(m_,"BR",{}),t0=s(m_,`
Nectar는 DryadLINQ 작업에서 intermediate data를 재사용할 수 있음.`),m_.forEach(e),rc=u(l),O=r(l,"UL",{});var xt=a(O);Ru=r(xt,"LI",{});var VP=a(Ru);i0=s(VP,"RDD에서도 이러한 능력을 본땄음"),VP.forEach(e),r0=u(xt),Lu=r(xt,"LI",{});var ZP=a(Lu);a0=s(ZP,"근데 Nectar는 in-memory caching을 제공하지 않고, 사용자가 원하는 dataset을 persist 및 partitioning control하게끔 하는 기능이 없음."),ZP.forEach(e),o0=u(xt),Iu=r(xt,"LI",{});var XP=a(Iu);p0=s(XP,"CIel 및 FlumeJava는 in-memory로 caching을 지원하지 않고, 원하는 데이터를 caching할 수 없음"),XP.forEach(e),f0=u(xt),bu=r(xt,"LI",{});var YP=a(bu);s0=s(YP,"분산 파일 시스템에 대한 인메모리 캐시도 제시되었지만, RDD처럼 중간 결과를 sharing하는 것보다는 약간 모자람"),YP.forEach(e),xt.forEach(e),ac=u(l),ut=r(l,"P",{});var E_=a(ut);n0=s(E_,"Lineage:"),u0=r(E_,"BR",{}),D0=s(E_,`
Lineage를 capture하는 것은 오랜 연구 주제였음.`),E_.forEach(e),oc=u(l),pl=r(l,"UL",{});var Za=a(pl);ku=r(Za,"LI",{});var gP=a(ku);v0=s(gP,"RDD는 fine-grained lineage를 capture하는 데 비용이 적게 드는 병렬 프로그래밍 모델을 제공하여, 장애 복구에 사용할 수 있도록 함."),gP.forEach(e),c0=u(Za),yu=r(Za,"LI",{});var lh=a(yu);_0=s(lh,"이러한 lineage based의 회복 매커니즘은 MapReduce나 Dryad의 메커니즘하고 비슷하지만, 얘네들은 job이 끝나면 lineage를 잃어버리므로, 컴퓨팅 간에 데이터를 공유하려면 replicated storage를 사용해야 함"),lh.forEach(e),m0=u(Za),Su=r(Za,"LI",{});var eh=a(Su);E0=s(eh,"반면 RDD는 disk I/O나 replication 없이 lineage를 써서, 데이터가 메모리에 지속되게 하여 효율적으로 데이터를 공유할 수 있음."),eh.forEach(e),Za.forEach(e),pc=u(l),Dt=r(l,"P",{});var d_=a(Dt);d0=s(d_,"Relational Database:"),R0=r(d_,"BR",{}),L0=s(d_,`
RDMS는 fine-grained이며 모든 record에 대한 read/write 접근을 허용함. 또한 fault tolerance, logging operation, consistency를 유지해야 함`),d_.forEach(e),fc=u(l),ma=r(l,"UL",{});var th=a(ma);Pu=r(th,"LI",{});var ih=a(Pu);I0=s(ih,"반면 RDS는 coarse-grained이므로 이런거 할 필요가 없음"),ih.forEach(e),th.forEach(e),sc=u(l),nc=r(l,"BR",{}),uc=r(l,"BR",{}),Dc=u(l),vt=r(l,"H2",{id:!0});var SI=a(vt);ct=r(SI,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var rh=a(ct);hu=r(rh,"SPAN",{class:!0}),a(hu).forEach(e),rh.forEach(e),b0=s(SI,"Conclusion"),SI.forEach(e),vc=u(l),cc=r(l,"HR",{}),_c=u(l),Ea=r(l,"P",{});var ah=a(Ea);k0=s(ah,"RDD : cluster application에서 데이터를 sharing하는 abstraction"),ah.forEach(e),mc=u(l),da=r(l,"UL",{});var oh=a(da);Au=r(oh,"LI",{});var ph=a(Au);y0=s(ph,"효율적인, general-purpose, fault-tolerance를 제공"),ph.forEach(e),oh.forEach(e),Ec=u(l),Ra=r(l,"P",{});var fh=a(Ra);S0=s(fh,"RDD는 다양한 종류의 병렬 application을 표현할 수 있음"),fh.forEach(e),dc=u(l),La=r(l,"UL",{});var sh=a(La);Mu=r(sh,"LI",{});var nh=a(Mu);P0=s(nh,"iterative computation을 위해 제안된 많은 특화된 프로그래밍 모델과, 이러한 모델이 캡처하지 못하는 새로운 응용 프로그램 등 다양한 병렬 애플리케이션을 표현할 수 있음."),nh.forEach(e),sh.forEach(e),Rc=u(l),Ia=r(l,"P",{});var uh=a(Ia);h0=s(uh,"fault tolerance를 위해 data replicating을 선택하는 기존 cluster의 storage abstraction과는 달리, RDD는 coarse-grained transformation 기반의 API를 제공"),uh.forEach(e),Lc=u(l),ba=r(l,"UL",{});var Dh=a(ba);xu=r(Dh,"LI",{});var vh=a(xu);A0=s(vh,"lineage를 통해 효율적으로 recover 가능"),vh.forEach(e),Dh.forEach(e),Ic=u(l),ka=r(l,"P",{});var ch=a(ka);M0=s(ch,`RDD가 구현된 시스템인 Spark의 성능은 interactive application에서 Hadoop보다 20배 뛰어남.
또한 100기가바이트 대의 데이터에 대화형 쿼리를 날릴 수도 있다.`),ch.forEach(e),this.h()},h(){D(Ht,"class","icon icon-link"),D(R,"aria-hidden","true"),D(R,"tabindex","-1"),D(R,"href","#abstraction"),D(d,"id","abstraction"),D(no,"class","icon icon-link"),D(Sl,"aria-hidden","true"),D(Sl,"tabindex","-1"),D(Sl,"href","#introduce"),D(yl,"id","introduce"),D(Co,"class","icon icon-link"),D(Hl,"aria-hidden","true"),D(Hl,"tabindex","-1"),D(Hl,"href","#resilient-distributed-datasetsrdd"),D(xl,"id","resilient-distributed-datasetsrdd"),D(Bo,"class","icon icon-link"),D(wl,"aria-hidden","true"),D(wl,"tabindex","-1"),D(wl,"href","#rdd-abstraction"),D(Ul,"id","rdd-abstraction"),D(Jo,"class","icon icon-link"),D(jl,"aria-hidden","true"),D(jl,"tabindex","-1"),D(jl,"href","#spark-programming-interface"),D(Bl,"id","spark-programming-interface"),D(ep,"class","icon icon-link"),D(Fl,"aria-hidden","true"),D(Fl,"tabindex","-1"),D(Fl,"href","#example-console-log-mining"),D(Nl,"id","example-console-log-mining"),v(Di.src,PI="/post_img/Distributed%20Computing/Spark/RDD/2.png")||D(Di,"src",PI),D(Di,"alt","Alt text"),v(vi.src,hI="/post_img/Distributed%20Computing/Spark/RDD/3.png")||D(vi,"src",hI),D(vi,"alt","Alt text"),v(ci.src,AI="/post_img/Distributed%20Computing/Spark/RDD/1.png")||D(ci,"src",AI),D(ci,"alt","Alt text"),v(Ei.src,MI="/post_img/Distributed%20Computing/Spark/RDD/0.png")||D(Ei,"src",MI),D(Ei,"alt","Alt text"),D(mp,"class","icon icon-link"),D(ql,"aria-hidden","true"),D(ql,"tabindex","-1"),D(ql,"href","#advantages-of-the-rdd-model"),D(Tl,"id","advantages-of-the-rdd-model"),v(Li.src,xI="/post_img/Distributed%20Computing/Spark/RDD/4.png")||D(Li,"src",xI),D(Li,"alt","Alt text"),D(jt,"start","2"),D(Hp,"class","icon icon-link"),D(Kl,"aria-hidden","true"),D(Kl,"tabindex","-1"),D(Kl,"href","#application-not-suitable-for-rdds"),D(Ql,"id","application-not-suitable-for-rdds"),D(Np,"class","icon icon-link"),D(Wl,"aria-hidden","true"),D(Wl,"tabindex","-1"),D(Wl,"href","#spark-programming-interfaces"),D($l,"id","spark-programming-interfaces"),D(Kp,"class","icon icon-link"),D(Yl,"aria-hidden","true"),D(Yl,"tabindex","-1"),D(Yl,"href","#rdd-operations-in-spark"),D(Xl,"id","rdd-operations-in-spark"),v(wi.src,HI="/post_img/Distributed%20Computing/Spark/RDD/5.png")||D(wi,"src",HI),D(wi,"alt","Alt text"),D(Xp,"class","icon icon-link"),D(te,"aria-hidden","true"),D(te,"tabindex","-1"),D(te,"href","#example-logistic-regression"),D(ee,"id","example-logistic-regression"),v(Gi.src,UI="/post_img/Distributed%20Computing/Spark/RDD/6.png")||D(Gi,"src",UI),D(Gi,"alt","Alt text"),v(zi.src,wI="/post_img/Distributed%20Computing/Spark/RDD/7.png")||D(zi,"src",wI),D(zi,"alt","Alt text"),D(af,"class","icon icon-link"),D(oe,"aria-hidden","true"),D(oe,"tabindex","-1"),D(oe,"href","#example-pagerank"),D(ae,"id","example-pagerank"),v(Qi.src,CI="/post_img/Distributed%20Computing/Spark/RDD/8.png")||D(Qi,"src",CI),D(Qi,"alt","Alt text"),v(Ki.src,BI="/post_img/Distributed%20Computing/Spark/RDD/9.png")||D(Ki,"src",BI),D(Ki,"alt","Alt text"),v(Wi.src,jI="/post_img/Distributed%20Computing/Spark/RDD/10.png")||D(Wi,"src",jI),D(Wi,"alt","Alt text"),D(kf,"class","icon icon-link"),D(ne,"aria-hidden","true"),D(ne,"tabindex","-1"),D(ne,"href","#representing-rdds"),D(se,"id","representing-rdds"),v(Yi.src,NI="/post_img/Distributed%20Computing/Spark/RDD/11.png")||D(Yi,"src",NI),D(Yi,"alt","Alt text"),v(gi.src,FI="/post_img/Distributed%20Computing/Spark/RDD/12.png")||D(gi,"src",FI),D(gi,"alt","Alt text"),D(ls,"class","icon icon-link"),D(me,"aria-hidden","true"),D(me,"tabindex","-1"),D(me,"href","#implementation"),D(_e,"id","implementation"),D(as,"class","icon icon-link"),D(Le,"aria-hidden","true"),D(Le,"tabindex","-1"),D(Le,"href","#job-scheduling"),D(Re,"id","job-scheduling"),v(nr.src,GI="/post_img/Distributed%20Computing/Spark/RDD/13.png")||D(nr,"src",GI),D(nr,"alt","Alt text"),D(Rs,"class","icon icon-link"),D(ye,"aria-hidden","true"),D(ye,"tabindex","-1"),D(ye,"href","#interpreter-integration"),D(ke,"id","interpreter-integration"),v(Lr.src,zI="/post_img/Distributed%20Computing/Spark/RDD/14.png")||D(Lr,"src",zI),D(Lr,"alt","Alt text"),D(As,"class","icon icon-link"),D(Ae,"aria-hidden","true"),D(Ae,"tabindex","-1"),D(Ae,"href","#memory-management"),D(he,"id","memory-management"),D(Gs,"class","icon icon-link"),D(xe,"aria-hidden","true"),D(xe,"tabindex","-1"),D(xe,"href","#support-for-checkpointing"),D(Me,"id","support-for-checkpointing"),D(Ws,"class","icon icon-link"),D(Ce,"aria-hidden","true"),D(Ce,"tabindex","-1"),D(Ce,"href","#evaluation"),D(we,"id","evaluation"),D(en,"class","icon icon-link"),D(je,"aria-hidden","true"),D(je,"tabindex","-1"),D(je,"href","#iterative-machine-learning-applications"),D(Be,"id","iterative-machine-learning-applications"),v(Br.src,OI="/post_img/Distributed%20Computing/Spark/RDD/15.png")||D(Br,"src",OI),D(Br,"alt","Alt text"),v(jr.src,TI="/post_img/Distributed%20Computing/Spark/RDD/16.png")||D(jr,"src",TI),D(jr,"alt","Alt text"),v(Or.src,qI="/post_img/Distributed%20Computing/Spark/RDD/17.png")||D(Or,"src",qI),D(Or,"alt","Alt text"),D(_n,"class","icon icon-link"),D(Oe,"aria-hidden","true"),D(Oe,"tabindex","-1"),D(Oe,"href","#pagerank"),D(ze,"id","pagerank"),v(Tr.src,JI="/post_img/Distributed%20Computing/Spark/RDD/18.png")||D(Tr,"src",JI),D(Tr,"alt","Alt text"),D(dn,"class","icon icon-link"),D(Qe,"aria-hidden","true"),D(Qe,"tabindex","-1"),D(Qe,"href","#fault-recovery"),D(Je,"id","fault-recovery"),v(qr.src,QI="/post_img/Distributed%20Computing/Spark/RDD/19.png")||D(qr,"src",QI),D(qr,"alt","Alt text"),D(Sn,"class","icon icon-link"),D(We,"aria-hidden","true"),D(We,"tabindex","-1"),D(We,"href","#behavior-with-insufficient-memory"),D($e,"id","behavior-with-insufficient-memory"),v(Qr.src,KI="/post_img/Distributed%20Computing/Spark/RDD/20.png")||D(Qr,"src",KI),D(Qr,"alt","Alt text"),D(Pn,"class","icon icon-link"),D(Xe,"aria-hidden","true"),D(Xe,"tabindex","-1"),D(Xe,"href","#user-applications-built-with-spark"),D(Ze,"id","user-applications-built-with-spark"),v(Zr.src,$I="/post_img/Distributed%20Computing/Spark/RDD/21.png")||D(Zr,"src",$I),D(Zr,"alt","Alt text"),D(Cn,"class","icon icon-link"),D(ge,"aria-hidden","true"),D(ge,"tabindex","-1"),D(ge,"href","#interactive-data-mining"),D(Ye,"id","interactive-data-mining"),v(ia.src,WI="/post_img/Distributed%20Computing/Spark/RDD/22.png")||D(ia,"src",WI),D(ia,"alt","Alt text"),D(Gn,"class","icon icon-link"),D(tt,"aria-hidden","true"),D(tt,"tabindex","-1"),D(tt,"href","#discussions"),D(et,"id","discussions"),D(zn,"class","icon icon-link"),D(rt,"aria-hidden","true"),D(rt,"tabindex","-1"),D(rt,"href","#expressing-existing-programming-models"),D(it,"id","expressing-existing-programming-models"),D(tu,"class","icon icon-link"),D(pt,"aria-hidden","true"),D(pt,"tabindex","-1"),D(pt,"href","#leveraging-rdds-for-debugging"),D(ot,"id","leveraging-rdds-for-debugging"),D(ru,"class","icon icon-link"),D(st,"aria-hidden","true"),D(st,"tabindex","-1"),D(st,"href","#related-work"),D(ft,"id","related-work"),D(hu,"class","icon icon-link"),D(ct,"aria-hidden","true"),D(ct,"tabindex","-1"),D(ct,"href","#conclusion"),D(vt,"id","conclusion")},m(l,o){p(l,d,o),t(d,R),t(R,Ht),t(d,L_),p(l,Fu,o),p(l,$t,o),t($t,I_),p(l,Gu,o),p(l,m,o),t(m,Xa),t(Xa,Ya),t(Ya,b_),t(m,k_),t(m,ga),t(ga,lo),t(lo,y_),t(m,S_),t(m,Ut),t(Ut,eo),t(eo,P_),t(Ut,h_),t(Ut,wt),t(wt,to),t(to,A_),t(wt,M_),t(wt,io),t(io,x_),t(m,H_),t(m,ro),t(ro,ao),t(ao,U_),t(m,w_),t(m,oo),t(oo,po),t(po,C_),t(m,B_),t(m,fo),t(fo,so),t(so,j_),p(l,zu,o),p(l,Ou,o),p(l,Tu,o),p(l,qu,o),p(l,yl,o),t(yl,Sl),t(Sl,no),t(yl,N_),p(l,Ju,o),p(l,Qu,o),p(l,Ku,o),p(l,Wt,o),t(Wt,F_),p(l,$u,o),p(l,q,o),t(q,uo),t(uo,G_),t(q,z_),t(q,Do),t(Do,O_),t(q,T_),t(q,vo),t(vo,q_),p(l,Wu,o),p(l,Vt,o),t(Vt,J_),p(l,Vu,o),p(l,P,o),t(P,co),t(co,Q_),t(P,K_),t(P,_o),t(_o,$_),t(P,W_),t(P,mo),t(mo,V_),t(P,Z_),t(P,Eo),t(Eo,X_),p(l,Zu,o),p(l,Zt,o),t(Zt,Y_),p(l,Xu,o),p(l,J,o),t(J,Ro),t(Ro,g_),t(J,lm),t(J,Lo),t(Lo,em),t(J,tm),t(J,Io),t(Io,im),p(l,Yu,o),p(l,Xt,o),t(Xt,rm),p(l,gu,o),p(l,Pl,o),t(Pl,bo),t(bo,am),t(Pl,om),t(Pl,ko),t(ko,pm),p(l,l1,o),p(l,Yt,o),t(Yt,fm),p(l,e1,o),p(l,h,o),t(h,yo),t(yo,sm),t(h,nm),t(h,So),t(So,um),t(h,Dm),t(h,Po),t(Po,vm),t(h,cm),t(h,ho),t(ho,_m),p(l,t1,o),p(l,gt,o),t(gt,mm),p(l,i1,o),p(l,hl,o),t(hl,Ao),t(Ao,Em),t(hl,dm),t(hl,Mo),t(Mo,Rm),p(l,r1,o),p(l,li,o),t(li,Lm),p(l,a1,o),p(l,Al,o),t(Al,xo),t(xo,Im),t(Al,bm),t(Al,Ho),t(Ho,km),p(l,o1,o),p(l,ei,o),t(ei,ym),p(l,p1,o),p(l,Ml,o),t(Ml,Uo),t(Uo,Sm),t(Ml,Pm),t(Ml,wo),t(wo,hm),p(l,f1,o),p(l,s1,o),p(l,n1,o),p(l,u1,o),p(l,xl,o),t(xl,Hl),t(Hl,Co),t(xl,Am),p(l,D1,o),p(l,v1,o),p(l,c1,o),p(l,Ul,o),t(Ul,wl),t(wl,Bo),t(Ul,Mm),p(l,_1,o),p(l,ti,o),t(ti,xm),p(l,m1,o),p(l,Q,o),t(Q,jo),t(jo,Hm),t(Q,Um),t(Q,No),t(No,wm),t(Q,Cm),t(Q,Fo),t(Fo,Bm),p(l,E1,o),p(l,ii,o),t(ii,jm),p(l,d1,o),p(l,Cl,o),t(Cl,Go),t(Go,Nm),t(Cl,Fm),t(Cl,zo),t(zo,Gm),p(l,R1,o),p(l,ri,o),t(ri,zm),p(l,L1,o),p(l,K,o),t(K,Oo),t(Oo,Om),t(K,Tm),t(K,To),t(To,qm),t(K,Jm),t(K,qo),t(qo,Qm),p(l,I1,o),p(l,Bl,o),t(Bl,jl),t(jl,Jo),t(Bl,Km),p(l,b1,o),p(l,ai,o),t(ai,$m),p(l,k1,o),p(l,oi,o),t(oi,Qo),t(Qo,Wm),p(l,y1,o),p(l,pi,o),t(pi,Vm),p(l,S1,o),p(l,$,o),t($,Ko),t(Ko,Zm),t($,Xm),t($,fi),t(fi,Ym),t(fi,Dl),t(Dl,$o),t($o,gm),t(Dl,lE),t(Dl,Wo),t(Wo,eE),t(Dl,tE),t(Dl,Vo),t(Vo,iE),t($,rE),t($,Zo),t(Zo,aE),p(l,P1,o),p(l,si,o),t(si,oE),p(l,h1,o),p(l,A,o),t(A,Xo),t(Xo,pE),t(A,fE),t(A,Yo),t(Yo,sE),t(A,nE),t(A,go),t(go,uE),t(A,DE),t(A,lp),t(lp,vE),p(l,A1,o),p(l,Nl,o),t(Nl,Fl),t(Fl,ep),t(Nl,cE),p(l,M1,o),p(l,ni,o),t(ni,_E),p(l,x1,o),p(l,ui,o),t(ui,vl),t(vl,mE),t(vl,EE),t(vl,dE),t(vl,Di),t(vl,cl),t(cl,tp),t(tp,RE),t(cl,LE),t(cl,ip),t(ip,IE),t(cl,bE),t(cl,Ct),t(Ct,kE),t(Ct,rp),t(rp,yE),t(Ct,SE),p(l,H1,o),p(l,_l,o),t(_l,PE),t(_l,hE),t(_l,AE),t(_l,vi),p(l,U1,o),p(l,ml,o),t(ml,ME),t(ml,xE),t(ml,HE),t(ml,ci),p(l,w1,o),p(l,El,o),t(El,ap),t(ap,UE),t(El,wE),t(El,op),t(op,CE),t(El,BE),p(l,C1,o),p(l,Gl,o),t(Gl,pp),Lh(zl,pp,null),t(Gl,jE),t(Gl,fp),t(fp,NE),p(l,B1,o),p(l,_i,o),t(_i,FE),p(l,j1,o),p(l,mi,o),t(mi,Ei),p(l,N1,o),p(l,M,o),t(M,di),t(di,GE),t(di,dl),t(dl,Bt),t(Bt,zE),t(Bt,sp),t(sp,OE),t(Bt,TE),t(dl,qE),t(dl,np),t(np,JE),t(dl,QE),t(dl,up),t(up,KE),t(M,$E),t(M,Dp),t(Dp,WE),t(M,VE),t(M,Ol),t(Ol,vp),t(vp,ZE),t(Ol,XE),t(Ol,cp),t(cp,YE),t(Ol,gE),t(M,l3),t(M,_p),t(_p,e3),p(l,F1,o),p(l,Tl,o),t(Tl,ql),t(ql,mp),t(Tl,t3),p(l,G1,o),p(l,Ri,o),t(Ri,Li),p(l,z1,o),p(l,Ii,o),t(Ii,i3),p(l,O1,o),p(l,c,o),t(c,Ep),t(Ep,r3),t(c,a3),t(c,dp),t(dp,o3),t(c,p3),t(c,Rp),t(Rp,f3),t(c,s3),t(c,Lp),t(Lp,n3),t(c,u3),t(c,Ip),t(Ip,D3),t(c,v3),t(c,bp),t(bp,c3),t(c,_3),t(c,kp),t(kp,m3),t(c,E3),t(c,yp),t(yp,d3),p(l,T1,o),p(l,bi,o),t(bi,R3),p(l,q1,o),p(l,Jl,o),t(Jl,Sp),t(Sp,Pp),t(Pp,hp),t(hp,L3),t(Jl,I3),t(Jl,ki),t(ki,jt),t(jt,Ap),t(Ap,b3),t(jt,k3),t(ki,Mp),t(Mp,xp),t(xp,y3),p(l,J1,o),p(l,Ql,o),t(Ql,Kl),t(Kl,Hp),t(Ql,S3),p(l,Q1,o),p(l,yi,o),t(yi,P3),p(l,K1,o),p(l,Si,o),t(Si,Up),t(Up,h3),p(l,$1,o),p(l,Pi,o),t(Pi,A3),p(l,W1,o),p(l,W,o),t(W,hi),t(hi,M3),t(hi,Nt),t(Nt,wp),t(wp,x3),t(Nt,H3),t(Nt,Cp),t(Cp,U3),t(W,w3),t(W,Bp),t(Bp,C3),t(W,B3),t(W,jp),t(jp,j3),p(l,V1,o),p(l,Z1,o),p(l,X1,o),p(l,Y1,o),p(l,$l,o),t($l,Wl),t(Wl,Np),t($l,N3),p(l,g1,o),p(l,lD,o),p(l,eD,o),p(l,Ai,o),t(Ai,F3),p(l,tD,o),p(l,Mi,o),t(Mi,Fp),t(Fp,G3),p(l,iD,o),p(l,xi,o),t(xi,z3),p(l,rD,o),p(l,V,o),t(V,Gp),t(Gp,O3),t(V,T3),t(V,zp),t(zp,q3),t(V,J3),t(V,Op),t(Op,Q3),p(l,aD,o),p(l,Hi,o),t(Hi,K3),p(l,oD,o),p(l,Vl,o),t(Vl,Tp),t(Tp,$3),t(Vl,W3),t(Vl,qp),t(qp,V3),p(l,pD,o),p(l,Ui,o),t(Ui,Z3),p(l,fD,o),p(l,Zl,o),t(Zl,Jp),t(Jp,X3),t(Zl,Y3),t(Zl,Qp),t(Qp,g3),p(l,sD,o),p(l,Xl,o),t(Xl,Yl),t(Yl,Kp),t(Xl,ld),p(l,nD,o),p(l,gl,o),t(gl,wi),t(gl,ed),t(gl,td),p(l,uD,o),p(l,le,o),t(le,$p),t($p,id),t(le,rd),t(le,Wp),t(Wp,ad),p(l,DD,o),p(l,Ci,o),t(Ci,od),p(l,vD,o),p(l,Bi,o),t(Bi,Vp),t(Vp,pd),p(l,cD,o),p(l,ji,o),t(ji,fd),p(l,_D,o),p(l,Ni,o),t(Ni,Zp),t(Zp,sd),p(l,mD,o),p(l,ee,o),t(ee,te),t(te,Xp),t(ee,nd),p(l,ED,o),p(l,Fi,o),t(Fi,ud),p(l,dD,o),p(l,ie,o),t(ie,Yp),t(Yp,Dd),t(ie,vd),t(ie,gp),t(gp,cd),p(l,RD,o),p(l,re,o),t(re,Gi),t(re,_d),t(re,zi),p(l,LD,o),p(l,Oi,o),t(Oi,md),p(l,ID,o),p(l,x,o),t(x,lf),t(lf,Ed),t(x,dd),t(x,Ti),t(Ti,Rd),t(Ti,ef),t(ef,Ld),t(x,Id),t(x,Ft),t(Ft,bd),t(Ft,tf),t(tf,kd),t(Ft,yd),t(x,Sd),t(x,rf),t(rf,Pd),p(l,bD,o),p(l,ae,o),t(ae,oe),t(oe,af),t(ae,hd),p(l,kD,o),p(l,qi,o),t(qi,of),t(of,Ad),p(l,yD,o),p(l,Ji,o),t(Ji,Md),p(l,SD,o),p(l,pe,o),t(pe,pf),t(pf,xd),t(pe,Hd),t(pe,ff),t(ff,Ud),p(l,PD,o),p(l,y,o),t(y,wd),t(y,Cd),t(y,Bd),t(y,Qi),t(y,jd),t(y,Ki),t(y,Nd),t(y,Fd),p(l,hD,o),p(l,_,o),t(_,S),t(S,Gd),t(S,sf),t(sf,zd),t(S,Od),t(S,nf),t(nf,Td),t(S,qd),t(S,uf),t(uf,Jd),t(S,Qd),t(S,Df),t(Df,Kd),t(S,$d),t(_,Wd),t(_,vf),t(vf,Vd),t(_,Zd),t(_,cf),t(cf,Xd),t(_,Yd),t(_,_f),t(_f,gd),t(_,l4),t(_,mf),t(mf,e4),t(_,t4),t(_,Ef),t(Ef,i4),t(_,r4),t(_,df),t(df,a4),p(l,AD,o),p(l,$i,o),t($i,o4),p(l,MD,o),p(l,L,o),t(L,Rf),t(Rf,p4),t(L,f4),t(L,Lf),t(Lf,s4),t(L,n4),t(L,If),t(If,u4),t(L,D4),t(L,fe),t(fe,v4),t(fe,c4),t(fe,_4),t(fe,Wi),t(L,m4),t(L,bf),t(bf,E4),p(l,xD,o),p(l,HD,o),p(l,UD,o),p(l,wD,o),p(l,se,o),t(se,ne),t(ne,kf),t(se,d4),p(l,CD,o),p(l,BD,o),p(l,jD,o),p(l,Vi,o),t(Vi,R4),p(l,ND,o),p(l,H,o),t(H,yf),t(yf,L4),t(H,I4),t(H,Sf),t(Sf,b4),t(H,k4),t(H,Pf),t(Pf,y4),t(H,S4),t(H,hf),t(hf,P4),p(l,FD,o),p(l,Zi,o),t(Zi,h4),p(l,GD,o),p(l,U,o),t(U,Af),t(Af,A4),t(U,M4),t(U,Mf),t(Mf,x4),t(U,H4),t(U,xf),t(xf,U4),t(U,w4),t(U,Xi),t(Xi,C4),t(Xi,Rl),t(Rl,ue),t(ue,B4),t(ue,j4),t(ue,N4),t(ue,Yi),t(Rl,F4),t(Rl,Hf),t(Hf,G4),t(Rl,z4),t(Rl,Uf),t(Uf,O4),p(l,zD,o),p(l,Gt,o),t(Gt,gi),t(Gt,T4),p(l,OD,o),p(l,Z,o),t(Z,wf),t(wf,q4),t(Z,J4),t(Z,Cf),t(Cf,Q4),t(Z,K4),t(Z,Bf),t(Bf,$4),p(l,TD,o),p(l,lr,o),t(lr,W4),p(l,qD,o),p(l,De,o),t(De,jf),t(jf,Nf),t(Nf,V4),t(De,Z4),t(De,Ff),t(Ff,Gf),t(Gf,X4),p(l,JD,o),p(l,er,o),t(er,Y4),p(l,QD,o),p(l,tr,o),t(tr,g4),p(l,KD,o),p(l,w,o),t(w,zf),t(zf,l5),t(w,e5),t(w,Of),t(Of,t5),t(w,i5),t(w,Tf),t(Tf,r5),t(w,a5),t(w,qf),t(qf,o5),p(l,$D,o),p(l,ir,o),t(ir,p5),p(l,WD,o),p(l,ve,o),t(ve,Jf),t(Jf,f5),t(ve,s5),t(ve,Qf),t(Qf,n5),p(l,VD,o),p(l,rr,o),t(rr,u5),p(l,ZD,o),p(l,ce,o),t(ce,Kf),t(Kf,D5),t(ce,v5),t(ce,$f),t($f,c5),p(l,XD,o),p(l,ar,o),t(ar,_5),p(l,YD,o),p(l,or,o),t(or,Wf),t(Wf,m5),p(l,gD,o),p(l,pr,o),t(pr,E5),p(l,l2,o),p(l,I,o),t(I,Vf),t(Vf,d5),t(I,R5),t(I,Zf),t(Zf,L5),t(I,I5),t(I,Xf),t(Xf,b5),t(I,k5),t(I,Yf),t(Yf,y5),t(I,S5),t(I,gf),t(gf,P5),p(l,e2,o),p(l,t2,o),p(l,i2,o),p(l,r2,o),p(l,_e,o),t(_e,me),t(me,ls),t(_e,h5),p(l,a2,o),p(l,o2,o),p(l,p2,o),p(l,fr,o),t(fr,A5),p(l,f2,o),p(l,Ee,o),t(Ee,es),t(es,M5),t(Ee,x5),t(Ee,ts),t(ts,H5),p(l,s2,o),p(l,sr,o),t(sr,U5),p(l,n2,o),p(l,de,o),t(de,is),t(is,w5),t(de,C5),t(de,rs),t(rs,B5),p(l,u2,o),p(l,Re,o),t(Re,Le),t(Le,as),t(Re,j5),p(l,D2,o),p(l,X,o),t(X,nr),t(X,N5),t(X,F5),t(X,G5),t(X,z5),p(l,v2,o),p(l,ur,o),t(ur,O5),p(l,c2,o),p(l,b,o),t(b,os),t(os,T5),t(b,q5),t(b,ps),t(ps,J5),t(b,Q5),t(b,fs),t(fs,K5),t(b,$5),t(b,ss),t(ss,W5),t(b,V5),t(b,ns),t(ns,Z5),p(l,_2,o),p(l,Dr,o),t(Dr,X5),p(l,m2,o),p(l,Y,o),t(Y,us),t(us,Y5),t(Y,g5),t(Y,Ds),t(Ds,lR),t(Y,eR),t(Y,vs),t(vs,tR),p(l,E2,o),p(l,Ie,o),t(Ie,cs),t(cs,iR),t(Ie,rR),t(Ie,vr),t(vr,aR),t(vr,_s),t(_s,ms),t(ms,oR),p(l,d2,o),p(l,cr,o),t(cr,pR),p(l,R2,o),p(l,be,o),t(be,Es),t(Es,fR),t(be,sR),t(be,ds),t(ds,nR),p(l,L2,o),p(l,ke,o),t(ke,ye),t(ye,Rs),t(ke,uR),p(l,I2,o),p(l,_r,o),t(_r,DR),p(l,b2,o),p(l,mr,o),t(mr,Ls),t(Ls,vR),p(l,k2,o),p(l,Er,o),t(Er,cR),p(l,y2,o),p(l,C,o),t(C,Is),t(Is,_R),t(C,mR),t(C,bs),t(bs,ER),t(C,dR),t(C,ks),t(ks,RR),t(C,LR),t(C,ys),t(ys,IR),p(l,S2,o),p(l,dr,o),t(dr,bR),p(l,P2,o),p(l,Se,o),t(Se,Ss),t(Ss,kR),t(Se,yR),t(Se,Rr),t(Rr,SR),t(Rr,zt),t(zt,Ps),t(Ps,PR),t(zt,hR),t(zt,hs),t(hs,AR),p(l,h2,o),p(l,Pe,o),t(Pe,Lr),t(Pe,MR),t(Pe,xR),p(l,A2,o),p(l,Ir,o),t(Ir,HR),p(l,M2,o),p(l,he,o),t(he,Ae),t(Ae,As),t(he,UR),p(l,x2,o),p(l,br,o),t(br,wR),p(l,H2,o),p(l,g,o),t(g,kr),t(kr,CR),t(kr,Ms),t(Ms,xs),t(xs,BR),t(g,jR),t(g,yr),t(yr,NR),t(yr,Hs),t(Hs,Us),t(Us,FR),t(g,GR),t(g,Sr),t(Sr,zR),t(Sr,ws),t(ws,Cs),t(Cs,OR),p(l,U2,o),p(l,Pr,o),t(Pr,TR),p(l,w2,o),p(l,B,o),t(B,Bs),t(Bs,qR),t(B,JR),t(B,js),t(js,QR),t(B,KR),t(B,Ns),t(Ns,$R),t(B,WR),t(B,Fs),t(Fs,VR),p(l,C2,o),p(l,Me,o),t(Me,xe),t(xe,Gs),t(Me,ZR),p(l,B2,o),p(l,hr,o),t(hr,XR),p(l,j2,o),p(l,Ar,o),t(Ar,zs),t(zs,YR),p(l,N2,o),p(l,Mr,o),t(Mr,gR),p(l,F2,o),p(l,ll,o),t(ll,Os),t(Os,l6),t(ll,e6),t(ll,Ts),t(Ts,t6),t(ll,i6),t(ll,qs),t(qs,r6),p(l,G2,o),p(l,xr,o),t(xr,a6),p(l,z2,o),p(l,He,o),t(He,Js),t(Js,o6),t(He,p6),t(He,Qs),t(Qs,f6),p(l,O2,o),p(l,Hr,o),t(Hr,s6),p(l,T2,o),p(l,Ue,o),t(Ue,Ks),t(Ks,n6),t(Ue,u6),t(Ue,$s),t($s,D6),p(l,q2,o),p(l,J2,o),p(l,Q2,o),p(l,K2,o),p(l,we,o),t(we,Ce),t(Ce,Ws),t(we,v6),p(l,$2,o),p(l,W2,o),p(l,V2,o),p(l,Ur,o),t(Ur,c6),p(l,Z2,o),p(l,j,o),t(j,wr),t(wr,_6),t(wr,Vs),t(Vs,Zs),t(Zs,m6),t(j,E6),t(j,Cr),t(Cr,d6),t(Cr,Xs),t(Xs,Ys),t(Ys,R6),t(j,L6),t(j,gs),t(gs,I6),t(j,b6),t(j,ln),t(ln,k6),p(l,X2,o),p(l,Be,o),t(Be,je),t(je,en),t(Be,y6),p(l,Y2,o),p(l,Ne,o),t(Ne,Br),t(Ne,S6),t(Ne,jr),p(l,g2,o),p(l,el,o),t(el,tn),t(tn,P6),t(el,h6),t(el,rn),t(rn,A6),t(el,M6),t(el,Nr),t(Nr,x6),t(Nr,Ot),t(Ot,an),t(an,H6),t(Ot,U6),t(Ot,on),t(on,w6),p(l,lv,o),p(l,Fr,o),t(Fr,C6),p(l,ev,o),p(l,tl,o),t(tl,pn),t(pn,B6),t(tl,j6),t(tl,fn),t(fn,N6),t(tl,F6),t(tl,sn),t(sn,G6),p(l,tv,o),p(l,Gr,o),t(Gr,z6),p(l,iv,o),p(l,zr,o),t(zr,O6),p(l,rv,o),p(l,il,o),t(il,nn),t(nn,T6),t(il,q6),t(il,un),t(un,J6),t(il,Q6),t(il,Dn),t(Dn,K6),p(l,av,o),p(l,Fe,o),t(Fe,Or),t(Fe,$6),t(Fe,W6),p(l,ov,o),p(l,Ge,o),t(Ge,vn),t(vn,V6),t(Ge,Z6),t(Ge,cn),t(cn,X6),p(l,pv,o),p(l,ze,o),t(ze,Oe),t(Oe,_n),t(ze,Y6),p(l,fv,o),p(l,Te,o),t(Te,Tr),t(Te,g6),t(Te,l7),p(l,sv,o),p(l,qe,o),t(qe,mn),t(mn,e7),t(qe,t7),t(qe,En),t(En,i7),p(l,nv,o),p(l,Je,o),t(Je,Qe),t(Qe,dn),t(Je,r7),p(l,uv,o),p(l,Ke,o),t(Ke,qr),t(Ke,a7),t(Ke,o7),p(l,Dv,o),p(l,rl,o),t(rl,Rn),t(Rn,p7),t(rl,f7),t(rl,Ln),t(Ln,s7),t(rl,n7),t(rl,In),t(In,u7),p(l,vv,o),p(l,Jr,o),t(Jr,D7),p(l,cv,o),p(l,al,o),t(al,bn),t(bn,v7),t(al,c7),t(al,kn),t(kn,_7),t(al,m7),t(al,yn),t(yn,E7),p(l,_v,o),p(l,$e,o),t($e,We),t(We,Sn),t($e,d7),p(l,mv,o),p(l,Ve,o),t(Ve,Qr),t(Ve,R7),t(Ve,L7),p(l,Ev,o),p(l,Ze,o),t(Ze,Xe),t(Xe,Pn),t(Ze,I7),p(l,dv,o),p(l,Kr,o),t(Kr,b7),p(l,Rv,o),p(l,$r,o),t($r,Wr),t(Wr,k7),t(Wr,hn),t(hn,An),t(An,y7),p(l,Lv,o),p(l,Vr,o),t(Vr,Zr),p(l,Iv,o),p(l,Xr,o),t(Xr,S7),p(l,bv,o),p(l,Yr,o),t(Yr,gr),t(gr,P7),t(gr,Mn),t(Mn,xn),t(xn,h7),p(l,kv,o),p(l,la,o),t(la,A7),p(l,yv,o),p(l,ea,o),t(ea,ta),t(ta,M7),t(ta,Ll),t(Ll,Hn),t(Hn,x7),t(Ll,H7),t(Ll,Un),t(Un,U7),t(Ll,w7),t(Ll,wn),t(wn,C7),p(l,Sv,o),p(l,Ye,o),t(Ye,ge),t(ge,Cn),t(Ye,B7),p(l,Pv,o),p(l,lt,o),t(lt,ia),t(lt,j7),t(lt,N7),p(l,hv,o),p(l,ol,o),t(ol,Bn),t(Bn,F7),t(ol,G7),t(ol,jn),t(jn,z7),t(ol,O7),t(ol,ra),t(ra,T7),t(ra,Nn),t(Nn,Fn),t(Fn,q7),p(l,Av,o),p(l,Mv,o),p(l,xv,o),p(l,Hv,o),p(l,et,o),t(et,tt),t(tt,Gn),t(et,J7),p(l,Uv,o),p(l,wv,o),p(l,Cv,o),p(l,aa,o),t(aa,Q7),p(l,Bv,o),p(l,it,o),t(it,rt),t(rt,zn),t(it,K7),p(l,jv,o),p(l,oa,o),t(oa,$7),p(l,Nv,o),p(l,at,o),t(at,On),t(On,W7),t(at,V7),t(at,Tn),t(Tn,Z7),p(l,Fv,o),p(l,pa,o),t(pa,X7),p(l,Gv,o),p(l,N,o),t(N,qn),t(qn,Y7),t(N,g7),t(N,Jn),t(Jn,lL),t(N,eL),t(N,Qn),t(Qn,tL),t(N,iL),t(N,fa),t(fa,rL),t(fa,Kn),t(Kn,$n),t($n,aL),p(l,zv,o),p(l,sa,o),t(sa,oL),p(l,Ov,o),p(l,F,o),t(F,Wn),t(Wn,pL),t(F,fL),t(F,Vn),t(Vn,sL),t(F,nL),t(F,Zn),t(Zn,uL),t(F,DL),t(F,Xn),t(Xn,vL),p(l,Tv,o),p(l,na,o),t(na,cL),p(l,qv,o),p(l,G,o),t(G,Yn),t(Yn,_L),t(G,mL),t(G,gn),t(gn,EL),t(G,dL),t(G,lu),t(lu,RL),t(G,LL),t(G,eu),t(eu,IL),p(l,Jv,o),p(l,ua,o),t(ua,bL),p(l,Qv,o),p(l,ot,o),t(ot,pt),t(pt,tu),t(ot,kL),p(l,Kv,o),p(l,Da,o),t(Da,yL),p(l,$v,o),p(l,va,o),t(va,iu),t(iu,SL),p(l,Wv,o),p(l,ca,o),t(ca,PL),p(l,Vv,o),p(l,Zv,o),p(l,Xv,o),p(l,Yv,o),p(l,ft,o),t(ft,st),t(st,ru),t(ft,hL),p(l,gv,o),p(l,lc,o),p(l,ec,o),p(l,_a,o),t(_a,AL),p(l,tc,o),p(l,z,o),t(z,Tt),t(Tt,au),t(au,ML),t(Tt,xL),t(Tt,qt),t(qt,ou),t(ou,HL),t(qt,UL),t(qt,pu),t(pu,wL),t(z,CL),t(z,Jt),t(Jt,fu),t(fu,BL),t(Jt,jL),t(Jt,Il),t(Il,su),t(su,NL),t(Il,FL),t(Il,nu),t(nu,GL),t(Il,zL),t(Il,uu),t(uu,OL),t(z,TL),t(z,Qt),t(Qt,Du),t(Du,qL),t(Qt,JL),t(Qt,vu),t(vu,cu),t(cu,QL),t(z,KL),t(z,Kt),t(Kt,_u),t(_u,$L),t(Kt,WL),t(Kt,bl),t(bl,mu),t(mu,VL),t(bl,ZL),t(bl,Eu),t(Eu,XL),t(bl,YL),t(bl,du),t(du,gL),p(l,ic,o),p(l,nt,o),t(nt,l0),t(nt,e0),t(nt,t0),p(l,rc,o),p(l,O,o),t(O,Ru),t(Ru,i0),t(O,r0),t(O,Lu),t(Lu,a0),t(O,o0),t(O,Iu),t(Iu,p0),t(O,f0),t(O,bu),t(bu,s0),p(l,ac,o),p(l,ut,o),t(ut,n0),t(ut,u0),t(ut,D0),p(l,oc,o),p(l,pl,o),t(pl,ku),t(ku,v0),t(pl,c0),t(pl,yu),t(yu,_0),t(pl,m0),t(pl,Su),t(Su,E0),p(l,pc,o),p(l,Dt,o),t(Dt,d0),t(Dt,R0),t(Dt,L0),p(l,fc,o),p(l,ma,o),t(ma,Pu),t(Pu,I0),p(l,sc,o),p(l,nc,o),p(l,uc,o),p(l,Dc,o),p(l,vt,o),t(vt,ct),t(ct,hu),t(vt,b0),p(l,vc,o),p(l,cc,o),p(l,_c,o),p(l,Ea,o),t(Ea,k0),p(l,mc,o),p(l,da,o),t(da,Au),t(Au,y0),p(l,Ec,o),p(l,Ra,o),t(Ra,S0),p(l,dc,o),p(l,La,o),t(La,Mu),t(Mu,P0),p(l,Rc,o),p(l,Ia,o),t(Ia,h0),p(l,Lc,o),p(l,ba,o),t(ba,xu),t(xu,A0),p(l,Ic,o),p(l,ka,o),t(ka,M0),bc=!0},p(l,[o]){const Hu={};o&1&&(Hu.$$scope={dirty:o,ctx:l}),zl.$set(Hu)},i(l){bc||(Ih(zl.$$.fragment,l),bc=!0)},o(l){bh(zl.$$.fragment,l),bc=!1},d(l){l&&e(d),l&&e(Fu),l&&e($t),l&&e(Gu),l&&e(m),l&&e(zu),l&&e(Ou),l&&e(Tu),l&&e(qu),l&&e(yl),l&&e(Ju),l&&e(Qu),l&&e(Ku),l&&e(Wt),l&&e($u),l&&e(q),l&&e(Wu),l&&e(Vt),l&&e(Vu),l&&e(P),l&&e(Zu),l&&e(Zt),l&&e(Xu),l&&e(J),l&&e(Yu),l&&e(Xt),l&&e(gu),l&&e(Pl),l&&e(l1),l&&e(Yt),l&&e(e1),l&&e(h),l&&e(t1),l&&e(gt),l&&e(i1),l&&e(hl),l&&e(r1),l&&e(li),l&&e(a1),l&&e(Al),l&&e(o1),l&&e(ei),l&&e(p1),l&&e(Ml),l&&e(f1),l&&e(s1),l&&e(n1),l&&e(u1),l&&e(xl),l&&e(D1),l&&e(v1),l&&e(c1),l&&e(Ul),l&&e(_1),l&&e(ti),l&&e(m1),l&&e(Q),l&&e(E1),l&&e(ii),l&&e(d1),l&&e(Cl),l&&e(R1),l&&e(ri),l&&e(L1),l&&e(K),l&&e(I1),l&&e(Bl),l&&e(b1),l&&e(ai),l&&e(k1),l&&e(oi),l&&e(y1),l&&e(pi),l&&e(S1),l&&e($),l&&e(P1),l&&e(si),l&&e(h1),l&&e(A),l&&e(A1),l&&e(Nl),l&&e(M1),l&&e(ni),l&&e(x1),l&&e(ui),l&&e(H1),l&&e(_l),l&&e(U1),l&&e(ml),l&&e(w1),l&&e(El),l&&e(C1),l&&e(Gl),kh(zl),l&&e(B1),l&&e(_i),l&&e(j1),l&&e(mi),l&&e(N1),l&&e(M),l&&e(F1),l&&e(Tl),l&&e(G1),l&&e(Ri),l&&e(z1),l&&e(Ii),l&&e(O1),l&&e(c),l&&e(T1),l&&e(bi),l&&e(q1),l&&e(Jl),l&&e(J1),l&&e(Ql),l&&e(Q1),l&&e(yi),l&&e(K1),l&&e(Si),l&&e($1),l&&e(Pi),l&&e(W1),l&&e(W),l&&e(V1),l&&e(Z1),l&&e(X1),l&&e(Y1),l&&e($l),l&&e(g1),l&&e(lD),l&&e(eD),l&&e(Ai),l&&e(tD),l&&e(Mi),l&&e(iD),l&&e(xi),l&&e(rD),l&&e(V),l&&e(aD),l&&e(Hi),l&&e(oD),l&&e(Vl),l&&e(pD),l&&e(Ui),l&&e(fD),l&&e(Zl),l&&e(sD),l&&e(Xl),l&&e(nD),l&&e(gl),l&&e(uD),l&&e(le),l&&e(DD),l&&e(Ci),l&&e(vD),l&&e(Bi),l&&e(cD),l&&e(ji),l&&e(_D),l&&e(Ni),l&&e(mD),l&&e(ee),l&&e(ED),l&&e(Fi),l&&e(dD),l&&e(ie),l&&e(RD),l&&e(re),l&&e(LD),l&&e(Oi),l&&e(ID),l&&e(x),l&&e(bD),l&&e(ae),l&&e(kD),l&&e(qi),l&&e(yD),l&&e(Ji),l&&e(SD),l&&e(pe),l&&e(PD),l&&e(y),l&&e(hD),l&&e(_),l&&e(AD),l&&e($i),l&&e(MD),l&&e(L),l&&e(xD),l&&e(HD),l&&e(UD),l&&e(wD),l&&e(se),l&&e(CD),l&&e(BD),l&&e(jD),l&&e(Vi),l&&e(ND),l&&e(H),l&&e(FD),l&&e(Zi),l&&e(GD),l&&e(U),l&&e(zD),l&&e(Gt),l&&e(OD),l&&e(Z),l&&e(TD),l&&e(lr),l&&e(qD),l&&e(De),l&&e(JD),l&&e(er),l&&e(QD),l&&e(tr),l&&e(KD),l&&e(w),l&&e($D),l&&e(ir),l&&e(WD),l&&e(ve),l&&e(VD),l&&e(rr),l&&e(ZD),l&&e(ce),l&&e(XD),l&&e(ar),l&&e(YD),l&&e(or),l&&e(gD),l&&e(pr),l&&e(l2),l&&e(I),l&&e(e2),l&&e(t2),l&&e(i2),l&&e(r2),l&&e(_e),l&&e(a2),l&&e(o2),l&&e(p2),l&&e(fr),l&&e(f2),l&&e(Ee),l&&e(s2),l&&e(sr),l&&e(n2),l&&e(de),l&&e(u2),l&&e(Re),l&&e(D2),l&&e(X),l&&e(v2),l&&e(ur),l&&e(c2),l&&e(b),l&&e(_2),l&&e(Dr),l&&e(m2),l&&e(Y),l&&e(E2),l&&e(Ie),l&&e(d2),l&&e(cr),l&&e(R2),l&&e(be),l&&e(L2),l&&e(ke),l&&e(I2),l&&e(_r),l&&e(b2),l&&e(mr),l&&e(k2),l&&e(Er),l&&e(y2),l&&e(C),l&&e(S2),l&&e(dr),l&&e(P2),l&&e(Se),l&&e(h2),l&&e(Pe),l&&e(A2),l&&e(Ir),l&&e(M2),l&&e(he),l&&e(x2),l&&e(br),l&&e(H2),l&&e(g),l&&e(U2),l&&e(Pr),l&&e(w2),l&&e(B),l&&e(C2),l&&e(Me),l&&e(B2),l&&e(hr),l&&e(j2),l&&e(Ar),l&&e(N2),l&&e(Mr),l&&e(F2),l&&e(ll),l&&e(G2),l&&e(xr),l&&e(z2),l&&e(He),l&&e(O2),l&&e(Hr),l&&e(T2),l&&e(Ue),l&&e(q2),l&&e(J2),l&&e(Q2),l&&e(K2),l&&e(we),l&&e($2),l&&e(W2),l&&e(V2),l&&e(Ur),l&&e(Z2),l&&e(j),l&&e(X2),l&&e(Be),l&&e(Y2),l&&e(Ne),l&&e(g2),l&&e(el),l&&e(lv),l&&e(Fr),l&&e(ev),l&&e(tl),l&&e(tv),l&&e(Gr),l&&e(iv),l&&e(zr),l&&e(rv),l&&e(il),l&&e(av),l&&e(Fe),l&&e(ov),l&&e(Ge),l&&e(pv),l&&e(ze),l&&e(fv),l&&e(Te),l&&e(sv),l&&e(qe),l&&e(nv),l&&e(Je),l&&e(uv),l&&e(Ke),l&&e(Dv),l&&e(rl),l&&e(vv),l&&e(Jr),l&&e(cv),l&&e(al),l&&e(_v),l&&e($e),l&&e(mv),l&&e(Ve),l&&e(Ev),l&&e(Ze),l&&e(dv),l&&e(Kr),l&&e(Rv),l&&e($r),l&&e(Lv),l&&e(Vr),l&&e(Iv),l&&e(Xr),l&&e(bv),l&&e(Yr),l&&e(kv),l&&e(la),l&&e(yv),l&&e(ea),l&&e(Sv),l&&e(Ye),l&&e(Pv),l&&e(lt),l&&e(hv),l&&e(ol),l&&e(Av),l&&e(Mv),l&&e(xv),l&&e(Hv),l&&e(et),l&&e(Uv),l&&e(wv),l&&e(Cv),l&&e(aa),l&&e(Bv),l&&e(it),l&&e(jv),l&&e(oa),l&&e(Nv),l&&e(at),l&&e(Fv),l&&e(pa),l&&e(Gv),l&&e(N),l&&e(zv),l&&e(sa),l&&e(Ov),l&&e(F),l&&e(Tv),l&&e(na),l&&e(qv),l&&e(G),l&&e(Jv),l&&e(ua),l&&e(Qv),l&&e(ot),l&&e(Kv),l&&e(Da),l&&e($v),l&&e(va),l&&e(Wv),l&&e(ca),l&&e(Vv),l&&e(Zv),l&&e(Xv),l&&e(Yv),l&&e(ft),l&&e(gv),l&&e(lc),l&&e(ec),l&&e(_a),l&&e(tc),l&&e(z),l&&e(ic),l&&e(nt),l&&e(rc),l&&e(O),l&&e(ac),l&&e(ut),l&&e(oc),l&&e(pl),l&&e(pc),l&&e(Dt),l&&e(fc),l&&e(ma),l&&e(sc),l&&e(nc),l&&e(uc),l&&e(Dc),l&&e(vt),l&&e(vc),l&&e(cc),l&&e(_c),l&&e(Ea),l&&e(mc),l&&e(da),l&&e(Ec),l&&e(Ra),l&&e(dc),l&&e(La),l&&e(Rc),l&&e(Ia),l&&e(Lc),l&&e(ba),l&&e(Ic),l&&e(ka)}}}const Mh={title:"Spark 논문(RDD) 정리",date:"2023-09-06T00:00:00.000Z",excerpt:"Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing",categories:["Apache Spark","논문정리"],coverImage:"/post_img/Distributed Computing/Spark/RDD/cover.png",coverWidth:16,coverHeight:9,indexed:!0,exposed:!0};class xh extends _h{constructor(d){super(),mh(this,d,null,Ph,Eh,{})}}export{xh as default,Mh as metadata};
